{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a7c1f1-edbd-4e02-a06f-5a0b47a63cee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# ICAPS24 SkDecide Tutorial: solving scheduling problems with constraint programming, operation research, and reinforcement learning solvers\n",
    "\n",
    "Alexandre Arnold, Guillaume Povéda, Florent Teichteil-Königsbuch\n",
    "\n",
    "Credits to [IMACS](https://imacs.polytechnique.fr/), especially to Nolwen Huet, and [Olivier Regnier-Coudert](https://github.com/olivierabz).\n",
    "\n",
    "In this tutorial notebook, you will be introduced to scheduling domains in scikit-decide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648f006",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What is scheduling and how it is different from planning or control domains ?\n",
    "\n",
    "\n",
    "Main characteristic of scheduling problems compared to classical planning : \n",
    "- Parallel tasks\n",
    "- Time dimension is preponderant\n",
    "- Complex time dependant constraint ?\n",
    "- For most scheduling problems we know the task to accomplish in advance contrary to planning problems.\n",
    "\n",
    "Solving technologies to solve scheduling problems :\n",
    "- State of the art are more on operational research community : mathematical programming, metaheuristic, discrete optimization in general -> need to extend scikit-decide with such solver technologies ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa32b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Scheduling API in scikit-decide\n",
    "We developped a side API to be able to describe scheduling problems in scikit-decide.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/airbus/scikit-decide/refs/heads/master/docs/.vuepress/public/characteristics.png\" alt=\"Example Image\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c2e82-df1a-455f-aa27-8ae45c0a1a20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "A base scheduling domain is : \n",
    "\n",
    "- SingleAgent : implementation choice, in practice some scheduling problem could be encoded as MA\n",
    "- Sequential : even though task are executed in parallel we implement domain in a way that is compatible with Sequential caracteristic.\n",
    "- Simulation : step function are stateless and can be somulated (sample transition from any state)\n",
    "- DeterministicInitialized : we start from an empty schedule [could be changed]\n",
    "- Actions : only controlled event like starting tasks are considered\n",
    "- FullyObservable : we know the current status of the schedule\n",
    "- Markovian : next state only depends on action and current state\n",
    "- Goals : goal is to accomplish all task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289db6f6-91f7-4554-8c4a-ead0b2871b27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Special features of scheduling problems :\n",
    "A scheduling problem is defined with additional features that are specific to scheduling, most of them being self explanatory. \\\n",
    "Each of the feature is requiring implementation of class methods, that are easy to implement (only giving a description of the scheduling problems using data containers, as you will see in the example).\n",
    "\n",
    "[Reference doc on scheduling features](https://airbus.github.io/scikit-decide/reference/#scheduling)\n",
    "- WithPrecedence/WithoutPrecedence : \n",
    "- MultiMode/SingleMode : multiple or single way of doing a taks\n",
    "- VariableResourceConsumption/ConstantResourceConsumption : task needing variable or constant resource quantity during execution...\n",
    "- WithPreemptivity/WithoutPreemptivity : allow or not preemption of task\n",
    "- WithResourceTypes/WithoutResourceTypes\n",
    "- WithResourceUnits/WithoutResourceUnits\n",
    "- MixedRenewable/RenewableOnly\n",
    "- SimulatedTaskDuration/UncertainMultivariateTaskDuration/UncertainUnivariateTaskDuration/UncertainBoundedTaskDuration/UniformBoundedTaskDuration/EnumerableTaskDuration/DeterministicTaskDuration\n",
    "- CustomTaskProgress/DeterministicTaskProgress\n",
    "- WithResourceSkills/WithoutResourceSkills\n",
    "- WithTimeLag/WithoutTimeLag\n",
    "- WithTimeWindow/WithoutTimeWindow\n",
    "- WithPreallocations/WithoutPreallocations\n",
    "- WihConditionalTasks/WithoutConditionnalTasks\n",
    "- UncertainResourceAvailabilityChanges/DeterministicResourceAvailabilityChanges/WithoutResourceAvailabilityChange\n",
    "- WithModeCosts/WithoutModeCosts\n",
    "- WithResourceCosts/WithoutResourceCosts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a733844-4ba3-40ea-85a5-5a9bf2464212",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Domain implementation\n",
    "See ref : **An empirical evaluation of permutation-based policies for stochastic RCPSP**, <i>Regnier-Coudert, Olivier and Povéda, Guillaume</i>, GECCO21 for more insights of the domain implementation.\n",
    "\n",
    "Behind the wall, a scikit-decide domain is fully implemented from the pure scheduling features.\n",
    "It implements the simulator from 1 scheduling state to another one, action available functions etc for the scheduling domain. \\\n",
    "Therefore, user don't need to implement get_next_state or other functions needed in scikit-decide. \\\n",
    "States and actions are containing those features :\n",
    "- State :\n",
    "    - set of task done\n",
    "    - set of remaining task\n",
    "    - set of starting time for each task, current progress, and resource allocated to it\n",
    "    - resource available\n",
    "- Actions : \n",
    "    - Start a task and allocate some resource to it\n",
    "    - Stop a task\n",
    "    - Resume a task and allocate some resource to it\n",
    "    - Do nothing (this will have no effect but to advance the simulation time to next time step or next event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadff6ec-165a-4582-a21b-5626291d41a6",
   "metadata": {
    "id": "Il_4li4ZC8tz"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6e568-8155-4575-bf60-cfe64716d674",
   "metadata": {},
   "source": [
    "Concerning the python kernel to use for this notebook:\n",
    "- If running locally, be sure to use an environment with\n",
    "  - `scikit-decide[all]`\n",
    "  - `optuna` and `optuna-dashboard` (to show how to tune hyperparameters)\n",
    "- If running on colab, the next cell does it for you.\n",
    "- If running on binder, the environment should be ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a7f01-3aad-4d42-9988-e1d322a054f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab: install the library\n",
    "on_colab = \"google.colab\" in str(get_ipython())\n",
    "if on_colab:\n",
    "    import glob\n",
    "    import json\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    using_nightly_version = True\n",
    "\n",
    "    if using_nightly_version:\n",
    "        # look for nightly build download url\n",
    "        release_curl_res = !curl -L   -H \"Accept: application/vnd.github+json\" -H \"X-GitHub-Api-Version: 2022-11-28\" https://api.github.com/repos/airbus/scikit-decide/releases/tags/nightly\n",
    "        release_dict = json.loads(release_curl_res.s)\n",
    "        release_download_url = sorted(\n",
    "            release_dict[\"assets\"], key=lambda d: d[\"updated_at\"]\n",
    "        )[-1][\"browser_download_url\"]\n",
    "        print(release_download_url)\n",
    "\n",
    "        # download and unzip\n",
    "        !wget --output-document=release.zip {release_download_url}\n",
    "        !unzip -o release.zip\n",
    "\n",
    "        # get proper wheel name according to python version used\n",
    "        wheel_pythonversion_tag = f\"cp{sys.version_info.major}{sys.version_info.minor}\"\n",
    "        wheel_path = glob.glob(\n",
    "            f\"dist/scikit_decide*{wheel_pythonversion_tag}*manylinux*.whl\"\n",
    "        )[0]\n",
    "\n",
    "        skdecide_pip_spec = f\"{wheel_path}[all]\"\n",
    "    else:\n",
    "        skdecide_pip_spec = \"scikit-decide[all]\"\n",
    "\n",
    "    # install scikit-decide with all extras + optuna + optuna-dashboard\n",
    "    !pip install {skdecide_pip_spec} optuna optuna-dashboard\n",
    "\n",
    "    # install and configure minizinc\n",
    "    !curl -o minizinc.AppImage -L https://github.com/MiniZinc/MiniZincIDE/releases/download/2.8.5/MiniZincIDE-2.8.5-x86_64.AppImage\n",
    "    !chmod +x minizinc.AppImage\n",
    "    !./minizinc.AppImage --appimage-extract\n",
    "    os.environ[\"PATH\"] = f\"{os.getcwd()}/squashfs-root/usr/bin/:{os.environ['PATH']}\"\n",
    "    os.environ[\n",
    "        \"LD_LIBRARY_PATH\"\n",
    "    ] = f\"{os.getcwd()}/squashfs-root/usr/lib/:{os.environ['LD_LIBRARY_PATH']}\"\n",
    "\n",
    "    # download utility modules (that are in the same repo)\n",
    "    this_folder = os.getcwd()\n",
    "    module_path = os.path.join(this_folder, \"rcpsp_domains/\")\n",
    "    os.makedirs(module_path, exist_ok=True)\n",
    "    for script in [\n",
    "        \"rcpsp_sk_domain.py\",\n",
    "        \"rcpsp_sk_domain_local_search.py\",\n",
    "        \"stochastic_rcpsp_sk_domain.py\",\n",
    "        \"multi_solve_optuna.py\",\n",
    "    ]:\n",
    "        !wget \"https://raw.githubusercontent.com/airbus/scikit-decide/master/notebooks/icaps24/rcpsp_domains/{script}\" -O \"{os.path.join(module_path, script)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193743c-93c3-4b1b-a502-fdd03e8c0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Set, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# [allow for running minizinc inside a notebook]\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from discrete_optimization.datasets import fetch_data_from_psplib\n",
    "from discrete_optimization.generic_tools.cp_tools import ParametersCp\n",
    "from discrete_optimization.rcpsp.parser import get_data_available, parse_file\n",
    "from discrete_optimization.rcpsp.problem import RcpspProblem, RcpspSolution\n",
    "from discrete_optimization.rcpsp.utils import plot_ressource_view, plot_task_gantt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from skdecide import rollout\n",
    "from skdecide.builders.domain.scheduling.modes import (\n",
    "    ConstantModeConsumption,\n",
    "    ModeConsumption,\n",
    ")\n",
    "from skdecide.builders.domain.scheduling.scheduling_domains import (\n",
    "    SchedulingObjectiveEnum,\n",
    "    SingleModeRCPSP,\n",
    ")\n",
    "from skdecide.hub.domain.rcpsp.rcpsp_sk_parser import load_domain\n",
    "from skdecide.hub.solver.do_solver.do_solver_scheduling import DOSolver, SolvingMethod\n",
    "from skdecide.hub.solver.do_solver.sgs_policies import (\n",
    "    BasePolicyMethod,\n",
    "    PolicyMethodParams,\n",
    ")\n",
    "from skdecide.hub.solver.do_solver.sk_to_do_binding import from_last_state_to_solution\n",
    "from skdecide.hub.solver.ray_rllib import RayRLlib\n",
    "from skdecide.hub.solver.stable_baselines import StableBaseline\n",
    "\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4dbd00-ae8b-438d-93a9-ca2bc65744c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## RCPSP template\n",
    "In particular, scheduling domain can represent RCPSP and its many other variants.\n",
    "\n",
    "Resource-constrained project scheduling problem (RCPSP) is made of $M$ activities that have precedence constraints. That means that if activity $j \\in [1,M]$ is a successor of activity $i \\in [1,M]$, then activity $i$ must be completed before activity $j$ can be started.\n",
    "\n",
    "On top of these constraints, each project is assigned a set of K renewable resources where each resource $k$ is available in $R_{k}$ units for the entire duration of the project. Each activity may require one or more of these resources to be completed. -- While scheduling the activities, the daily resource usage for resource $k$ can not exceed $R_{k}$ units.\n",
    "- Each activity $j$ takes $d_{j}$ time units to complete\n",
    "- The overall goal of the problem is usually to minimize the makespan\n",
    "\n",
    "A classic variant of RCPSP is the multimode RCPSP where each task can be executed in several ways (one way=one mode). A typical example is :\n",
    "- Mode n°1 'Fast mode': high resource consumption and fast\n",
    "- Mode n°2 'Slow mode' : low resource consumption but slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c329472-972c-49f1-883c-2dcfaa0763bb",
   "metadata": {
    "custom_css": "autofit",
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's look what defines the classical RCPSP for example in terms of scheduling features.\n",
    "SingleModeRCPSP??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a90d938-0c63-4a04-9bf0-e539d5ebaee6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Small RCPSP Domain\n",
    "When implementing a ```SingleModeRCPSP```, you are asked to fill a few methods as in this example.\\\n",
    "As we pointed out before, there is no complex code to implement, only description of the scheduling instance respecting the typing convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f961346",
   "metadata": {
    "custom_css": "autofit",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VerySimple_RCPSPDomain(SingleModeRCPSP):\n",
    "    def __init__(self):\n",
    "        self.initialize_domain()\n",
    "\n",
    "    # We optimize the makespan\n",
    "    def _get_objectives(self) -> List[SchedulingObjectiveEnum]:\n",
    "        return [SchedulingObjectiveEnum.MAKESPAN]\n",
    "\n",
    "    # The max horizon is 10\n",
    "    def _get_max_horizon(self) -> int:\n",
    "        return 10\n",
    "\n",
    "    # For each task returns its successors\n",
    "    def _get_successors(self) -> Dict[int, List[int]]:\n",
    "        return {\n",
    "            1: [2, 4],\n",
    "            2: [3],\n",
    "            3: [5],\n",
    "            4: [5],\n",
    "            5: [],\n",
    "        }\n",
    "\n",
    "    # Return task ids\n",
    "    def _get_tasks_ids(self) -> Union[Set[int], Dict[int, Any], List[int]]:\n",
    "        return set([*range(1, 6)])\n",
    "\n",
    "    # Details the resource consumption for each task\n",
    "    def _get_tasks_mode(self) -> Dict[int, ModeConsumption]:\n",
    "        return {\n",
    "            1: ConstantModeConsumption({\"r1\": 0}),\n",
    "            2: ConstantModeConsumption({\"r1\": 4}),\n",
    "            3: ConstantModeConsumption({\"r1\": 1}),\n",
    "            4: ConstantModeConsumption({\"r1\": 0}),\n",
    "            5: ConstantModeConsumption({\"r1\": 0}),\n",
    "        }\n",
    "\n",
    "    # Returns all resource types in the problem\n",
    "    def _get_resource_types_names(self) -> List[str]:\n",
    "        return [\"r1\"]\n",
    "\n",
    "    # Task duration by mode, here fully deterministic\n",
    "    def _get_task_duration(\n",
    "        self, task: int, mode: Optional[int] = 1, progress_from: Optional[float] = 0.0\n",
    "    ) -> int:\n",
    "        all_durations = {1: 0, 2: 3, 3: 3, 4: 7, 5: 0}\n",
    "        return all_durations[task]\n",
    "\n",
    "    # Returns resource capacity\n",
    "    def _get_original_quantity_resource(self, resource: str, **kwargs) -> int:\n",
    "        all_resource_quantities = {\"r1\": 7}\n",
    "        return all_resource_quantities[resource]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89b5e2-4e8b-4806-9012-680d34bf0352",
   "metadata": {},
   "source": [
    "#### Domain instanciation \n",
    "Let's instanciate the domain and see what is inside a state (already implemented in scikit-decide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a105db-62ff-4dcc-a137-4b71598e8b39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "domain = VerySimple_RCPSPDomain()\n",
    "domain.set_inplace_environment(False)\n",
    "state = domain.get_initial_state()\n",
    "print(f\" The state contains the following field:\")\n",
    "from pprint import pprint\n",
    "\n",
    "pprint([x for x in dir(state) if not x.startswith(\"_\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6eeaac-b5ab-4cb2-aa89-134986c8b7f4",
   "metadata": {},
   "source": [
    "Now let see what are the available actions in the initial state : \n",
    "You should get : \n",
    "- Starting task 1 (which is the \"source\" task in our problem)\n",
    "- Advance in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a068c4-62da-4ad1-91a8-f97dc0b1decc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\n\\n\".join([str(a) for a in domain.get_applicable_actions(state).get_elements()])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a70de97-c143-447a-b01a-ec4603d8bf23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Solving RCPSP domains\n",
    "\n",
    "We will study 3 different ways of solving scheduling problem\n",
    "- Classical graph search algorithm (A*) on (very small) instances\n",
    "- Combinatorial optimization and heuristics\n",
    "- Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00216b8-56fa-4356-a0d5-c522643db0c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Solving with A*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9add91-b742-4e9e-b6d7-6a238b7fa694",
   "metadata": {},
   "source": [
    "Scheduling domain can be solved with compatible solver in the library scikit-decide. In the case of RCPSP, deterministic planning solver such as A* can be tried. This solver will only work with tiny scheduling problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe3d8f-f4fe-466c-a5d8-085c4ec36a78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skdecide.hub.solver.lazy_astar import LazyAstar\n",
    "\n",
    "solver = LazyAstar(domain_factory=lambda: domain, heuristic=None)\n",
    "solver.solve(from_memory=state)\n",
    "# Rollout from scikit-decide main library !\n",
    "episode = rollout(\n",
    "    domain=domain, solver=solver, verbose=False, return_episodes=True, num_episodes=1\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3407b6c-0910-49b8-8afb-f9956dcd0c2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ploting solution\n",
    "states = episode[0]\n",
    "do_sol = from_last_state_to_solution(states[-1], domain)\n",
    "# Each line of the plot is a task\n",
    "fig_gantt = plot_task_gantt(do_sol.problem, do_sol)\n",
    "# Plot resource consumption plot\n",
    "fig_resource = plot_ressource_view(do_sol.problem, do_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be627ef-0e78-4047-a4e3-703046b26a57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solving with combinatorial optimization \n",
    "Naïve graph search won't be efficient on classical sized instance. We developed a range of solvers based on operational research/discrete optimization methods to solve scheduling problems in skdecide.\n",
    "[Discrete Optimization](https://github.com/airbus/discrete-optimization) library is the scheduling engine to solve scikit-decide scheduling domains. It implements an extensive API similar to scikit-decide for combinatorial optimization problems.\n",
    "\n",
    "Besides scheduling it implements a wide range of domain (optimisation problems):\n",
    "- knapsack, coloring, tsp, vrp, maximum independent set, facility location, rcpsp and variants.\n",
    "\n",
    "All problems have a complete set of solving solvers available : \n",
    "- Mathematical programming methods (Milp with open source solver and Gurobi, CP with Ortools, minizinc models..)\n",
    "- Local search and genetic algorithms\n",
    "- Custom heuristics (queue scheduling etc)\n",
    "API is flexible to combine different solver together, do (semi) automatic hyperparameter optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494db2e-8118-4cdd-930a-55cbbbf34543",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(get_data_available()) == 0:\n",
    "    fetch_data_from_psplib()\n",
    "file = [f for f in get_data_available() if \"j1201_1.sm\" in f][0]\n",
    "rcpsp_domain = load_domain(file)\n",
    "rcpsp_domain.set_inplace_environment(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0eeb7d-12e4-45fa-b15f-d87f09205e2a",
   "metadata": {},
   "source": [
    "### Solving with constraint programming solver\n",
    "Current SoTa for scheduling is to use specific CP solver, sometimes using lazy clause generation (like ortools cpsat or chuffed among the open source solutions). \\\n",
    "```DOSolver``` is a scikit-decide Solver but uses in backend the CP model and solver present in discrete-optimization library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ee21b-5b2b-4441-9c75-30107b99ecfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Solving with Constraint programming solver (Chuffed solver by default)\n",
    "from discrete_optimization.rcpsp.solvers.cpsat import CpSatRcpspSolver\n",
    "\n",
    "minizinc_available = False\n",
    "p = ParametersCp.default_cpsat()\n",
    "p.time_limit = 5\n",
    "solver = DOSolver(\n",
    "    domain_factory=lambda: rcpsp_domain,\n",
    "    method=SolvingMethod.CP if minizinc_available else None,\n",
    "    do_solver_type=CpSatRcpspSolver if not minizinc_available else None,\n",
    "    policy_method_params=PolicyMethodParams(\n",
    "        base_policy_method=BasePolicyMethod.FOLLOW_GANTT\n",
    "    ),\n",
    "    dict_params={\"parameters_cp\": p},\n",
    ")\n",
    "solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9533f-7eb6-4a56-8a61-28171aa0c327",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "episode = rollout(\n",
    "    domain=rcpsp_domain,\n",
    "    solver=solver,\n",
    "    verbose=False,\n",
    "    return_episodes=True,\n",
    "    num_episodes=1,\n",
    ")[0]\n",
    "states = episode[0]\n",
    "do_sol = from_last_state_to_solution(states[-1], rcpsp_domain)\n",
    "print(do_sol.problem.evaluate(do_sol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba457e-d03f-4d80-abae-d7cb128ed008",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nice animated schedule !\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "def plot_schedule(ax, state):\n",
    "    ax.clear()\n",
    "    ax.set_title(f\"Schedule at Time {state.t}\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Task ID\")\n",
    "    # Define colors for tasks\n",
    "    colors = plt.cm.tab10.colors\n",
    "    # Collect task IDs that are scheduled\n",
    "    scheduled_tasks = [\n",
    "        task_id\n",
    "        for task_id, task in state.tasks_full_details.items()\n",
    "        if task.start is not None\n",
    "    ]\n",
    "    # Plot each task as a rectangle\n",
    "    for idx, (task_id, task) in enumerate(state.tasks_full_details.items()):\n",
    "        if task.start is not None and task.end is not None:\n",
    "            rect = Rectangle(\n",
    "                (task.start, task_id - 0.4),\n",
    "                task.end - task.start,\n",
    "                0.8,\n",
    "                color=colors[idx % 10],\n",
    "                alpha=0.6,\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(\n",
    "                (task.start + task.end) / 2,\n",
    "                task_id,\n",
    "                f\"T{task_id}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"black\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "        if task.start is not None and task.end is None:\n",
    "            rect = Rectangle(\n",
    "                (task.start, task_id - 0.4),\n",
    "                state.t - task.start,\n",
    "                0.8,\n",
    "                color=colors[idx % 10],\n",
    "                alpha=0.6,\n",
    "                linestyle=\"dashed\",\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(\n",
    "                (task.start + state.t) / 2,\n",
    "                task_id,\n",
    "                f\"T{task_id}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"black\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "    # Plot the current time line\n",
    "    ax.axvline(state.t, color=\"r\", linestyle=\"--\", label=\"Current Time\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, max(state.t + 1, 10))\n",
    "    if scheduled_tasks:\n",
    "        ax.set_ylim(min(scheduled_tasks) - 1.5, max(scheduled_tasks) + 1.5)\n",
    "\n",
    "\n",
    "# Function to animate the plot\n",
    "def animate(i):\n",
    "    plot_schedule(ax, episode[0][i])\n",
    "\n",
    "\n",
    "# Create the animation\n",
    "fig, ax = plt.subplots()\n",
    "ani = FuncAnimation(fig, animate, frames=len(episode[0]), repeat=False)\n",
    "image_folder = os.path.join(os.getcwd(), \"images/\")\n",
    "if not os.path.exists(image_folder):\n",
    "    os.makedirs(image_folder)\n",
    "gif_path = os.path.join(image_folder, \"schedule_animation.gif\")\n",
    "ani.save(gif_path, writer=PillowWriter(fps=3))\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(open(\"./images/schedule_animation.gif\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21295c38-a3b6-4de2-855f-901cfb6aac2b",
   "metadata": {},
   "source": [
    "Here is an example of generated schedule:\n",
    "![generated-schedule](./images/schedule_animation_example.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05673d64-054b-428b-8735-a157db645366",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Hyperparameter optimisation\n",
    "Discrete Optimization solvers come with hyperparameters API opening the possibility to do hyperparam optimisation using the optuna library which is easily integrated to it.\n",
    "Hyperparams of solver can be for examples : \n",
    "- temperature, cooling factor for metaheuristics such as Simulated annealing\n",
    "- population size, mutation and crossover operators for genetic algorithms\n",
    "- solver backend or model variants for CP approaches etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c378197-af62-47c4-be2e-6ae5ee34fd15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from discrete_optimization.generic_rcpsp_tools.solvers.ls import LsGenericRcpspSolver\n",
    "from discrete_optimization.rcpsp.solvers.cp_mzn import CpRcpspSolver\n",
    "from discrete_optimization.rcpsp.solvers.ga import GaRcpspSolver\n",
    "\n",
    "print(\"CP Solver hyperparams\", CpRcpspSolver.hyperparameters, \"\\n\")\n",
    "print(\"LNS hyperparams : \", LsGenericRcpspSolver.hyperparameters, \"\\n\")\n",
    "print(\"Local search hyperparams : \", LsGenericRcpspSolver.hyperparameters, \"\\n\")\n",
    "print(\"Genetic algorithms hyperparams : \", GaRcpspSolver.hyperparameters, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77be39-e0ed-47db-9862-e759a32e1b94",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Script implementing the optuna study.\n",
    "from rcpsp_domains.multi_solve_optuna import run_optuna_multisolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb31de-ab23-444c-9841-55c462879eb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This takes several minutes.\n",
    "do_hyperparams = True\n",
    "if do_hyperparams:\n",
    "    run_optuna_multisolve(\n",
    "        rcpsp_domain, name_file_log=\"./rcpsp_domains/optuna_journal.log\"\n",
    "    )\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75953d-538b-44b6-91b0-b79ea1da6c7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Visualising optuna-dashboard\n",
    "One of the main advantage of optuna is to be able to visually analyse results in a dashboard app : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe656d-c986-434e-baea-983138288c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "on_colab = \"google.colab\" in str(get_ipython())  # running on colab?\n",
    "on_binder = socket.gethostname().startswith(\n",
    "    \"jupyter-\"\n",
    ")  # running on binder? (not 100% sure but rather robust)\n",
    "\n",
    "\n",
    "def start_optuna_dashboard(\n",
    "    port=1234, storage: str = \"rcpsp_domains/optuna_journal.log\"\n",
    "):\n",
    "    import threading\n",
    "    import time\n",
    "    from wsgiref.simple_server import make_server\n",
    "\n",
    "    from optuna_dashboard import wsgi\n",
    "\n",
    "    app = wsgi(storage)\n",
    "    httpd = make_server(\"localhost\", port, app)\n",
    "    thread = threading.Thread(target=httpd.serve_forever)\n",
    "    thread.start()\n",
    "    time.sleep(3)  # Wait until the server startup\n",
    "    return port\n",
    "\n",
    "\n",
    "if on_colab:\n",
    "    port = start_optuna_dashboard()\n",
    "    from google.colab import output\n",
    "\n",
    "    print(\"Visit optuna-dashboard on:\")\n",
    "    output.serve_kernel_port_as_window(port, path=\"/dashboard/\")\n",
    "\n",
    "elif on_binder:\n",
    "    print(\"Not yet working on binder...\")\n",
    "else:\n",
    "    try:\n",
    "        import optuna_dashboard  # nopycln: import\n",
    "    except ImportError:\n",
    "        !pip install optuna-dashboard\n",
    "    port = start_optuna_dashboard()\n",
    "    print(f\"Visit optuna-dashboard on http://localhost:{port}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4709c2-97b0-4335-9018-304c99cc92b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Reinforcement learning\n",
    "As additional (ongoing) works, we introduce new domains for specific scheduling problems, more adapted for reinforcement learning solvers to be run on.\n",
    "Those implementation are scheduling-variant specific, the one we will look is the RCPSP domain again. The environment is vectorized contrary to the generic scheduling domain of scikit-decide.\n",
    "\n",
    "- states are ($nb_{task}$, 2) shape array, where for each task we store in states[i, 0] the binary value corresponding if the task has been scheduled or not, and in states[i,1] the starting time\n",
    "- action are index of task to schedule next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18df130-030c-4a2a-bd19-514c84033737",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from discrete_optimization.rcpsp.parser import get_data_available, parse_file\n",
    "from rcpsp_domains.rcpsp_sk_domain import ParamsDomainEncoding, RCPSPSGSDomain\n",
    "\n",
    "file = [f for f in get_data_available() if \"j301_1.sm\" in f][0]\n",
    "model: RcpspProblem = parse_file(file)\n",
    "domain_sk = RCPSPSGSDomain(\n",
    "    model,\n",
    "    params_domain_encoding=ParamsDomainEncoding(\n",
    "        return_times_in_state=True,\n",
    "        return_scheduled_in_state=True,\n",
    "        use_cpm_for_cost=False,\n",
    "        terminate_when_already_schedule=False,\n",
    "        dummy_cost_when_already_schedule=30,\n",
    "        use_additive_makespan_for_cost=True,\n",
    "        nb_min_task_inserted=8,\n",
    "        nb_max_task_inserted=25,\n",
    "        filter_tasks=True,\n",
    "        only_available_tasks=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d80fb-bbf7-4343-a332-6fbae6b5367d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some utils functions\n",
    "def run_rollout(domain, solver=None, nb_rollout=100):\n",
    "    makespans = []\n",
    "    for i in range(1000):\n",
    "        episodes = rollout(\n",
    "            domain=domain,\n",
    "            solver=solver,\n",
    "            verbose=False,\n",
    "            num_episodes=1,\n",
    "            return_episodes=True,\n",
    "        )\n",
    "        if domain.state[-1, 0]:\n",
    "            solution_rcpsp = RcpspSolution(\n",
    "                problem=model,\n",
    "                rcpsp_schedule={\n",
    "                    t: {\n",
    "                        \"start_time\": domain.state[domain.task_to_index[t], 1],\n",
    "                        \"end_time\": domain.state[domain.task_to_index[t], 1]\n",
    "                        + domain.dur[domain.task_to_index[t]],\n",
    "                    }\n",
    "                    for t in model.tasks_list\n",
    "                },\n",
    "            )\n",
    "            # print(model.evaluate(solution_rcpsp), model.satisfy(solution_rcpsp))\n",
    "            makespans.append(domain_sk.state[-1, 1])\n",
    "    return makespans\n",
    "\n",
    "\n",
    "def compute_statistics(arr):\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array\")\n",
    "    statistics = {\n",
    "        \"mean\": np.mean(arr),\n",
    "        \"median\": np.median(arr),\n",
    "        \"min\": np.min(arr),\n",
    "        \"max\": np.max(arr),\n",
    "        \"25th percentile\": np.percentile(arr, 25),\n",
    "        \"50th percentile\": np.percentile(arr, 50),\n",
    "        \"75th percentile\": np.percentile(arr, 75),\n",
    "    }\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ca97a-8e3a-4ad5-aadd-f7e65f91e567",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Random rollouts\n",
    "Let's run random rollout on this domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b61ed-c547-4149-aec9-a2a9e67f00f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "makespans_random = run_rollout(domain_sk, solver=None, nb_rollout=100)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb96a8-491a-45c2-ac5f-fde84846bdd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats = compute_statistics(np.array(makespans_random))\n",
    "print(\"Stats with random policy \", stats)\n",
    "sns.displot(makespans_random, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10f622-6e81-4886-b69a-b15d086d1edf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Few words on RL solvers\n",
    "In the next section we will test mainly 3 RL solvers, briefly explained here :\n",
    "\n",
    "#### Proximal Policy Optimization (PPO)\n",
    "- **Type**: Policy-based method.\n",
    "- **Mechanism**: Utilizes a clipped surrogate objective to update policies, balancing exploration and exploitation.\n",
    "- **Advantages**: \n",
    "  - More stable and reliable training compared to earlier policy gradient methods.\n",
    "  - Suitable for both discrete and continuous action spaces.\n",
    "- **Usage**: Popular in many reinforcement learning applications, including robotics and games.\n",
    "\n",
    "#### Advantage Actor-Critic (A2C)\n",
    "- **Type**: Actor-Critic method.\n",
    "- **Mechanism**: Combines value-based and policy-based methods, using an actor to decide actions and a critic to evaluate them.\n",
    "- **Advantages**: \n",
    "  - Efficient and relatively easy to implement.\n",
    "  - Good balance between bias and variance, leading to more stable learning.\n",
    "- **Usage**: Effective for various control problems and environments with continuous action spaces.\n",
    "\n",
    "#### Deep Q-Network (DQN)\n",
    "- **Type**: Value-based method.\n",
    "- **Mechanism**: Uses deep neural networks to approximate the Q-value function, enabling handling of high-dimensional state spaces.\n",
    "- **Advantages**: \n",
    "  - Demonstrated success in complex environments like Atari games.\n",
    "  - Employs techniques like experience replay and target networks for stable training.\n",
    "- **Usage**: Ideal for problems with discrete action spaces and where the state-action space can be effectively represented with deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7b4bb-a350-4aef-8005-4adae2f79ca9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Solving the domain using stable baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc80214-da5d-4143-bb78-8272a497df63",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Special notice for binder + sb3:</b>\n",
    "it seems that <a href=https://stable-baselines3.readthedocs.io/en/master/>stable-baselines3</a> algorithms are <em>extremely slow</em> on <a href=https://mybinder.org/>binder</a>. We could not find a proper explanation about it. We strongly advise you to either launch the notebook locally or on colab, or to skip the cells that are using sb3 algorithms.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab96c6-d051-4277-8e0f-f1c5bd5419b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rcpsp_domains.rcpsp_sk_domain import RCPSPSGSDomain, records\n",
    "from stable_baselines3 import A2C, DQN\n",
    "\n",
    "# Here you can play with the core algorithm to be used. Empirically A2C works the best !\n",
    "algo = A2C\n",
    "\n",
    "records.clear()\n",
    "domain_sk = RCPSPSGSDomain(\n",
    "    model,\n",
    "    params_domain_encoding=ParamsDomainEncoding(\n",
    "        return_times_in_state=True,\n",
    "        return_scheduled_in_state=True,\n",
    "        use_cpm_for_cost=True,\n",
    "        terminate_when_already_schedule=False,\n",
    "        dummy_cost_when_already_schedule=1,\n",
    "        use_additive_makespan_for_cost=False,\n",
    "        nb_min_task_inserted=1,\n",
    "        nb_max_task_inserted=None,\n",
    "        filter_tasks=False,\n",
    "        only_available_tasks=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "solver_args = {\n",
    "    \"baselines_policy\": \"MlpPolicy\",\n",
    "    \"learn_config\": {\"total_timesteps\": 30000},\n",
    "    \"verbose\": 0,\n",
    "    \"n_steps\": 300,\n",
    "    # \"batch_size\": 100\n",
    "}\n",
    "solver_args.update(\n",
    "    {\n",
    "        \"policy_kwargs\": dict(\n",
    "            net_arch=[dict(pi=[256, 256, 128, 128], vf=[256, 256, 128, 128])]\n",
    "        )\n",
    "    }\n",
    ")\n",
    "solver_args[\"algo_class\"] = algo\n",
    "solver = StableBaseline(domain_factory=lambda: domain_sk, **solver_args)\n",
    "solver.solve()\n",
    "makespans_sb = run_rollout(domain_sk, solver=solver, nb_rollout=100)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a503c4e-16c1-44a6-a572-ae1d45579322",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "records_sb = np.array(records)\n",
    "ax.plot(np.convolve(records_sb, np.ones(30) / 30, mode=\"valid\"))\n",
    "ax.set_title(f\"quality of rollout through time, {algo.__name__}\")\n",
    "sns.displot(makespans_sb, bins=20)\n",
    "print(f\"Stats with {algo.__name__}\", compute_statistics(np.array(makespans_sb)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b1c35-7350-42b7-a790-6574a29677fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### DQN With RLLIB\n",
    "Wrappers of RLLib implemented in scikit-decide hub can have the advantage of taking into account **filtered actions**, that is a usual pain point in Reinforcement learning. \\\n",
    "Using this solver will use the fact that available actions at a given state should only be task that are not yet scheduled. \\\n",
    "[Note : To the contrary, other solvers we tested were discarding these filtered action, therefore the implementation was handling useless action by putting some penalty cost on the transition]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438f20f-085b-45cb-9ba0-60777eb019fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.dqn import DQN\n",
    "from rcpsp_domains.rcpsp_sk_domain import RCPSPSGSDomain, records\n",
    "\n",
    "records.clear()\n",
    "from skdecide.hub.solver.ray_rllib import RayRLlib\n",
    "\n",
    "algo = DQN\n",
    "domain_sk = RCPSPSGSDomain(\n",
    "    model,\n",
    "    params_domain_encoding=ParamsDomainEncoding(\n",
    "        return_times_in_state=False,\n",
    "        return_scheduled_in_state=True,\n",
    "        use_cpm_for_cost=True,\n",
    "        terminate_when_already_schedule=False,\n",
    "        dummy_cost_when_already_schedule=30,\n",
    "        use_additive_makespan_for_cost=False,\n",
    "        nb_min_task_inserted=None,\n",
    "        nb_max_task_inserted=25,\n",
    "        filter_tasks=True,\n",
    "        only_available_tasks=False,\n",
    "    ),\n",
    ")\n",
    "ac = algo.get_default_config()\n",
    "ac.lr = 5e-3\n",
    "solver = RayRLlib(\n",
    "    domain_factory=lambda: domain_sk.shallow_copy(),\n",
    "    algo_class=algo,\n",
    "    config=ac,\n",
    "    train_iterations=10,\n",
    ")\n",
    "assert RayRLlib.check_domain(domain_sk)\n",
    "solver.solve()\n",
    "makespan_rllib = run_rollout(domain_sk, solver=solver, nb_rollout=100)\n",
    "records_rllib = np.array(records)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce2de4-25ce-44a2-ae08-a6dde6cb652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "records_rllib = np.array(records)\n",
    "ax.plot(np.convolve(records_rllib, np.ones(30) / 30, mode=\"valid\"))\n",
    "ax.set_title(f\"quality of rollout through time, Rllib {algo.__name__}\")\n",
    "sns.displot(makespan_rllib, bins=20)\n",
    "print(f\"Stats with {algo.__name__}\", compute_statistics(np.array(makespan_rllib)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b441df6-4de0-49e6-937e-74257593fbe1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Bonus words on RL\n",
    "\n",
    "#### Stochastic RCPSP : \n",
    "RL is particularly suited for stochastic domains, ```StochasticRCPSPSGSDomain``` is a stochastic domain where duration are sampled from a distribution. \\\n",
    "The state space is : \n",
    "-an array of shape ($nb_{tasks}$, 3), where we store the fact that a task is scheduled, along with start and sampled end times. \\\n",
    "RL algorithms can be experimented on this domain (implemented in ```rcpsp_domains.stochastic_rcpsp_sk_domain``` module)\n",
    "\n",
    "#### Local search domain for RCPSP : \n",
    "An alternative domain implementation for RCPSP is to consider local moves/mutation of the schedules as the available actions for a RL domain. \\\n",
    "In our playground implementation, actions are local moves consisting in reverting a subpart of the permutation of tasks representing the solution. This is similar to the [2-opt](https://en.wikipedia.org/wiki/2-opt) mutation for traveling salesman problem.\\\n",
    "Implemented in ```rcpsp_domains.rcpsp_sk_domain_local_search```.\n",
    "\n",
    "#### Direct permutation optimisation :\n",
    "We can also use RL to optimize directly the full permutation, the actions here are a $nb_{tasks}$ floating or integer array. [We use np.argsort to compute a permutation of task that is then used to build an rcpsp solution]\\\n",
    "Implemented in ```rcpsp_domains.rcpsp_sk_domain_local_search```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9623aeb0-9511-49c7-9abd-682fcb466d2a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial you've been introduced to : \n",
    "- the scheduling API of scikit-decide\n",
    "- its automatic implementation of scheduling domain from simple data definition of scheduling problem\n",
    "- use of scikit-decide solver (planning, discrete optimization, RL) to solve scheduling problems\n",
    "- discrete optimization library easing the implementation of mathematical programming, metaheuristic solver and hyperparameter optimisation.\n",
    "\n",
    "The RL works is notably open to more research with inclusion of GNN like [wheatley](https://github.com/jolibrain/wheatley) or more efficient RL formulation [Jumanji](https://github.com/instadeepai/jumanji)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
