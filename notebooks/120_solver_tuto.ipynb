{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2ffe6d-84bf-4869-9de8-7131c84910b7",
   "metadata": {},
   "source": [
    "# How to write a new scikit-decide solver: depth-first search\n",
    "\n",
    "In this tutorial, we detail how to implement a new scikit-decide solver.\n",
    "To keep it simple, we choose to implement a simple depth-first search, that stops whenever a goal is found.\n",
    "We will apply it to the maze domain.\n",
    "\n",
    "Defining a solver is a matter of:\n",
    "- defining the characteristics from the domain needed by the solver\n",
    "- selecting the necessary solver characteristics\n",
    "- auto-generating the code skeleton from the combination above (with all abstract methods needed)\n",
    "- filling the code as needed\n",
    "\n",
    "The first steps can be accomplished via the [code generator](https://airbus.github.io/scikit-decide/codegen/) available in the scikit-decide online documentation.\n",
    "The last step is where you really need to type something (namely the solver logics).\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Disclaimer:** \n",
    "The chosen solver is a simple one, used only to showcase *in a pedagogical way* how to implement a new scikit-decide solver.\n",
    "It is not adapted to large domain. \n",
    "For a more realistic solver, one could use for instance a [greedy best-first search](https://en.wikipedia.org/wiki/Best-first_search)\n",
    "that uses an heuristic to guide the search. Or use one of the solvers available in scikit-decide hub as [A*](https://airbus.github.io/scikit-decide/reference/_skdecide.hub.solver.astar.astar.html#astar), as presented in the [tutorial dedicated to the maze domain](https://colab.research.google.com/github/airbus/scikit-decide/blob/master/notebooks/11_domain_tuto.ipynb).\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4771e9-042b-4ac4-a37a-c73e5b60f44d",
   "metadata": {},
   "source": [
    "Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0349ee3-2503-4965-a697-93d24803af20",
   "metadata": {},
   "source": [
    "## Define the characteristics from the domain needed by the solver\n",
    "\n",
    "\n",
    "We want to specify the domains that will be compatible with the solver. \n",
    "To achieve it, we select the most generic characteristics that the solver can handle.\n",
    "\n",
    "In our case, we want a domain with\n",
    "- deterministic transitions\n",
    "- deterministic initial state\n",
    "- fully observable\n",
    "- markovian\n",
    "- single agent\n",
    "- enumerable actions\n",
    "\n",
    "It can be achieved with the template `DeterministicPlanningDomain` except for the condition \"enumerable actions\".\n",
    "For the latter, we will see how to enforce it via a specific method during the implementation.\n",
    "\n",
    "*Translation on [code generators](https://airbus.github.io/scikit-decide/codegen/) page:*\n",
    "\n",
    "- Click on \"Edit\" in \"Domain specification\"\n",
    "\n",
    "<img src=\"./solver-tuto/code-generator-solver-1.png\" style=\"height:15em;\">\n",
    "\n",
    "- Choose the template `DeterministicPlanningDomain`\n",
    "\n",
    "<img src=\"./solver-tuto/code-generator-solver-2.png\" style=\"height:25em;\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176659e3-2e60-4e78-8990-d3d52b19a88e",
   "metadata": {},
   "source": [
    "## Select the solver characteristics\n",
    "\n",
    "Our solver will be deterministic so we can choose the `DeterministicPolicySolver` template. \n",
    "As the depth-first search can be launched a priori from any state of the domain, so we can also add the characteristic `FromAnyState`.\n",
    "\n",
    "Note that we could also make the solver restorable by implementing a save/load of the graph traversal. In that case we should add the `Restorable` characteristic.\n",
    "To keep things simple we do not here.\n",
    "\n",
    "\n",
    "*Translation on [code generators](https://airbus.github.io/scikit-decide/codegen/) page:*\n",
    "\n",
    "- Toggle the button  \"Create Solver\".\n",
    "\n",
    "<img src=\"./solver-tuto/code-generator-solver-3.png\" style=\"height:15em;\">\n",
    "\n",
    "- Click on \"Edit\" in \"Solver specification\"\n",
    "- Choose the template `DeterministicPolicySolver`\n",
    "- Update it by clicking on `FromAnyState`\n",
    "\n",
    "<img src=\"./solver-tuto/code-generator-solver-4.png\" style=\"height:25em;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df3436ad-df99-4d56-9c2d-31c586ac569d",
   "metadata": {},
   "source": [
    "## Generate the skeleton\n",
    "\n",
    "We just have to click on the \"Copy code\" button and paste it:\n",
    "\n",
    "```python\n",
    "\n",
    "from typing import *\n",
    "\n",
    "from skdecide import *\n",
    "from skdecide.builders.domain import *\n",
    "from skdecide.builders.solver import *\n",
    "\n",
    "\n",
    "class D(DeterministicPlanningDomain):\n",
    "    pass\n",
    "\n",
    "\n",
    "class MySolver(DeterministicPolicySolver, FromAnyState):\n",
    "    T_domain = D\n",
    "\n",
    "    \n",
    "    def _solve_from(self, memory: D.T_state) -> None:\n",
    "        pass\n",
    "    \n",
    "    def _get_next_action(self, observation: D.T_observation) -> D.T_event:\n",
    "        pass\n",
    "    \n",
    "    def _is_policy_defined_for(self, observation: D.T_observation) -> bool:\n",
    "        pass\n",
    "    \n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea300f-8634-44a2-8e0c-9f2b108d82ba",
   "metadata": {},
   "source": [
    "As we want to enforce an enumerable action space for the domain, we also add to the skeleton the method `_check_domain_additional()`:\n",
    "```python\n",
    "    @classmethod\n",
    "    def _check_domain_additional(cls, domain: Domain) -> bool:\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478559c0-fafc-4d54-a560-c12b9a47e626",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note:**\n",
    "\n",
    "In scikit-decide, the methods to implement by a domain or solver developper are prefixed with `_`. \n",
    "On the contrary the user of a domain or a solver should call the methods not prefixed by `_`. \n",
    "\n",
    "For instance:\n",
    "\n",
    "- As a solver *developper*, we *implement* `_solve_from()`.\n",
    "- As a solver *user*, we *call* `solve()`, as we will see later.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f8d46-4410-492f-84b4-843b66dc36b1",
   "metadata": {},
   "source": [
    "## Implement the solver\n",
    "\n",
    "Now the real work is starting.\n",
    "\n",
    "The depth-first search algorithm is quite simple. We see the possible states of the domain as nodes of a graph, \n",
    "edges corresponding to the different possible actions possible. \n",
    "Starting from the given state, we perform a depth-first search that stops when reaching a goal.\n",
    "\n",
    "More precisely, we apply successively the first available action to the domain until \n",
    "- reaching a goal: in that case we stop the search (no optimization of the cost),\n",
    "- reaching a dead-end: in that case we roll-back to the previous state and choose the next available action,\n",
    "- exhausting the actions available at the current state: we roll-back to the previous state and choose the next available action,\n",
    "- not being able to roll-back (when exhausting available actions from initial state).\n",
    "\n",
    "Some remarks:\n",
    "- We specify a max depth to avoid a too long computation for large domains.\n",
    "- We store the graph traversal history to avoid recomputing it each time the solver is asked to sample an action.\n",
    "- We also need to implement an `__init__()` method. We make sure to call the constructor of the base class `Solver` which\n",
    "  takes a domain factory as an argument and cast it to the specified level of characteristics. The cast domain factory is available in   `self.domain_factory`.\n",
    "- As the domain is fully observable, observation and state are the same thing.\n",
    "- **Disclaimer:** This is a simple version not using any heuristic and thus not optimizing in any way the cost. We only try to reach a goal.\n",
    "  Of course, as we blindly traverse the graph, it can be very long to solve and should be used only on small domains.\n",
    "  But it fills the purpose of showcasing the implementation of a new solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119e612-6329-4079-9f43-00099f974315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "from skdecide import *\n",
    "from skdecide.builders.domain import *\n",
    "from skdecide.builders.solver import *\n",
    "\n",
    "\n",
    "class D(DeterministicPlanningDomain):\n",
    "    pass\n",
    "\n",
    "\n",
    "class DFSSolver(DeterministicPolicySolver, FromAnyState):\n",
    "    \"\"\"Depth-first search solver.\n",
    "\n",
    "    The considered oriented graph is:\n",
    "     - nodes: domain states\n",
    "     - edges: domain actions linking a state to the resulting state when the action is applied\n",
    "\n",
    "    We perform a DFS of this graph and stop whenever a goal or a max depth is reached.\n",
    "\n",
    "    The traversal is made from a given point and the resulting plan is stored as a policy mapping a state to the next action.\n",
    "    Whenever the solver is asked for a new action, either this is from a state in the computed policy, or a new solve is done from that new state.\n",
    "\n",
    "    Args:\n",
    "        max_depth: maximal depth for the DFS\n",
    "        render_during_solve: for pedagogical purposes, it can be nice to see the traversal performed\n",
    "            during the solving process. This flag enables it, if the domain is renderable.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    T_domain = D\n",
    "\n",
    "    @classmethod\n",
    "    def _check_domain_additional(cls, domain: Domain) -> bool:\n",
    "        \"\"\"Check that the domain as enumerable space of action.\"\"\"\n",
    "        return isinstance(domain.get_action_space(), EnumerableSpace)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        domain_factory: Callable[[], Domain],\n",
    "        max_depth: int = 1000,\n",
    "        render_during_solve: bool = False,\n",
    "    ):\n",
    "        \"\"\"Constructor.\"\"\"\n",
    "        super().__init__(domain_factory)\n",
    "        self.max_depth = max_depth\n",
    "        self.render_during_solve = render_during_solve\n",
    "        # initialize the policy\n",
    "        self.policy: dict[D.T_observation, D.T_agent] = {}\n",
    "        # initialize a domain to test actions\n",
    "        self.domain: DeterministicPlanningDomain = self.domain_factory()\n",
    "\n",
    "    def _solve_from(self, memory: D.T_state) -> None:\n",
    "        \"\"\"Solve from the given state.\n",
    "\n",
    "        Launch the DFS with the state as root node.\n",
    "\n",
    "        \"\"\"\n",
    "        self.current_state = memory\n",
    "        goal_reached = self.domain.is_goal(self.current_state)\n",
    "        queue = self._get_state_n_applicable_actions_as_a_list(self.current_state)\n",
    "        visited_states = {self.current_state}\n",
    "        current_plan = []\n",
    "        # DFS loop\n",
    "        while (\n",
    "            not goal_reached and len(queue) > 0 and len(current_plan) < self.max_depth\n",
    "        ):\n",
    "            state, action = queue.pop()\n",
    "            # rollback the plan if needed (if a dead-end was reached)\n",
    "            while state != self.current_state:\n",
    "                self.current_state, _ = current_plan.pop()\n",
    "\n",
    "            # update the plan with the new action to test\n",
    "            current_plan.append((state, action))\n",
    "            # apply\n",
    "            self.current_state = self.domain.get_next_state(state, action)\n",
    "            # check if we reach an already visited state (in case of loops in the graph)\n",
    "            if self.current_state in visited_states:\n",
    "                # drop the move\n",
    "                current_plan.pop()\n",
    "                self.current_state = state\n",
    "            else:\n",
    "                visited_states.add(self.current_state)\n",
    "                # check if we reach\n",
    "                #  - a goal\n",
    "                #  - a state from which we know already a policy from a previous call to `solve()`\n",
    "                if self.domain.is_goal(self.current_state):\n",
    "                    # bingo\n",
    "                    goal_reached = True\n",
    "                elif self.current_state in self.policy:\n",
    "                    # from here the previously computed policy get to the goal: bingo\n",
    "                    goal_reached = True\n",
    "                else:\n",
    "                    # goal not yet reached: we add applicable actions from next state\n",
    "                    # NB: if we are in a deadend, nothing will be added, so next tested action will be from a previous state\n",
    "                    queue.extend(\n",
    "                        self._get_state_n_applicable_actions_as_a_list(\n",
    "                            self.current_state\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        # Check stop reason\n",
    "        if goal_reached:\n",
    "            # add computed plan to the policy (update only to keep track of previous call to `solve()`)\n",
    "            self.policy.update(current_plan)\n",
    "        else:\n",
    "            # solve fails => raise error\n",
    "            if len(current_plan) >= self.max_depth:\n",
    "                # due to max_depth\n",
    "                raise RuntimeError(\n",
    "                    \"The solver was unable to find a solution within the given max depth.\"\n",
    "                )\n",
    "            else:\n",
    "                # no valid path exists\n",
    "                raise RuntimeError(\n",
    "                    \"The solver was trapped in a deadend. The domain has no solution from the given initial state.\"\n",
    "                )\n",
    "\n",
    "    def _get_next_action(self, observation: D.T_observation) -> D.T_event:\n",
    "        \"\"\"Choose the next action according to the computed policy.\n",
    "\n",
    "        If the state has not yet been visited, solve from this state.\n",
    "\n",
    "        \"\"\"\n",
    "        if observation not in self.policy:\n",
    "            self._solve_from(observation)\n",
    "        return self.policy[observation]\n",
    "\n",
    "    def _is_policy_defined_for(self, observation: D.T_observation) -> bool:\n",
    "        \"\"\"Tell whether the state (=observation as fully observable) is in the policy.\"\"\"\n",
    "        return observation in self.policy\n",
    "\n",
    "    def _get_state_n_applicable_actions_as_a_list(\n",
    "        self, state: D.T_state\n",
    "    ) -> list[tuple[D.T_state, D.T_event]]:\n",
    "        \"\"\"Get applicable actions and make a list of (state, action) with it.\"\"\"\n",
    "        applicable_actions_space = self.domain.get_applicable_actions(state)\n",
    "        action_space: EnumerableSpace = self.domain.get_action_space()\n",
    "        return [\n",
    "            (state, action)\n",
    "            for action in action_space.get_elements()\n",
    "            if action in applicable_actions_space\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def current_state(self) -> D.T_state:\n",
    "        \"\"\"Current state/node in DFS.\"\"\"\n",
    "        return self._current_state\n",
    "\n",
    "    @current_state.setter\n",
    "    def current_state(self, state: D.T_state) -> None:\n",
    "        \"\"\"Setter for current state in DFS.\n",
    "\n",
    "        Useful to render current_state each time it is moving during the solving process.\n",
    "\n",
    "        \"\"\"\n",
    "        self._current_state = state\n",
    "        if self.render_during_solve and isinstance(self.domain, Renderable):\n",
    "            self.domain.render(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d0cc3-ad63-4f1c-b1fc-e4cc937105d9",
   "metadata": {},
   "source": [
    "## Test the solver on the maze domain\n",
    "\n",
    "We use the maze domain from the scikit-decide hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72930475-1e68-4adf-b6ef-1890817ae2e7",
   "metadata": {},
   "source": [
    "We first define a domain factory to be feed to the solver and make sure to use the option allowing an inline display in a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28cf1d0-3bf6-4584-907c-a81e060d7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skdecide.hub.domain.maze import Maze\n",
    "\n",
    "domain_factory = lambda: Maze(display_in_jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6b225-88c2-41c7-8ccc-6787d33e6e75",
   "metadata": {},
   "source": [
    "Now the new solver should be compatible with the maze domain. Let us check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e428213-c9bf-46a8-836d-15e70b53ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = domain_factory()\n",
    "assert DFSSolver.check_domain(domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f141d-6dbd-4033-a536-a447574a1d60",
   "metadata": {},
   "source": [
    "We need a state from which starting the maze, we can take the initial state returned by the `reset()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53809789-7636-4145-abad-1c25e9fba8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = domain.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c8e2a-df41-4b93-ac28-9ed3c87d13c2",
   "metadata": {},
   "source": [
    "Now we can solve and rollout from this state. We use the option `render_during_solve` to display the live DFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f98979-dc06-445f-81be-1d519acc8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DFSSolver(\n",
    "    domain_factory=domain_factory, max_depth=100, render_during_solve=True\n",
    ") as solver:\n",
    "    solver.solve(from_memory=state)\n",
    "    episodes = rollout(\n",
    "        domain=domain, solver=solver, render=True, verbose=False, return_episodes=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
