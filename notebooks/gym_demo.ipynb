{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Gym environment demo: Continuous Mountain Car\n",
    "\n",
    "In this notebook we will solve the continuous mountain car problem taken from [OpenAI Gym](https://gym.openai.com/), a toolkit for developing environments, usually to be solved by reinforcement learning algorithms.\n",
    "Continuous Mountain Car, a standard testing domain in Reinforcement Learning (RL), is a problem in which an under-powered car must drive up a steep hill. Note that we use here the *continuous* version of the mountain car because \n",
    "it has a shaped reward (i.e.not sparse) which can be used successfully when solving, as opposed to the other \"Mountain Car\" environments. ***Citation needed about what is a shaped/sparse reward***\n",
    "\n",
    "\n",
    "This problem has been chosen for three reasons:\n",
    "  - Show how scikit-decide can be used to solve Gym environments (the de-facto standard in the RL community),\n",
    "  - Highlight that by doing so, you will be able to use not only solvers from the RL community (like the ones in StableBaselines3 for example), but also other solvers coming from other communities like genetic programming and planning/search (use of an underlying search graph) that can sometimes be very efficient.\n",
    "  - We use the \"continuous\" version of the mountain car because \n",
    "\n",
    "Therefore in this notebook we will go through the following steps:\n",
    "  - Wrap a Gym environment in a scikit-decide domain;\n",
    "  - Use a classical RL algorithm like PPO to solve our problem;\n",
    "  - Give CGP (Cartesian Genetic Programming)  a try on the same problem;\n",
    "  - Finally use IW (Iterated Width) coming from the planning community on the same problem.\n",
    "\n",
    "We will conclude the notebook by an analysis of the 3 solvers.\n",
    "\n",
    "\n",
    "**For local Jupyter users:** you will need to install [`ffmpeg`](https://www.ffmpeg.org/) before running this notebook as the solutions are showed as mp4 movies thanks to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import NamedTuple, Optional, Any, List, Callable\n",
    "from copy import deepcopy\n",
    "from time import sleep\n",
    "from collections import deque\n",
    "import random\n",
    "from math import sqrt, ceil\n",
    "from base64 import b64encode\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "import gym\n",
    "\n",
    "from skdecide.hub.solver.stable_baselines import StableBaseline\n",
    "from skdecide import DeterministicPlanningDomain, Space, Value\n",
    "from skdecide.hub.domain.gym import GymDomain, GymWidthDomain, GymDiscreteActionDomain, GymPlanningDomain\n",
    "from skdecide.builders.domain import UnrestrictedActions, Renderable\n",
    "from skdecide.utils import rollout, match_solvers, load_registered_solver\n",
    "from skdecide.hub.space.gym import ListSpace, EnumSpace, MultiDiscreteSpace\n",
    "from skdecide.hub.solver.iw import IW\n",
    "from skdecide.hub.solver.cgp import CGP  # Cartesian Genetic Programming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running this notebook on remote servers like with Colab or Binder, rendering of gym environment will fail as no actual display device exists. Thus we need to start a virtual display to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DISPLAY\" not in os.environ:\n",
    "    import pyvirtualdisplay\n",
    "    _display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
    "    _display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Add an explanation of this gym environment: goal, actions available, ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the gym environment we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'MountainCarContinuous-v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a domain factory using `GymDomain` proxy available in scikit-decide, for solving purpose.\n",
    "And another domain factory using a `gym.wrapper.Monitor` for rolling-out to record movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_factory = lambda: GymDomain(gym.make(ENV_NAME))\n",
    "domain4movie_factory = lambda: GymDomain(gym.wrappers.Monitor(gym.make(ENV_NAME), \"tmp_gym_recording\", force=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a screenshot of such an environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = domain_factory()\n",
    "domain.reset()\n",
    "plt.imshow(domain.render(mode=\"rgb_array\"))\n",
    "plt.axis(\"off\")\n",
    "domain.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve & Play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Reinforcement Learning (StableBaseline)\n",
    "*Small text describing the algo needed*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the compatibility of the domain with the chosen solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain = domain_factory()\n",
    "assert StableBaseline.check_domain(domain)\n",
    "domain.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a solver factory (class to use with default arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_factory = lambda: StableBaseline(PPO, 'MlpPolicy', learn_config={'total_timesteps': 50000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve and play the solution using a monitor wrapper to get a movie. The statement `with` ensure that the solver is properly cleaned after use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with solver_factory() as solver:\n",
    "    # solve\n",
    "    GymDomain.solve_with(solver, domain_factory)\n",
    "    # create a domain wrapped in a monitor for recording during rollout\n",
    "    domain4movie = domain4movie_factory()\n",
    "    # rollout\n",
    "    try:\n",
    "        rollout(domain4movie, solver, num_episodes=1, max_steps=1000, max_framerate=None, outcome_formatter=None)\n",
    "    finally:\n",
    "        domain4movie.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display recorded movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videofilename = glob.glob(\"tmp_gym_recording/openaigym.video.*.video000000.mp4\")[0]\n",
    "with open(videofilename,'rb') as mp4:\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4.read()).decode()\n",
    "display(HTML(f\"<video alt='solution movie' controls autoplay preload'><source src='{data_url}' type='video/mp4'></video>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Cartesian Genetic Programming (CGP)\n",
    "*Small text describing the algo needed*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the compatibility of the domain with the chosen solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = domain_factory()\n",
    "assert StableBaseline.check_domain(domain)\n",
    "domain.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a solver factory (class to use with default arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_factory = lambda: CGP('TEMP_CGP', n_it=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve and play the solution using a monitor wrapper to get a movie. The statement `with` ensure that the solver is properly cleaned after use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with solver_factory() as solver:\n",
    "    # solve\n",
    "    GymDomain.solve_with(solver, domain_factory)\n",
    "    # create a domain wrapped in a monitor for recording during rollout\n",
    "    domain4movie = domain4movie_factory()\n",
    "    # rollout\n",
    "    try:\n",
    "        rollout(domain4movie, solver, num_episodes=1, max_steps=1000, max_framerate=None, outcome_formatter=None)\n",
    "    finally:\n",
    "        domain4movie.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display recorded movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videofilename = glob.glob(\"tmp_gym_recording/openaigym.video.*.video000000.mp4\")[0]\n",
    "with open(videofilename,'rb') as mp4:\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4.read()).decode()\n",
    "display(HTML(f\"<video alt='solution movie' controls autoplay preload'><source src='{data_url}' type='video/mp4'></video>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Classical Planning  (IW)\n",
    "*Small text describing the algo needed*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to further wraps the domain so that IW can be used on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(GymPlanningDomain, GymWidthDomain, GymDiscreteActionDomain):\n",
    "    pass\n",
    "\n",
    "\n",
    "class GymDomainForWidthSolvers(D):\n",
    "    def __init__(self, gym_env: gym.Env,\n",
    "                 set_state: Callable[[gym.Env, D.T_memory[D.T_state]], None] = None,\n",
    "                 get_state: Callable[[gym.Env], D.T_memory[D.T_state]] = None,\n",
    "                 termination_is_goal: bool = True,\n",
    "                 continuous_feature_fidelity: int = 5,\n",
    "                 discretization_factor: int = 3,\n",
    "                 branching_factor: int = None,\n",
    "                 max_depth: int = 1000) -> None:\n",
    "        GymPlanningDomain.__init__(self,\n",
    "                                   gym_env=gym_env,\n",
    "                                   set_state=set_state,\n",
    "                                   get_state=get_state,\n",
    "                                   termination_is_goal=termination_is_goal,\n",
    "                                   max_depth=max_depth)\n",
    "        GymDiscreteActionDomain.__init__(self,\n",
    "                                         discretization_factor=discretization_factor,\n",
    "                                         branching_factor=branching_factor)\n",
    "        GymWidthDomain.__init__(self, continuous_feature_fidelity=continuous_feature_fidelity)\n",
    "        gym_env._max_episode_steps = max_depth\n",
    "    \n",
    "    def state_features(self, s):\n",
    "        return self.bee2_features(s)\n",
    "    \n",
    "    def heuristic(self, s):\n",
    "        return Value(cost=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We redefine accordingly the domain factories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_factory = lambda: GymDomainForWidthSolvers(gym.make(ENV_NAME))\n",
    "domain4movie_factory = lambda: GymDomainForWidthSolvers(gym.wrappers.Monitor(gym.make(ENV_NAME), \"tmp_gym_recording\", force=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the compatibility of the domain with the chosen solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = domain_factory()\n",
    "assert IW.check_domain(domain)\n",
    "domain.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a solver factory (class to use with default arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'state_features': lambda d, s: d.bee2_features(s),\n",
    "    'node_ordering': lambda a_gscore, a_novelty, a_depth, b_gscore, b_novelty, b_depth: a_novelty > b_novelty,\n",
    "    'parallel': False,\n",
    "    'debug_logs': False,\n",
    "    'domain_factory': domain_factory,\n",
    "}\n",
    "solver_factory = lambda: IW(**default_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve and play the solution using a monitor wrapper to get a movie. The statement `with` ensure that the solver is properly cleaned after use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with solver_factory() as solver:\n",
    "    # solve\n",
    "    GymDomain.solve_with(solver, domain_factory)\n",
    "    # create a domain wrapped in a monitor for recording during rollout\n",
    "    domain4movie = domain4movie_factory()\n",
    "    # rollout\n",
    "    try:\n",
    "        rollout(domain4movie, solver, num_episodes=1, max_steps=1000, max_framerate=None, outcome_formatter=None)\n",
    "    finally:\n",
    "        domain4movie.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display recorded movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videofilename = glob.glob(\"tmp_gym_recording/openaigym.video.*.video000000.mp4\")[0]\n",
    "with open(videofilename,'rb') as mp4:\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4.read()).decode()\n",
    "display(HTML(f\"<video alt='solution movie' controls autoplay preload'><source src='{data_url}' type='video/mp4'></video>\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
