{"selection": {"domain": {"template": "Domain", "characteristics": {"Agent": "MultiAgent", "Concurrency": "Parallel", "Constraints": "(none)", "Dynamics": "Environment", "Events": "Events", "Goals": "(none)", "Initialization": "(none)", "Memory": "History", "Observability": "PartiallyObservable", "Renderability": "(none)", "Value": "Rewards"}, "showFinetunedOnly": true, "simplifySignatures": true}, "solver": {"template": "Solver", "characteristics": {"Assessability": "(none)", "Policy": "(none)", "Restorability": "(none)"}, "showFinetunedOnly": true}}, "templates": {"domain": [{"name": "Domain", "characteristics": {"Agent": "MultiAgent", "Concurrency": "Parallel", "Constraints": "(none)", "Dynamics": "Environment", "Events": "Events", "Goals": "(none)", "Initialization": "(none)", "Memory": "History", "Observability": "PartiallyObservable", "Renderability": "(none)", "Value": "Rewards"}}, {"name": "RLDomain", "characteristics": {"Agent": "SingleAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "Environment", "Events": "Actions", "Goals": "(none)", "Initialization": "Initializable", "Memory": "Markovian", "Observability": "TransformedObservable", "Renderability": "(none)", "Value": "Rewards"}}, {"name": "MultiAgentRLDomain", "characteristics": {"Agent": "MultiAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "Environment", "Events": "Actions", "Goals": "(none)", "Initialization": "Initializable", "Memory": "Markovian", "Observability": "TransformedObservable", "Renderability": "(none)", "Value": "Rewards"}}, {"name": "StatelessSimulatorDomain", "characteristics": {"Agent": "SingleAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "Simulation", "Events": "Actions", "Goals": "(none)", "Initialization": "(none)", "Memory": "Markovian", "Observability": "TransformedObservable", "Renderability": "(none)", "Value": "Rewards"}}, {"name": "MDPDomain", "characteristics": {"Agent": "SingleAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "EnumerableTransitions", "Events": "Actions", "Goals": "(none)", "Initialization": "DeterministicInitialized", "Memory": "Markovian", "Observability": "FullyObservable", "Renderability": "(none)", "Value": "Rewards"}}, {"name": "POMDPDomain", "characteristics": {"Agent": "SingleAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "EnumerableTransitions", "Events": "Actions", "Goals": "(none)", "Initialization": "UncertainInitialized", "Memory": "Markovian", "Observability": "PartiallyObservable", "Renderability": "(none)", "Value": "Rewards"}}, {"name": "GoalMDPDomain", "characteristics": {"Agent": "SingleAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "EnumerableTransitions", "Events": "Actions", "Goals": "Goals", "Initialization": "DeterministicInitialized", "Memory": "Markovian", "Observability": "FullyObservable", "Renderability": "(none)", "Value": "PositiveCosts"}}, {"name": "GoalPOMDPDomain", "characteristics": {"Agent": "SingleAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "EnumerableTransitions", "Events": "Actions", "Goals": "Goals", "Initialization": "UncertainInitialized", "Memory": "Markovian", "Observability": "PartiallyObservable", "Renderability": "(none)", "Value": "PositiveCosts"}}, {"name": "DeterministicPlanningDomain", "characteristics": {"Agent": "SingleAgent", "Concurrency": "Sequential", "Constraints": "(none)", "Dynamics": "DeterministicTransitions", "Events": "Actions", "Goals": "Goals", "Initialization": "DeterministicInitialized", "Memory": "Markovian", "Observability": "FullyObservable", "Renderability": "(none)", "Value": "PositiveCosts"}}], "solver": [{"name": "Solver", "characteristics": {"Assessability": "(none)", "Policy": "(none)", "Restorability": "(none)"}}, {"name": "DeterministicPolicySolver", "characteristics": {"Assessability": "(none)", "Policy": "DeterministicPolicies", "Restorability": "(none)"}}]}, "characteristics": {"domain": [{"name": "Agent", "levels": ["MultiAgent", "SingleAgent"]}, {"name": "Concurrency", "levels": ["Parallel", "Sequential"]}, {"name": "Constraints", "levels": ["(none)", "Constrained"]}, {"name": "Dynamics", "levels": ["Environment", "Simulation", "UncertainTransitions", "EnumerableTransitions", "DeterministicTransitions"]}, {"name": "Events", "levels": ["Events", "Actions", "UnrestrictedActions"]}, {"name": "Goals", "levels": ["(none)", "Goals"]}, {"name": "Initialization", "levels": ["(none)", "Initializable", "UncertainInitialized", "DeterministicInitialized"]}, {"name": "Memory", "levels": ["History", "FiniteHistory", "Markovian", "Memoryless"]}, {"name": "Observability", "levels": ["PartiallyObservable", "TransformedObservable", "FullyObservable"]}, {"name": "Renderability", "levels": ["(none)", "Renderable"]}, {"name": "Value", "levels": ["Rewards", "PositiveCosts"]}], "solver": [{"name": "Assessability", "levels": ["(none)", "Utilities", "QValues"]}, {"name": "Policy", "levels": ["(none)", "Policies", "UncertainPolicies", "DeterministicPolicies"]}, {"name": "Restorability", "levels": ["(none)", "Restorable"]}]}, "methods": {"domain": {"MultiAgent": [], "SingleAgent": [], "Parallel": [], "Sequential": [], "Constrained": ["_get_constraints_"], "Environment": ["_state_step"], "Simulation": ["_state_sample"], "UncertainTransitions": ["_get_transition_value", "_get_next_state_distribution", "_is_terminal"], "EnumerableTransitions": ["_get_transition_value", "_get_next_state_distribution", "_is_terminal"], "DeterministicTransitions": ["_get_transition_value", "_is_terminal", "_get_next_state"], "Events": ["_get_applicable_actions_from", "_get_action_space_", "_get_enabled_events_from"], "Actions": ["_get_applicable_actions_from", "_get_action_space_"], "UnrestrictedActions": ["_get_action_space_"], "Goals": ["_get_goals_"], "Initializable": ["_state_reset"], "UncertainInitialized": ["_get_initial_state_distribution_"], "DeterministicInitialized": ["_get_initial_state_"], "History": [], "FiniteHistory": ["_get_memory_maxlen_"], "Markovian": [], "Memoryless": [], "PartiallyObservable": ["_get_observation_distribution", "_get_observation_space_"], "TransformedObservable": ["_get_observation", "_get_observation_space_"], "FullyObservable": ["_get_observation_space_"], "Renderable": ["_render_from"], "Rewards": [], "PositiveCosts": [], "domain": []}, "solver": {"Utilities": ["_get_utility"], "QValues": ["_get_q_value", "_get_utility"], "Policies": ["_sample_action", "_is_policy_defined_for"], "UncertainPolicies": ["_get_next_action_distribution", "_is_policy_defined_for"], "DeterministicPolicies": ["_get_next_action", "_is_policy_defined_for"], "Restorable": ["_save", "_load"], "solver": ["_solve_domain"]}}, "types": {"domain": {"MultiAgent": {"T_agent": "skdecide.core.StrDict"}, "SingleAgent": {"T_agent": "typing.Union"}, "Parallel": {"T_concurrency": "typing.List"}, "Sequential": {"T_concurrency": "typing.Union"}, "Constrained": {}, "Environment": {}, "Simulation": {}, "UncertainTransitions": {}, "EnumerableTransitions": {}, "DeterministicTransitions": {}, "Events": {}, "Actions": {}, "UnrestrictedActions": {}, "Goals": {}, "Initializable": {}, "UncertainInitialized": {}, "DeterministicInitialized": {}, "History": {"T_memory": "skdecide.core.Memory"}, "FiniteHistory": {"T_memory": "skdecide.core.Memory"}, "Markovian": {"T_memory": "typing.Union"}, "Memoryless": {"T_memory": "typing.Union"}, "PartiallyObservable": {}, "TransformedObservable": {}, "FullyObservable": {}, "Renderable": {}, "Rewards": {}, "PositiveCosts": {}}, "solver": {"Utilities": {}, "QValues": {}, "Policies": {}, "UncertainPolicies": {}, "DeterministicPolicies": {}, "Restorable": {}}}, "signatures": {"domain": {"get_constraints": {"params": [{"name": "self"}], "return": "List[Constraint[D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state]]"}, "_get_constraints": {"params": [{"name": "self"}], "return": "List[Constraint[D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state]]"}, "_get_constraints_": {"params": [{"name": "self"}], "return": "List[Constraint[D.T_memory[D.T_state], D.T_agent[D.T_concurrency[D.T_event]], D.T_state]]"}, "step": {"params": [{"name": "self"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[TransitionValue[D.T_value]], D.T_agent[D.T_info]]"}, "_step": {"params": [{"name": "self"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[TransitionValue[D.T_value]], D.T_agent[D.T_info]]"}, "_state_step": {"params": [{"name": "self"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "TransitionOutcome[D.T_state, D.T_agent[TransitionValue[D.T_value]], D.T_agent[D.T_info]]"}, "set_memory": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}], "return": "None"}, "_set_memory": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}], "return": "None"}, "sample": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[TransitionValue[D.T_value]], D.T_agent[D.T_info]]"}, "_sample": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[TransitionValue[D.T_value]], D.T_agent[D.T_info]]"}, "_state_sample": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "TransitionOutcome[D.T_state, D.T_agent[TransitionValue[D.T_value]], D.T_agent[D.T_info]]"}, "get_next_state_distribution": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "DiscreteDistribution[D.T_state]"}, "_get_next_state_distribution": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "SingleValueDistribution[D.T_state]"}, "get_transition_value": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}, {"name": "next_state", "default": "None", "annotation": "Optional[D.T_state]"}], "return": "D.T_agent[TransitionValue[D.T_value]]"}, "_get_transition_value": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}, {"name": "next_state", "default": "None", "annotation": "Optional[D.T_state]"}], "return": "D.T_agent[TransitionValue[D.T_value]]"}, "is_transition_value_dependent_on_next_state": {"params": [{"name": "self"}], "return": "bool"}, "_is_transition_value_dependent_on_next_state": {"params": [{"name": "self"}], "return": "bool"}, "_is_transition_value_dependent_on_next_state_": {"params": [{"name": "self"}], "return": "bool"}, "is_terminal": {"params": [{"name": "self"}, {"name": "state", "annotation": "D.T_state"}], "return": "bool"}, "_is_terminal": {"params": [{"name": "self"}, {"name": "state", "annotation": "D.T_state"}], "return": "bool"}, "get_next_state": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "D.T_state"}, "_get_next_state": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "D.T_state"}, "get_enabled_events": {"params": [{"name": "self"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "Space[D.T_event]"}, "_get_enabled_events": {"params": [{"name": "self"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "Space[D.T_event]"}, "_get_enabled_events_from": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}], "return": "Space[D.T_event]"}, "is_enabled_event": {"params": [{"name": "self"}, {"name": "event", "annotation": "D.T_event"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "bool"}, "_is_enabled_event": {"params": [{"name": "self"}, {"name": "event", "annotation": "D.T_event"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "bool"}, "_is_enabled_event_from": {"params": [{"name": "self"}, {"name": "event", "annotation": "D.T_event"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}], "return": "bool"}, "get_action_space": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_event]]"}, "_get_action_space": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_event]]"}, "_get_action_space_": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_event]]"}, "is_action": {"params": [{"name": "self"}, {"name": "event", "annotation": "D.T_event"}], "return": "bool"}, "_is_action": {"params": [{"name": "self"}, {"name": "event", "annotation": "D.T_event"}], "return": "bool"}, "get_applicable_actions": {"params": [{"name": "self"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "D.T_agent[Space[D.T_event]]"}, "_get_applicable_actions": {"params": [{"name": "self"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "D.T_agent[Space[D.T_event]]"}, "_get_applicable_actions_from": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}], "return": "D.T_agent[Space[D.T_event]]"}, "is_applicable_action": {"params": [{"name": "self"}, {"name": "action", "annotation": "D.T_agent[D.T_event]"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "bool"}, "_is_applicable_action": {"params": [{"name": "self"}, {"name": "action", "annotation": "D.T_agent[D.T_event]"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}], "return": "bool"}, "_is_applicable_action_from": {"params": [{"name": "self"}, {"name": "action", "annotation": "D.T_agent[D.T_event]"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}], "return": "bool"}, "get_goals": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_observation]]"}, "_get_goals": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_observation]]"}, "_get_goals_": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_observation]]"}, "is_goal": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "bool"}, "_is_goal": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "bool"}, "reset": {"params": [{"name": "self"}], "return": "D.T_agent[D.T_observation]"}, "_reset": {"params": [{"name": "self"}], "return": "D.T_agent[D.T_observation]"}, "_state_reset": {"params": [{"name": "self"}], "return": "D.T_state"}, "get_initial_state_distribution": {"params": [{"name": "self"}], "return": "Distribution[D.T_state]"}, "_get_initial_state_distribution": {"params": [{"name": "self"}], "return": "Distribution[D.T_state]"}, "_get_initial_state_distribution_": {"params": [{"name": "self"}], "return": "Distribution[D.T_state]"}, "get_initial_state": {"params": [{"name": "self"}], "return": "D.T_state"}, "_get_initial_state": {"params": [{"name": "self"}], "return": "D.T_state"}, "_get_initial_state_": {"params": [{"name": "self"}], "return": "D.T_state"}, "_init_memory": {"params": [{"name": "self"}, {"name": "state", "default": "None", "annotation": "Optional[D.T_state]"}], "return": "D.T_memory[D.T_state]"}, "_get_memory_maxlen": {"params": [{"name": "self"}], "return": "int"}, "_get_memory_maxlen_": {"params": [{"name": "self"}], "return": "int"}, "get_observation_space": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_observation]]"}, "_get_observation_space": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_observation]]"}, "_get_observation_space_": {"params": [{"name": "self"}], "return": "D.T_agent[Space[D.T_observation]]"}, "is_observation": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "bool"}, "_is_observation": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "bool"}, "get_observation_distribution": {"params": [{"name": "self"}, {"name": "state", "annotation": "D.T_state"}, {"name": "action", "default": "None", "annotation": "Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}], "return": "Distribution[D.T_agent[D.T_observation]]"}, "_get_observation_distribution": {"params": [{"name": "self"}, {"name": "state", "annotation": "D.T_state"}, {"name": "action", "default": "None", "annotation": "Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}], "return": "Distribution[D.T_agent[D.T_observation]]"}, "get_observation": {"params": [{"name": "self"}, {"name": "state", "annotation": "D.T_state"}, {"name": "action", "default": "None", "annotation": "Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}], "return": "D.T_agent[D.T_observation]"}, "_get_observation": {"params": [{"name": "self"}, {"name": "state", "annotation": "D.T_state"}, {"name": "action", "default": "None", "annotation": "Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}], "return": "D.T_agent[D.T_observation]"}, "render": {"params": [{"name": "self"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}, {"name": "kwargs", "annotation": "Any"}], "return": "Any"}, "_render": {"params": [{"name": "self"}, {"name": "memory", "default": "None", "annotation": "Optional[D.T_memory[D.T_state]]"}, {"name": "kwargs", "annotation": "Any"}], "return": "Any"}, "_render_from": {"params": [{"name": "self"}, {"name": "memory", "annotation": "D.T_memory[D.T_state]"}, {"name": "kwargs", "annotation": "Any"}], "return": "Any"}, "check_value": {"params": [{"name": "self"}, {"name": "value", "annotation": "TransitionValue[D.T_value]"}], "return": "bool"}, "_check_value": {"params": [{"name": "self"}, {"name": "value", "annotation": "TransitionValue[D.T_value]"}], "return": "bool"}, "_is_positive": {"params": [{"name": "self"}, {"name": "cost", "annotation": "D.T_value"}], "return": "bool"}}, "solver": {"get_utility": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "D.T_value"}, "_get_utility": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "D.T_value"}, "get_q_value": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "D.T_value"}, "_get_q_value": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}, {"name": "action", "annotation": "D.T_agent[D.T_concurrency[D.T_event]]"}], "return": "D.T_value"}, "sample_action": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "D.T_agent[D.T_concurrency[D.T_event]]"}, "_sample_action": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "D.T_agent[D.T_concurrency[D.T_event]]"}, "is_policy_defined_for": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "bool"}, "_is_policy_defined_for": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "bool"}, "get_next_action_distribution": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "Distribution[D.T_agent[D.T_concurrency[D.T_event]]]"}, "_get_next_action_distribution": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "Distribution[D.T_agent[D.T_concurrency[D.T_event]]]"}, "get_next_action": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "D.T_agent[D.T_concurrency[D.T_event]]"}, "_get_next_action": {"params": [{"name": "self"}, {"name": "observation", "annotation": "D.T_agent[D.T_observation]"}], "return": "D.T_agent[D.T_concurrency[D.T_event]]"}, "save": {"params": [{"name": "self"}, {"name": "path", "annotation": "str"}], "return": "None"}, "_save": {"params": [{"name": "self"}, {"name": "path", "annotation": "str"}], "return": "None"}, "load": {"params": [{"name": "self"}, {"name": "path", "annotation": "str"}, {"name": "domain_factory", "annotation": "Callable[[], D]"}], "return": "None"}, "_load": {"params": [{"name": "self"}, {"name": "path", "annotation": "str"}, {"name": "domain_factory", "annotation": "Callable[[], D]"}], "return": "None"}, "_solve_domain": {"params": [{"name": "self"}, {"name": "domain_factory", "annotation": "Callable[[], D]"}], "return": "None"}}}, "objects": {"Space": "/reference/_skdecide.core.html#space", "ImplicitSpace": "/reference/_skdecide.core.html#implicitspace", "EnumerableSpace": "/reference/_skdecide.core.html#enumerablespace", "EmptySpace": "/reference/_skdecide.core.html#emptyspace", "SamplableSpace": "/reference/_skdecide.core.html#samplablespace", "SerializableSpace": "/reference/_skdecide.core.html#serializablespace", "Distribution": "/reference/_skdecide.core.html#distribution", "ImplicitDistribution": "/reference/_skdecide.core.html#implicitdistribution", "DiscreteDistribution": "/reference/_skdecide.core.html#discretedistribution", "SingleValueDistribution": "/reference/_skdecide.core.html#singlevaluedistribution", "TransitionValue": "/reference/_skdecide.core.html#transitionvalue", "EnvironmentOutcome": "/reference/_skdecide.core.html#environmentoutcome", "TransitionOutcome": "/reference/_skdecide.core.html#transitionoutcome", "StrDict": "/reference/_skdecide.core.html#strdict", "Constraint": "/reference/_skdecide.core.html#constraint", "ImplicitConstraint": "/reference/_skdecide.core.html#implicitconstraint", "BoundConstraint": "/reference/_skdecide.core.html#boundconstraint"}}