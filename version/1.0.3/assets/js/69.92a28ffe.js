(window.webpackJsonp=window.webpackJsonp||[]).push([[69],{584:function(t,e,a){"use strict";a.r(e);var s=a(38),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"hub-domain-flight-planning-domain"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hub-domain-flight-planning-domain"}},[t._v("#")]),t._v(" hub.domain.flight_planning.domain")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("Domain specification")]),t._v(" "),a("skdecide-summary")],1),t._v(" "),a("h2",{attrs:{id:"state"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state"}},[t._v("#")]),t._v(" State")]),t._v(" "),a("p",[t._v("Definition of a aircraft state during the flight plan")]),t._v(" "),a("h3",{attrs:{id:"constructor"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#constructor"}},[t._v("#")]),t._v(" Constructor "),a("Badge",{attrs:{text:"State",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"State",sig:{params:[{name:"trajectory"},{name:"id"}]}}}),t._v(" "),a("p",[t._v("Initialisation of a state")]),t._v(" "),a("p",[t._v("Args:\ntrajectory : Trajectory information of the flight\nid: Node id in the airway graph")]),t._v(" "),a("h2",{attrs:{id:"h-action"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#h-action"}},[t._v("#")]),t._v(" H_Action")]),t._v(" "),a("p",[t._v("Horizontal action that can be perform by the aircraft")]),t._v(" "),a("h3",{attrs:{id:"left"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#left"}},[t._v("#")]),t._v(" left "),a("Badge",{attrs:{text:"H_Action",type:"tip"}})],1),t._v(" "),a("h3",{attrs:{id:"right"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#right"}},[t._v("#")]),t._v(" right "),a("Badge",{attrs:{text:"H_Action",type:"tip"}})],1),t._v(" "),a("h3",{attrs:{id:"straight"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#straight"}},[t._v("#")]),t._v(" straight "),a("Badge",{attrs:{text:"H_Action",type:"tip"}})],1),t._v(" "),a("h2",{attrs:{id:"v-action"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#v-action"}},[t._v("#")]),t._v(" V_Action")]),t._v(" "),a("p",[t._v("Vertical action that can be perform by the aircraft")]),t._v(" "),a("h3",{attrs:{id:"climb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#climb"}},[t._v("#")]),t._v(" climb "),a("Badge",{attrs:{text:"V_Action",type:"tip"}})],1),t._v(" "),a("h3",{attrs:{id:"cruise"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cruise"}},[t._v("#")]),t._v(" cruise "),a("Badge",{attrs:{text:"V_Action",type:"tip"}})],1),t._v(" "),a("h3",{attrs:{id:"descent"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#descent"}},[t._v("#")]),t._v(" descent "),a("Badge",{attrs:{text:"V_Action",type:"tip"}})],1),t._v(" "),a("h2",{attrs:{id:"flightplanningdomain"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flightplanningdomain"}},[t._v("#")]),t._v(" FlightPlanningDomain")]),t._v(" "),a("p",[t._v("Automated flight planning domain.")]),t._v(" "),a("h2",{attrs:{id:"domain-definition"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#domain-definition"}},[t._v("#")]),t._v(" Domain definition")]),t._v(" "),a("p",[t._v("The flight planning domain can be quickly defined as :")]),t._v(" "),a("ul",[a("li",[t._v("An origin, as ICAO code of an airport,")]),t._v(" "),a("li",[t._v("A destination, as ICAO code of an airport,")]),t._v(" "),a("li",[t._v("An aircraft type, as a string recognizable by the OpenAP library.")])]),t._v(" "),a("h2",{attrs:{id:"airways-graph"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#airways-graph"}},[t._v("#")]),t._v(" Airways graph")]),t._v(" "),a("p",[t._v("A three-dimensional airway graph of waypoints is created. The graph is following the great circle\nwhich represents the shortest pass between the origin and the destination.\nThe planner computes a plan by choosing waypoints in the graph, which are represented by 4-dimensionnal states.\nThere is 3 phases in the graph :")]),t._v(" "),a("ul",[a("li",[t._v("The climbing phase")]),t._v(" "),a("li",[t._v("The cruise phase")]),t._v(" "),a("li",[t._v("The descent phase")])]),t._v(" "),a("p",[t._v("The flight planning domain allows to choose a number of forward, lateral and vertical waypoints in the graph.\nIt is also possible to choose different width (tiny, small, normal, large, xlarge) which will increase\nor decrease the graph width.")]),t._v(" "),a("h2",{attrs:{id:"state-representation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-representation"}},[t._v("#")]),t._v(" State representation")]),t._v(" "),a("p",[t._v("Here, the states are represented by 4 features :")]),t._v(" "),a("ul",[a("li",[t._v("The position in the graph (x,y,z)")]),t._v(" "),a("li",[t._v("The aircraft mass, which can also represent the fuel consumption (integer)")]),t._v(" "),a("li",[t._v("The altitude (integer)")]),t._v(" "),a("li",[t._v("The time (seconds)")])]),t._v(" "),a("h2",{attrs:{id:"wind-interpolation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#wind-interpolation"}},[t._v("#")]),t._v(" Wind interpolation")]),t._v(" "),a("p",[t._v("The flight planning domain can take in consideration the wind conditions.\nThat interpolation have a major impact on the results, as jet streams are high altitude wind\nwhich can increase or decrease the ground speed of the aircraft.\nIt also have an impact on the computation time of a flight plan,\nas the objective and heuristic function became more complex.")]),t._v(" "),a("h2",{attrs:{id:"objective-or-cost-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#objective-or-cost-functions"}},[t._v("#")]),t._v(" Objective (or cost) functions")]),t._v(" "),a("p",[t._v("There is three possible objective functions:")]),t._v(" "),a("ul",[a("li",[t._v("Fuel (Default)")]),t._v(" "),a("li",[t._v("Distance")]),t._v(" "),a("li",[t._v("Time")])]),t._v(" "),a("p",[t._v("The chosen objective will represent the cost to go from a state to another. The aim of the algorithm is to minimize the cost.")]),t._v(" "),a("h2",{attrs:{id:"heuristic-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#heuristic-functions"}},[t._v("#")]),t._v(" Heuristic functions")]),t._v(" "),a("p",[t._v("When using an A* algorithm to compute the flight plan, we need to feed it with a heuristic function, which guide the algorithm.\nFor now, there is 5 different (not admissible) heuristic function, depending on "),a("code",[t._v("self.heuristic_name")]),t._v(":")]),t._v(" "),a("ul",[a("li",[t._v("time, which computes the required time to get to the goal. It takes in consideration the local wind & speed of the aircraft.")]),t._v(" "),a("li",[t._v("distance, wich computes the distance to the goal.")]),t._v(" "),a("li",[t._v("lazy_fuel, which propagates the fuel consummed so far.")]),t._v(" "),a("li",[t._v("lazy_time, which propagates the time spent on the flight so far")]),t._v(" "),a("li",[t._v("None : we give a 0 cost value, which will transform the A* algorithm into a Dijkstra-like algorithm.")])]),t._v(" "),a("h2",{attrs:{id:"aircraft-performance-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aircraft-performance-models"}},[t._v("#")]),t._v(" Aircraft performance models")]),t._v(" "),a("p",[t._v("The flight planning domain can use two possible A/C performance models:")]),t._v(" "),a("ul",[a("li",[t._v("OpenAP: the aircraft performance model is based on the OpenAP library.")]),t._v(" "),a("li",[t._v('Poll-Schumann: the aircraft performance model is based on Poll-Schumann equations as stated on the paper: "An estimation\nmethod for the fuel burn and other performance characteristics of civil transport aircraft in the cruise" by Poll and Schumann;\nThe Aernautical Journal, 2020.')])]),t._v(" "),a("h2",{attrs:{id:"optional-features"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#optional-features"}},[t._v("#")]),t._v(" Optional features")]),t._v(" "),a("p",[t._v("The flight planning domain has several optional features :")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Fuel loop: this is an optimisation of the loaded fuel for the aircraft.\nIt will run some flights to computes the loaded fuel, using distance objective & heuristic.")])]),t._v(" "),a("li",[a("p",[t._v("Constraints definition: you can define constraints such as")]),t._v(" "),a("ul",[a("li",[t._v("A time constraint, represented by a time windows")]),t._v(" "),a("li",[t._v("A fuel constraint, represented by the maximum fuel for instance.")])])]),t._v(" "),a("li",[a("p",[t._v("Slopes: you can define your own climbing & descending slopes which have to be between 10.0 and 25.0.")])])]),t._v(" "),a("h3",{attrs:{id:"constructor-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#constructor-2"}},[t._v("#")]),t._v(" Constructor "),a("Badge",{attrs:{text:"FlightPlanningDomain",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"FlightPlanningDomain",sig:{params:[{name:"aircraft_state",annotation:"<class 'skdecide.hub.domain.flight_planning.aircraft_performance.bean.aircraft_state.AircraftState'>"},{name:"mach_cruise",default:"0.78",annotation:"<class 'float'>"},{name:"mach_climb",default:"0.7",annotation:"<class 'float'>"},{name:"mach_descent",default:"0.6",annotation:"<class 'float'>"},{name:"nb_forward_points",default:"30",annotation:"<class 'int'>"},{name:"nb_lateral_points",default:"10",annotation:"<class 'int'>"},{name:"nb_climb_descent_steps",default:"4",annotation:"<class 'int'>"},{name:"flight_levels_ft",default:"None",annotation:"typing.Optional[list[int]]"},{name:"graph_width",default:"medium",annotation:"<class 'str'>"},{name:"origin",default:"None",annotation:"typing.Optional[tuple[str, pygeodesy.ellipsoidalVincenty.LatLon]]"},{name:"destination",default:"None",annotation:"typing.Optional[tuple[str, pygeodesy.ellipsoidalVincenty.LatLon]]"},{name:"objective",default:"fuel",annotation:"<class 'str'>"},{name:"heuristic_name",default:"lazy_fuel",annotation:"<class 'str'>"},{name:"starting_time",default:"28800.0",annotation:"<class 'float'>"},{name:"weather_date",default:"None",annotation:"typing.Optional[skdecide.hub.domain.flight_planning.domain.WeatherDate]"},{name:"wind_interpolator",default:"None",annotation:"typing.Optional[skdecide.hub.domain.flight_planning.weather_interpolator.weather_tools.interpolator.GenericInterpolator.GenericWindInterpolator]"},{name:"constraints",default:"None"},{name:"fuel_loaded",default:"None",annotation:"typing.Optional[float]"},{name:"fuel_loop",default:"False",annotation:"<class 'bool'>"},{name:"fuel_loop_solver_cls",default:"None",annotation:"typing.Optional[type[skdecide.solvers.Solver]]"},{name:"fuel_loop_solver_kwargs",default:"None",annotation:"typing.Optional[dict[str, typing.Any]]"},{name:"fuel_loop_tol",default:"0.001",annotation:"<class 'float'>"},{name:"res_img_dir",default:"None",annotation:"typing.Optional[str]"}]}}}),t._v(" "),a("p",[t._v("Initialisation of a flight planning instance")]),t._v(" "),a("h4",{attrs:{id:"parameters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("p",[t._v('origin (Union[str, tuple]):\nICAO code of the airport, or a tuple (lat,lon,alt), of the origin of the flight plan. Altitude should be in ft\ndestination (Union[str, tuple]):\nICAO code of the airport, or a tuple (lat,lon,alt), of the destination of the flight plan. Altitude should be in ft\naircraft_state (AircraftState)\nInitial aircraft state.\ncruise_height_min (float)\nMinimum cruise height in ft\ncruise_height_max (float)\nMaximum cruise height in ft\nweather_date (WeatherDate, optional):\nDate for the weather, needed for days management.\nIf None, no wind will be applied.\nobjective (str, optional):\nCost function of the flight plan. It can be either fuel, distance or time. Defaults to "fuel".\nheuristic_name (str, optional):\nHeuristic of the flight plan, it will guide the aircraft through the graph. It can be either fuel, distance or time. Defaults to "fuel".\nwind_interpolator (GenericWindInterpolator, optional):\nWind interpolator for the flight plan. If None, create one from the specified weather_date.\nThe data is either already present locally or be downloaded from https://www.ncei.noaa.gov\nconstraints ('),a("em",[t._v("type")]),t._v(', optional):\nConstraints dictionnary (keyValues : [\'time\', \'fuel\'] ) to be defined in for the flight plan. Defaults to None.\nnb_forward_points (int, optional):\nNumber of forward nodes in the graph. Defaults to 41.\nnb_lateral_points (int, optional):\nNumber of lateral nodes in the graph. Defaults to 11.\nnb_vertical_points (int, optional):\nNumber of vertical nodes in the graph. Defaults to None.\nfuel_loaded (float, optional):\nFuel loaded in the airscraft for the flight plan. Defaults to None.\nfuel_loop (bool, optional):\nBoolean to create a fuel loop to optimize the fuel loaded for the flight. Defaults to False\nfuel_loop_solver_cls (type[Solver], optional):\nSolver class used in the fuel loop. Defaults to LazyAstar.\nfuel_loop_solver_kwargs (dict[str, Any], optional):\nKwargs to initialize the solver used in the fuel loop.\ngraph_width (str, optional):\nAirways graph width, in ["small", "medium", "large", "xlarge"]. Defaults to None\nres_img_dir (str, optional):\nDirectory in which images will be saved. Defaults to None\nstarting_time (float, optional):\nStart time of the flight, in seconds. Defaults to 8AM (3_600.0 * 8.0)')]),t._v(" "),a("h3",{attrs:{id:"check-value"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#check-value"}},[t._v("#")]),t._v(" check_value "),a("Badge",{attrs:{text:"Rewards",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"check_value",sig:{params:[{name:"self"},{name:"value",annotation:"Value[D.T_value]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Check that a value is compliant with its reward specification.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("This function returns always True by default because any kind of reward should be accepted at this level.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-2"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("value")]),t._v(": The value to check.")])]),t._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the value is compliant (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"flying"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flying"}},[t._v("#")]),t._v(" flying "),a("Badge",{attrs:{text:"FlightPlanningDomain",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"flying",sig:{params:[{name:"self"},{name:"from_",annotation:"<class 'pandas.core.frame.DataFrame'>"},{name:"to_",annotation:"tuple[float, float, int]"},{name:"current_speed",annotation:"<class 'float'>"},{name:"current_phase",annotation:"<enum 'PhaseEnum'>"},{name:"current_rating",annotation:"<enum 'RatingEnum'>"}],return:"<class 'pandas.core.frame.DataFrame'>"}}}),t._v(" "),a("p",[t._v("Compute the trajectory of a flying object from a given point to a given point")]),t._v(" "),a("h4",{attrs:{id:"parameters-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-3"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("p",[t._v("from_ (pd.DataFrame): the trajectory of the object so far\nto_ (tuple[float, float]): the destination of the object")]),t._v(" "),a("h4",{attrs:{id:"returns-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-2"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("pd.DataFrame: the final trajectory of the object\n")])])]),a("h3",{attrs:{id:"get-action-mask"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-action-mask"}},[t._v("#")]),t._v(" get_action_mask "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_action_mask",sig:{params:[{name:"self"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"D.T_agent[Mask]"}}}),t._v(" "),a("p",[t._v("Get action mask for the given memory or internal one if omitted.")]),t._v(" "),a("p",[t._v("An action mask is another (more specific) format for applicable actions, that has a meaning only if the action\nspace can be iterated over in some way. It is represented by a flat array of 0's and 1's ordered as the actions\nwhen enumerated: 1 for an applicable action, and 0 for a not applicable action.")]),t._v(" "),a("p",[t._v("More precisely, this implementation makes the assumption that each agent action space is an "),a("code",[t._v("EnumerableSpace")]),t._v(",\nand calls internally "),a("code",[t._v("self.get_applicable_action()")]),t._v(".")]),t._v(" "),a("p",[t._v("The action mask is used for instance by RL solvers to shut down logits associated to non-applicable actions in\nthe output of their internal neural network.")]),t._v(" "),a("h4",{attrs:{id:"parameters-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-4"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider. If None, works on the internal memory of the domain.")])]),t._v(" "),a("h4",{attrs:{id:"returns-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-3"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("a numpy array (or dict agent-> numpy array for multi-agent domains) with 0-1 indicating applicability of\nthe action (1 meaning applicable and 0 not applicable)")]),t._v(" "),a("h3",{attrs:{id:"get-action-space"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-action-space"}},[t._v("#")]),t._v(" get_action_space "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_action_space",sig:{params:[{name:"self"}],return:"D.T_agent[Space[D.T_event]]"}}}),t._v(" "),a("p",[t._v("Get the (cached) domain action space (finite or infinite set).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events.get_action_space()")]),t._v(" internally calls "),a("code",[t._v("Events._get_action_space_()")]),t._v(" the first time and\nautomatically caches its value to make future calls more efficient (since the action space is assumed to be\nconstant).")]),t._v(" "),a("h4",{attrs:{id:"returns-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-4"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The action space.")]),t._v(" "),a("h3",{attrs:{id:"get-agents"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-agents"}},[t._v("#")]),t._v(" get_agents "),a("Badge",{attrs:{text:"MultiAgent",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_agents",sig:{params:[{name:"self"}],return:"set[str]"}}}),t._v(" "),a("p",[t._v("Return a singleton for single agent domains.")]),t._v(" "),a("p",[t._v("We must be here consistent with "),a("code",[t._v("skdecide.core.autocast()")]),t._v(' which transforms a single agent domain\ninto a multi agents domain whose only agent has the id "agent".')]),t._v(" "),a("h3",{attrs:{id:"get-applicable-actions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-applicable-actions"}},[t._v("#")]),t._v(" get_applicable_actions "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_applicable_actions",sig:{params:[{name:"self"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"D.T_agent[Space[D.T_event]]"}}}),t._v(" "),a("p",[t._v("Get the space (finite or infinite set) of applicable actions in the given memory (state or history), or in\nthe internal one if omitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events.get_applicable_actions()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._get_applicable_actions()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute\ninstead of the memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-5"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-5"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The space of applicable actions.")]),t._v(" "),a("h3",{attrs:{id:"get-enabled-events"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-enabled-events"}},[t._v("#")]),t._v(" get_enabled_events "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_enabled_events",sig:{params:[{name:"self"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"Space[D.T_event]"}}}),t._v(" "),a("p",[t._v("Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or\nhistory), or in the internal one if omitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events.get_enabled_events()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._get_enabled_events()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute instead of\nthe memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-6"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-6"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The space of enabled events.")]),t._v(" "),a("h3",{attrs:{id:"get-goals"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-goals"}},[t._v("#")]),t._v(" get_goals "),a("Badge",{attrs:{text:"Goals",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_goals",sig:{params:[{name:"self"}],return:"D.T_agent[Space[D.T_observation]]"}}}),t._v(" "),a("p",[t._v("Get the (cached) domain goals space (finite or infinite set).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Goals.get_goals()")]),t._v(" internally calls "),a("code",[t._v("Goals._get_goals_()")]),t._v(" the first time and automatically caches its\nvalue to make future calls more efficient (since the goals space is assumed to be constant).")]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Goal states are assumed to be fully observable (i.e. observation = state) so that there is never uncertainty\nabout whether the goal has been reached or not. This assumption guarantees that any policy that does not\nreach the goal with certainty incurs in infinite expected cost. - "),a("em",[t._v("Geffner, 2013: A Concise Introduction to\nModels and Methods for Automated Planning")])])]),t._v(" "),a("h4",{attrs:{id:"returns-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-7"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The goals space.")]),t._v(" "),a("h3",{attrs:{id:"get-initial-state"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-initial-state"}},[t._v("#")]),t._v(" get_initial_state "),a("Badge",{attrs:{text:"DeterministicInitialized",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_initial_state",sig:{params:[{name:"self"}],return:"D.T_state"}}}),t._v(" "),a("p",[t._v("Get the (cached) initial state.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("DeterministicInitialized.get_initial_state()")]),t._v(" internally\ncalls "),a("code",[t._v("DeterministicInitialized._get_initial_state_()")]),t._v(" the first time and automatically caches its value to make\nfuture calls more efficient (since the initial state is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-8"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The initial state.")]),t._v(" "),a("h3",{attrs:{id:"get-initial-state-distribution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-initial-state-distribution"}},[t._v("#")]),t._v(" get_initial_state_distribution "),a("Badge",{attrs:{text:"UncertainInitialized",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_initial_state_distribution",sig:{params:[{name:"self"}],return:"Distribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the (cached) probability distribution of initial states.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainInitialized.get_initial_state_distribution()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainInitialized._get_initial_state_distribution_()")]),t._v(" the first time and automatically caches its value\nto make future calls more efficient (since the initial state distribution is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-9"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of initial states.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state"}},[t._v("#")]),t._v(" get_next_state "),a("Badge",{attrs:{text:"DeterministicTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_next_state",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"D.T_state"}}}),t._v(" "),a("p",[t._v("Get the next state given a memory and action.")]),t._v(" "),a("h4",{attrs:{id:"parameters-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-7"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-10"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-10"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The deterministic next state.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution"}},[t._v("#")]),t._v(" get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"DiscreteDistribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the discrete probability distribution of next state given a memory and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("In the Markovian case (memory only holds last state "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.061ex",height:"1.023ex",viewBox:"0 -442 469 452"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})])])])])]),t._v("), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function can\nbe mathematically represented by "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.292ex",height:"2.283ex",viewBox:"0 -759 4107.1 1009"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"msup",transform:"translate(1140, 0)"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1997.5, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2275.5, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2744.5, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3189.1, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3718.1, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(", where "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.94ex",height:"1.767ex",viewBox:"0 -759 857.5 781"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"msup"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])])])])])]),t._v(" is the next state random variable.")],1)]),t._v(" "),a("h4",{attrs:{id:"parameters-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-8"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-11"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-11"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The discrete probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-observation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-observation"}},[t._v("#")]),t._v(" get_observation "),a("Badge",{attrs:{text:"TransformedObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_observation",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"},{name:"action",default:"None",annotation:"Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}],return:"D.T_agent[D.T_observation]"}}}),t._v(" "),a("p",[t._v("Get the deterministic observation given a state and action.")]),t._v(" "),a("h4",{attrs:{id:"parameters-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-9"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to be observed.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The last applied action (or None if the state is an initial state).")])]),t._v(" "),a("h4",{attrs:{id:"returns-12"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-12"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of the observation.")]),t._v(" "),a("h3",{attrs:{id:"get-observation-distribution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-observation-distribution"}},[t._v("#")]),t._v(" get_observation_distribution "),a("Badge",{attrs:{text:"PartiallyObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_observation_distribution",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"},{name:"action",default:"None",annotation:"Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}],return:"Distribution[D.T_agent[D.T_observation]]"}}}),t._v(" "),a("p",[t._v("Get the probability distribution of the observation given a state and action.")]),t._v(" "),a("p",[t._v("In mathematical terms (discrete case), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function represents: "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.078ex",height:"2.262ex",viewBox:"0 -750 4012.7 1000"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(1140, 0)"}},[a("path",{attrs:{"data-c":"4F",d:"M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1903, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2181, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2650, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3094.7, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3623.7, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(",\nwhere "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.726ex",height:"1.643ex",viewBox:"0 -704 763 726"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"4F",d:"M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"}})])])])])]),t._v(" is the random variable of the observation.")],1),t._v(" "),a("h4",{attrs:{id:"parameters-10"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-10"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to be observed.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The last applied action (or None if the state is an initial state).")])]),t._v(" "),a("h4",{attrs:{id:"returns-13"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-13"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of the observation.")]),t._v(" "),a("h3",{attrs:{id:"get-observation-space"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-observation-space"}},[t._v("#")]),t._v(" get_observation_space "),a("Badge",{attrs:{text:"PartiallyObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_observation_space",sig:{params:[{name:"self"}],return:"D.T_agent[Space[D.T_observation]]"}}}),t._v(" "),a("p",[t._v("Get the (cached) observation space (finite or infinite set).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("PartiallyObservable.get_observation_space()")]),t._v(" internally\ncalls "),a("code",[t._v("PartiallyObservable._get_observation_space_()")]),t._v(" the first time and automatically caches its value to make\nfuture calls more efficient (since the observation space is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-14"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-14"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The observation space.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value"}},[t._v("#")]),t._v(" get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"},{name:"next_state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_agent[Value[D.T_value]]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.")]),t._v(" "),a("p",[t._v("The transition to consider is defined by the function parameters.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("If this function never depends on the next_state parameter for its computation, it is recommended to\nindicate it by overriding "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" to return\nFalse. This information can then be exploited by solvers to avoid computing next state to evaluate a\ntransition value (more efficient).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-11"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-11"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")]),t._v(" "),a("li",[a("strong",[t._v("next_state")]),t._v(": The next state in which the transition ends (if needed for the computation).")])]),t._v(" "),a("h4",{attrs:{id:"returns-15"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-15"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition value (reward or cost).")]),t._v(" "),a("h3",{attrs:{id:"heuristic"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#heuristic"}},[t._v("#")]),t._v(" heuristic "),a("Badge",{attrs:{text:"FlightPlanningDomain",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"heuristic",sig:{params:[{name:"self"},{name:"s",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"},{name:"heuristic_name",default:"None",annotation:"<class 'str'>"}],return:"skdecide.core.Value[float]"}}}),t._v(" "),a("p",[t._v("Heuristic to be used by search algorithms, depending on the objective and constraints.")]),t._v(" "),a("h4",{attrs:{id:"parameters-12"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-12"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("p",[t._v("s (D.T_state): Actual state\nobjective (str, optional): Objective function. Defaults to None.")]),t._v(" "),a("h4",{attrs:{id:"returns-16"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-16"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("Value[D.T_value]: Heuristic value of the state.\n")])])]),a("h3",{attrs:{id:"is-action"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-action"}},[t._v("#")]),t._v(" is_action "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_action",sig:{params:[{name:"self"},{name:"event",annotation:"D.T_event"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an event is an action (i.e. a controllable event for the agents).")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the domain\naction space provided by "),a("code",[t._v("Events.get_action_space()")]),t._v(", but it can be overridden for faster implementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-13"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-13"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("event")]),t._v(": The event to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-17"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-17"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the event is an action (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-applicable-action"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-applicable-action"}},[t._v("#")]),t._v(" is_applicable_action "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_applicable_action",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_event]"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an action is applicable in the given memory (state or history), or in the internal one if\nomitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events.is_applicable_action()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._is_applicable_action()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute instead\nof the memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-14"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-14"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-18"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-18"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the action is applicable (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-enabled-event"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-enabled-event"}},[t._v("#")]),t._v(" is_enabled_event "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_enabled_event",sig:{params:[{name:"self"},{name:"event",annotation:"D.T_event"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an uncontrollable event is enabled in the given memory (state or history), or in the\ninternal one if omitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events.is_enabled_event()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._is_enabled_event()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute instead of\nthe memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-15"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-15"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-19"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-19"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the event is enabled (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-goal"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-goal"}},[t._v("#")]),t._v(" is_goal "),a("Badge",{attrs:{text:"Goals",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_goal",sig:{params:[{name:"self"},{name:"observation",annotation:"D.T_agent[D.T_observation]"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether an observation belongs to the goals.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the domain\ngoals space provided by "),a("code",[t._v("Goals.get_goals()")]),t._v(", but it can be overridden for faster implementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-16"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-16"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("observation")]),t._v(": The observation to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-20"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-20"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the observation is a goal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-observation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-observation"}},[t._v("#")]),t._v(" is_observation "),a("Badge",{attrs:{text:"PartiallyObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_observation",sig:{params:[{name:"self"},{name:"observation",annotation:"D.T_agent[D.T_observation]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Check that an observation indeed belongs to the domain observation space.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the domain\nobservation space provided by "),a("code",[t._v("PartiallyObservable.get_observation_space()")]),t._v(", but it can be overridden for\nfaster implementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-17"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-17"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("observation")]),t._v(": The observation to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-21"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-21"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the observation belongs to the domain observation space (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal"}},[t._v("#")]),t._v(" is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("A terminal state is a state with no outgoing transition (except to itself with value 0).")]),t._v(" "),a("h4",{attrs:{id:"parameters-18"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-18"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-22"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-22"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the state is terminal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state"}},[t._v("#")]),t._v(" is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions.is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-23"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-23"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"reset"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reset"}},[t._v("#")]),t._v(" reset "),a("Badge",{attrs:{text:"Initializable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"reset",sig:{params:[{name:"self"}],return:"D.T_agent[D.T_observation]"}}}),t._v(" "),a("p",[t._v("Reset the state of the environment and return an initial observation.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Initializable.reset()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Initializable._reset()")]),t._v("\n(which returns an initial state). The boilerplate code automatically stores the initial state into the "),a("code",[t._v("_memory")]),t._v("\nattribute and samples a corresponding observation.")]),t._v(" "),a("h4",{attrs:{id:"returns-24"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-24"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("An initial observation.")]),t._v(" "),a("h3",{attrs:{id:"sample"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample"}},[t._v("#")]),t._v(" sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation.sample()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Simulation._sample()")]),t._v("\n(which returns a transition outcome). The boilerplate code automatically samples an observation corresponding to\nthe sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation.sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-19"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-19"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-25"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-25"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory"}},[t._v("#")]),t._v(" set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with successive '),a("code",[t._v("Environment.step()")]),t._v("\ncalls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-20"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-20"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"set-network"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-network"}},[t._v("#")]),t._v(" set_network "),a("Badge",{attrs:{text:"FlightPlanningDomain",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"set_network",sig:{params:[{name:"self"},{name:"p0",annotation:"<class 'pygeodesy.ellipsoidalVincenty.LatLon'>"},{name:"p1",annotation:"<class 'pygeodesy.ellipsoidalVincenty.LatLon'>"},{name:"nb_forward_points",annotation:"<class 'int'>"},{name:"nb_lateral_points",annotation:"<class 'int'>"},{name:"nb_climb_descent_steps",annotation:"<class 'int'>"},{name:"flight_levels_ft",annotation:"list[float]"},{name:"graph_width",default:"medium",annotation:"<class 'str'>"}]}}}),t._v(" "),a("p",[t._v("Creation of the airway graph.")]),t._v(" "),a("h4",{attrs:{id:"parameters-21"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-21"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("p",[t._v("p0 : Origin of the flight plan\np1 : Destination of the flight plan\nnb_forward_points (int): Number of forward points in the graph\nnb_lateral_points (int): Number of lateral points in the graph\nnb_climb_descent_steps (int): Number of steps in climb and descent\nflight_levels_ft (list[float]): list of flight levels during cruise\ngraph_width (str, optional): small, medium and wide strings (default to medium)")]),t._v(" "),a("h4",{attrs:{id:"returns-26"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-26"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("A 3D matrix containing for each points its latitude, longitude, altitude between origin & destination.\n")])])]),a("h3",{attrs:{id:"step"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step"}},[t._v("#")]),t._v(" step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment.step()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Environment._step()")]),t._v(" (which\nreturns a transition outcome). The boilerplate code automatically stores next state into the "),a("code",[t._v("_memory")]),t._v(" attribute\nand samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment.step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment.step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable.reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-22"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-22"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-27"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-27"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"check-value-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#check-value-2"}},[t._v("#")]),t._v(" _check_value "),a("Badge",{attrs:{text:"Rewards",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_check_value",sig:{params:[{name:"self"},{name:"value",annotation:"Value[D.T_value]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Check that a value is compliant with its cost specification (must be positive).")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("This function calls "),a("code",[t._v("PositiveCost._is_positive()")]),t._v(" to determine if a value is positive (can be overridden for\nadvanced value types).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-23"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-23"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("value")]),t._v(": The value to check.")])]),t._v(" "),a("h4",{attrs:{id:"returns-28"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-28"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the value is compliant (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"get-action-mask-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-action-mask-2"}},[t._v("#")]),t._v(" _get_action_mask "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_action_mask",sig:{params:[{name:"self"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"D.T_agent[Mask]"}}}),t._v(" "),a("p",[t._v("Get action mask for the given memory or internal one if omitted.")]),t._v(" "),a("p",[t._v("An action mask is another (more specific) format for applicable actions, that has a meaning only if the action\nspace can be iterated over in some way. It is represented by a flat array of 0's and 1's ordered as the actions\nwhen enumerated: 1 for an applicable action, and 0 for a not applicable action.")]),t._v(" "),a("p",[t._v("More precisely, this implementation makes the assumption that each agent action space is an "),a("code",[t._v("EnumerableSpace")]),t._v(",\nand calls internally "),a("code",[t._v("self.get_applicable_action()")]),t._v(".")]),t._v(" "),a("p",[t._v("The action mask is used for instance by RL solvers to shut down logits associated to non-applicable actions in\nthe output of their internal neural network.")]),t._v(" "),a("h4",{attrs:{id:"parameters-24"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-24"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider. If None, works on the internal memory of the domain.")])]),t._v(" "),a("h4",{attrs:{id:"returns-29"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-29"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("a numpy array (or dict agent-> numpy array for multi-agent domains) with 0-1 indicating applicability of\nthe action (1 meaning applicable and 0 not applicable)")]),t._v(" "),a("h3",{attrs:{id:"get-action-space-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-action-space-2"}},[t._v("#")]),t._v(" _get_action_space "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_action_space",sig:{params:[{name:"self"}],return:"D.T_agent[Space[D.T_event]]"}}}),t._v(" "),a("p",[t._v("Get the (cached) domain action space (finite or infinite set).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events._get_action_space()")]),t._v(" internally calls "),a("code",[t._v("Events._get_action_space_()")]),t._v(" the first time and\nautomatically caches its value to make future calls more efficient (since the action space is assumed to be\nconstant).")]),t._v(" "),a("h4",{attrs:{id:"returns-30"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-30"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The action space.")]),t._v(" "),a("h3",{attrs:{id:"get-action-space-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-action-space-3"}},[t._v("#")]),t._v(" _get_action_space_ "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_action_space_",sig:{params:[{name:"self"}],return:"skdecide.core.Space[argparse.Action]"}}}),t._v(" "),a("p",[t._v("Define action space.")]),t._v(" "),a("h3",{attrs:{id:"get-applicable-actions-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-applicable-actions-2"}},[t._v("#")]),t._v(" _get_applicable_actions "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_applicable_actions",sig:{params:[{name:"self"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"D.T_agent[Space[D.T_event]]"}}}),t._v(" "),a("p",[t._v("Get the space (finite or infinite set) of applicable actions in the given memory (state or history), or in\nthe internal one if omitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events._get_applicable_actions()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._get_applicable_actions_from()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute\ninstead of the memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-25"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-25"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-31"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-31"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The space of applicable actions.")]),t._v(" "),a("h3",{attrs:{id:"get-applicable-actions-from"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-applicable-actions-from"}},[t._v("#")]),t._v(" _get_applicable_actions_from "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_applicable_actions_from",sig:{params:[{name:"self"},{name:"state",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"}],return:"skdecide.core.Space[argparse.Action]"}}}),t._v(" "),a("p",[t._v("Get the applicable actions from a state.")]),t._v(" "),a("h3",{attrs:{id:"get-enabled-events-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-enabled-events-2"}},[t._v("#")]),t._v(" _get_enabled_events "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_enabled_events",sig:{params:[{name:"self"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"Space[D.T_event]"}}}),t._v(" "),a("p",[t._v("Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or\nhistory), or in the internal one if omitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events._get_enabled_events()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._get_enabled_events_from()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute\ninstead of the memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-26"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-26"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-32"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-32"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The space of enabled events.")]),t._v(" "),a("h3",{attrs:{id:"get-enabled-events-from"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-enabled-events-from"}},[t._v("#")]),t._v(" _get_enabled_events_from "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_enabled_events_from",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"Space[D.T_event]"}}}),t._v(" "),a("p",[t._v("Get the space (finite or infinite set) of enabled uncontrollable events in the given memory (state or\nhistory).")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Events._get_enabled_events()")]),t._v(", the difference being that the\nmemory parameter is mandatory here.")]),t._v(" "),a("h4",{attrs:{id:"parameters-27"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-27"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-33"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-33"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The space of enabled events.")]),t._v(" "),a("h3",{attrs:{id:"get-goals-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-goals-2"}},[t._v("#")]),t._v(" _get_goals "),a("Badge",{attrs:{text:"Goals",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_goals",sig:{params:[{name:"self"}],return:"D.T_agent[Space[D.T_observation]]"}}}),t._v(" "),a("p",[t._v("Get the (cached) domain goals space (finite or infinite set).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Goals._get_goals()")]),t._v(" internally calls "),a("code",[t._v("Goals._get_goals_()")]),t._v(" the first time and automatically caches\nits value to make future calls more efficient (since the goals space is assumed to be constant).")]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Goal states are assumed to be fully observable (i.e. observation = state) so that there is never uncertainty\nabout whether the goal has been reached or not. This assumption guarantees that any policy that does not\nreach the goal with certainty incurs in infinite expected cost. - "),a("em",[t._v("Geffner, 2013: A Concise Introduction to\nModels and Methods for Automated Planning")])])]),t._v(" "),a("h4",{attrs:{id:"returns-34"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-34"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The goals space.")]),t._v(" "),a("h3",{attrs:{id:"get-goals-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-goals-3"}},[t._v("#")]),t._v(" _get_goals_ "),a("Badge",{attrs:{text:"Goals",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_goals_",sig:{params:[{name:"self"}],return:"skdecide.core.Space[skdecide.hub.domain.flight_planning.domain.State]"}}}),t._v(" "),a("p",[t._v("Get the domain goals space (finite or infinite set).")]),t._v(" "),a("p",[t._v("Set the end position as goal.")]),t._v(" "),a("h3",{attrs:{id:"get-initial-state-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-initial-state-2"}},[t._v("#")]),t._v(" _get_initial_state "),a("Badge",{attrs:{text:"DeterministicInitialized",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_initial_state",sig:{params:[{name:"self"}],return:"D.T_state"}}}),t._v(" "),a("p",[t._v("Get the (cached) initial state.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("DeterministicInitialized._get_initial_state()")]),t._v(" internally\ncalls "),a("code",[t._v("DeterministicInitialized._get_initial_state_()")]),t._v(" the first time and automatically caches its value to make\nfuture calls more efficient (since the initial state is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-35"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-35"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The initial state.")]),t._v(" "),a("h3",{attrs:{id:"get-initial-state-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-initial-state-3"}},[t._v("#")]),t._v(" _get_initial_state_ "),a("Badge",{attrs:{text:"DeterministicInitialized",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_initial_state_",sig:{params:[{name:"self"}],return:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"}}}),t._v(" "),a("p",[t._v("Get the initial state.")]),t._v(" "),a("p",[t._v("Set the start position as initial state.")]),t._v(" "),a("h3",{attrs:{id:"get-initial-state-distribution-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-initial-state-distribution-2"}},[t._v("#")]),t._v(" _get_initial_state_distribution "),a("Badge",{attrs:{text:"UncertainInitialized",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_initial_state_distribution",sig:{params:[{name:"self"}],return:"Distribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the (cached) probability distribution of initial states.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainInitialized._get_initial_state_distribution()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainInitialized._get_initial_state_distribution_()")]),t._v(" the first time and automatically caches its value\nto make future calls more efficient (since the initial state distribution is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-36"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-36"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of initial states.")]),t._v(" "),a("h3",{attrs:{id:"get-initial-state-distribution-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-initial-state-distribution-3"}},[t._v("#")]),t._v(" _get_initial_state_distribution_ "),a("Badge",{attrs:{text:"UncertainInitialized",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_initial_state_distribution_",sig:{params:[{name:"self"}],return:"Distribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the probability distribution of initial states.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("UncertainInitialized._get_initial_state_distribution()")]),t._v(", the\ndifference being that the result is not cached here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("The underscore at the end of this function's name is a convention to remind that its result should be\nconstant.")])]),t._v(" "),a("h4",{attrs:{id:"returns-37"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-37"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of initial states.")]),t._v(" "),a("h3",{attrs:{id:"get-memory-maxlen"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-memory-maxlen"}},[t._v("#")]),t._v(" _get_memory_maxlen "),a("Badge",{attrs:{text:"History",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_memory_maxlen",sig:{params:[{name:"self"}],return:"int"}}}),t._v(" "),a("p",[t._v("Get the (cached) memory max length.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("FiniteHistory._get_memory_maxlen()")]),t._v(" internally calls "),a("code",[t._v("FiniteHistory._get_memory_maxlen_()")]),t._v(" the first\ntime and automatically caches its value to make future calls more efficient (since the memory max length is\nassumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-38"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-38"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The memory max length.")]),t._v(" "),a("h3",{attrs:{id:"get-memory-maxlen-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-memory-maxlen-2"}},[t._v("#")]),t._v(" _get_memory_maxlen_ "),a("Badge",{attrs:{text:"FiniteHistory",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_memory_maxlen_",sig:{params:[{name:"self"}],return:"int"}}}),t._v(" "),a("p",[t._v("Get the memory max length.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("FiniteHistory._get_memory_maxlen()")]),t._v(", the difference being that\nthe result is not cached here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("The underscore at the end of this function's name is a convention to remind that its result should be\nconstant.")])]),t._v(" "),a("h4",{attrs:{id:"returns-39"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-39"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The memory max length.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-2"}},[t._v("#")]),t._v(" _get_next_state "),a("Badge",{attrs:{text:"DeterministicTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_next_state",sig:{params:[{name:"self"},{name:"memory",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"},{name:"action",annotation:"<class 'argparse.Action'>"}],return:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"}}}),t._v(" "),a("p",[t._v("Compute the next state, adapted to work with the structure of the generated flight graph.")]),t._v(" "),a("p",[t._v("Args:\nmemory (D.T_state): The current state.\naction (D.T_event): The action to perform.")]),t._v(" "),a("p",[t._v("Returns:\nD.T_state: The next state, or the current state if the action is not possible.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution-2"}},[t._v("#")]),t._v(" _get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"SingleValueDistribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the discrete probability distribution of next state given a memory and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("In the Markovian case (memory only holds last state "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.061ex",height:"1.023ex",viewBox:"0 -442 469 452"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})])])])])]),t._v("), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function can\nbe mathematically represented by "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.292ex",height:"2.283ex",viewBox:"0 -759 4107.1 1009"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"msup",transform:"translate(1140, 0)"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1997.5, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2275.5, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2744.5, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3189.1, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3718.1, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(", where "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.94ex",height:"1.767ex",viewBox:"0 -759 857.5 781"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"msup"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])])])])])]),t._v(" is the next state random variable.")],1)]),t._v(" "),a("h4",{attrs:{id:"parameters-28"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-28"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-40"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-40"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The discrete probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-observation-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-observation-2"}},[t._v("#")]),t._v(" _get_observation "),a("Badge",{attrs:{text:"TransformedObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_observation",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"},{name:"action",default:"None",annotation:"Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}],return:"D.T_agent[D.T_observation]"}}}),t._v(" "),a("p",[t._v("Get the deterministic observation given a state and action.")]),t._v(" "),a("h4",{attrs:{id:"parameters-29"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-29"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to be observed.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The last applied action (or None if the state is an initial state).")])]),t._v(" "),a("h4",{attrs:{id:"returns-41"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-41"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of the observation.")]),t._v(" "),a("h3",{attrs:{id:"get-observation-distribution-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-observation-distribution-2"}},[t._v("#")]),t._v(" _get_observation_distribution "),a("Badge",{attrs:{text:"PartiallyObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_observation_distribution",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"},{name:"action",default:"None",annotation:"Optional[D.T_agent[D.T_concurrency[D.T_event]]]"}],return:"Distribution[D.T_agent[D.T_observation]]"}}}),t._v(" "),a("p",[t._v("Get the probability distribution of the observation given a state and action.")]),t._v(" "),a("p",[t._v("In mathematical terms (discrete case), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function represents: "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.078ex",height:"2.262ex",viewBox:"0 -750 4012.7 1000"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(1140, 0)"}},[a("path",{attrs:{"data-c":"4F",d:"M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1903, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2181, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2650, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3094.7, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3623.7, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(",\nwhere "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.726ex",height:"1.643ex",viewBox:"0 -704 763 726"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"4F",d:"M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"}})])])])])]),t._v(" is the random variable of the observation.")],1),t._v(" "),a("h4",{attrs:{id:"parameters-30"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-30"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to be observed.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The last applied action (or None if the state is an initial state).")])]),t._v(" "),a("h4",{attrs:{id:"returns-42"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-42"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of the observation.")]),t._v(" "),a("h3",{attrs:{id:"get-observation-space-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-observation-space-2"}},[t._v("#")]),t._v(" _get_observation_space "),a("Badge",{attrs:{text:"PartiallyObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_observation_space",sig:{params:[{name:"self"}],return:"D.T_agent[Space[D.T_observation]]"}}}),t._v(" "),a("p",[t._v("Get the (cached) observation space (finite or infinite set).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("PartiallyObservable._get_observation_space()")]),t._v(" internally\ncalls "),a("code",[t._v("PartiallyObservable._get_observation_space_()")]),t._v(" the first time and automatically caches its value to make\nfuture calls more efficient (since the observation space is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-43"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-43"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The observation space.")]),t._v(" "),a("h3",{attrs:{id:"get-observation-space-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-observation-space-3"}},[t._v("#")]),t._v(" _get_observation_space_ "),a("Badge",{attrs:{text:"PartiallyObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_observation_space_",sig:{params:[{name:"self"}],return:"skdecide.core.Space[skdecide.hub.domain.flight_planning.domain.State]"}}}),t._v(" "),a("p",[t._v("Define observation space.")]),t._v(" "),a("h3",{attrs:{id:"get-terminal-state-time-fuel"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-terminal-state-time-fuel"}},[t._v("#")]),t._v(" _get_terminal_state_time_fuel "),a("Badge",{attrs:{text:"FlightPlanningDomain",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_terminal_state_time_fuel",sig:{params:[{name:"self"},{name:"state",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"}],return:"<class 'dict'>"}}}),t._v(" "),a("p",[t._v("Get the domain terminal state information to compare with the constraints")]),t._v(" "),a("p",[t._v("Args:\nstate (State): terminal state to retrieve the information on fuel and time.")]),t._v(" "),a("p",[t._v("Returns:\ndict: dictionnary containing both fuel and time information.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value-2"}},[t._v("#")]),t._v(" _get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"},{name:"action",annotation:"<class 'argparse.Action'>"},{name:"next_state",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"}],return:"skdecide.core.Value[float]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.\nSet cost to distance travelled between points")]),t._v(" "),a("p",[t._v("Args:\nmemory (D.T_state): The current state\naction (D.T_event): The action to perform\nnext_state (Optional[D.T_state], optional): The next state. Defaults to None.")]),t._v(" "),a("p",[t._v("Returns:\nValue[D.T_value]: Cost to go from memory to next state")]),t._v(" "),a("h3",{attrs:{id:"init-memory"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#init-memory"}},[t._v("#")]),t._v(" _init_memory "),a("Badge",{attrs:{text:"History",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_init_memory",sig:{params:[{name:"self"},{name:"state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_memory[D.T_state]"}}}),t._v(" "),a("p",[t._v("Initialize memory (possibly with a state) according to its specification and return it.")]),t._v(" "),a("p",[t._v("This function is automatically called by "),a("code",[t._v("Initializable._reset()")]),t._v(" to reinitialize the internal memory whenever\nthe domain is used as an environment.")]),t._v(" "),a("h4",{attrs:{id:"parameters-31"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-31"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": An optional state to initialize the memory with (typically the initial state).")])]),t._v(" "),a("h4",{attrs:{id:"returns-44"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-44"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The new initialized memory.")]),t._v(" "),a("h3",{attrs:{id:"is-action-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-action-2"}},[t._v("#")]),t._v(" _is_action "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_action",sig:{params:[{name:"self"},{name:"event",annotation:"D.T_event"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an event is an action (i.e. a controllable event for the agents).")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the domain\naction space provided by "),a("code",[t._v("Events._get_action_space()")]),t._v(", but it can be overridden for faster implementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-32"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-32"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("event")]),t._v(": The event to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-45"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-45"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the event is an action (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-applicable-action-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-applicable-action-2"}},[t._v("#")]),t._v(" _is_applicable_action "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_applicable_action",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_event]"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an action is applicable in the given memory (state or history), or in the internal one if\nomitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events._is_applicable_action()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._is_applicable_action_from()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute\ninstead of the memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-33"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-33"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-46"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-46"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the action is applicable (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-applicable-action-from"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-applicable-action-from"}},[t._v("#")]),t._v(" _is_applicable_action_from "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_applicable_action_from",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_event]"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an action is applicable in the given memory (state or history).")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Events._is_applicable_action()")]),t._v(", the difference being that the\nmemory parameter is mandatory here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the space of\napplicable actions provided by "),a("code",[t._v("Events._get_applicable_actions_from()")]),t._v(", but it can be overridden for faster\nimplementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-34"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-34"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-47"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-47"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the action is applicable (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-enabled-event-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-enabled-event-2"}},[t._v("#")]),t._v(" _is_enabled_event "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_enabled_event",sig:{params:[{name:"self"},{name:"event",annotation:"D.T_event"},{name:"memory",default:"None",annotation:"Optional[D.T_memory[D.T_state]]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an uncontrollable event is enabled in the given memory (state or history), or in the\ninternal one if omitted.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Events._is_enabled_event()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Events._is_enabled_event_from()")]),t._v(". The boilerplate code automatically passes the "),a("code",[t._v("_memory")]),t._v(" attribute instead\nof the memory parameter whenever the latter is None.")]),t._v(" "),a("h4",{attrs:{id:"parameters-35"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-35"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider (if None, the internal memory attribute "),a("code",[t._v("_memory")]),t._v(" is used instead).")])]),t._v(" "),a("h4",{attrs:{id:"returns-48"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-48"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the event is enabled (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-enabled-event-from"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-enabled-event-from"}},[t._v("#")]),t._v(" _is_enabled_event_from "),a("Badge",{attrs:{text:"Events",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_enabled_event_from",sig:{params:[{name:"self"},{name:"event",annotation:"D.T_event"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether an event is enabled in the given memory (state or history).")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Events._is_enabled_event()")]),t._v(", the difference being that the\nmemory parameter is mandatory here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the space of\nenabled events provided by "),a("code",[t._v("Events._get_enabled_events_from()")]),t._v(", but it can be overridden for faster\nimplementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-36"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-36"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-49"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-49"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the event is enabled (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-goal-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-goal-2"}},[t._v("#")]),t._v(" _is_goal "),a("Badge",{attrs:{text:"Goals",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_goal",sig:{params:[{name:"self"},{name:"observation",annotation:"D.T_agent[D.T_observation]"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether an observation belongs to the goals.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the domain\ngoals space provided by "),a("code",[t._v("Goals._get_goals()")]),t._v(", but it can be overridden for faster implementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-37"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-37"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("observation")]),t._v(": The observation to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-50"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-50"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the observation is a goal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-observation-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-observation-2"}},[t._v("#")]),t._v(" _is_observation "),a("Badge",{attrs:{text:"PartiallyObservable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_observation",sig:{params:[{name:"self"},{name:"observation",annotation:"D.T_agent[D.T_observation]"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Check that an observation indeed belongs to the domain observation space.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("By default, this function is implemented using the "),a("code",[t._v("skdecide.core.Space.contains()")]),t._v(" function on the domain\nobservation space provided by "),a("code",[t._v("PartiallyObservable._get_observation_space()")]),t._v(", but it can be overridden for\nfaster implementations.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-38"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-38"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("observation")]),t._v(": The observation to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-51"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-51"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the observation belongs to the domain observation space (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-positive"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-positive"}},[t._v("#")]),t._v(" _is_positive "),a("Badge",{attrs:{text:"PositiveCosts",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_positive",sig:{params:[{name:"self"},{name:"cost",annotation:"D.T_value"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Determine if a value is positive (can be overridden for advanced value types).")]),t._v(" "),a("h4",{attrs:{id:"parameters-39"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-39"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("cost")]),t._v(": The cost to evaluate.")])]),t._v(" "),a("h4",{attrs:{id:"returns-52"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-52"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the cost is positive (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal-2"}},[t._v("#")]),t._v(" _is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.State'>"}],return:"<class 'bool'>"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("Stop an episode only when goal reached.")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-2"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-53"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-53"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-3"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state_ "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state_",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation.")]),t._v(" "),a("p",[t._v("This is a helper function called by default\nfrom "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(", the difference being that the result\nis not cached here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("The underscore at the end of this function's name is a convention to remind that its result should be\nconstant.")])]),t._v(" "),a("h4",{attrs:{id:"returns-54"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-54"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"reset-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reset-2"}},[t._v("#")]),t._v(" _reset "),a("Badge",{attrs:{text:"Initializable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_reset",sig:{params:[{name:"self"}],return:"D.T_agent[D.T_observation]"}}}),t._v(" "),a("p",[t._v("Reset the state of the environment and return an initial observation.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Initializable._reset()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Initializable._state_reset()")]),t._v(" (which returns an initial state). The boilerplate code automatically stores\nthe initial state into the "),a("code",[t._v("_memory")]),t._v(" attribute and samples a corresponding observation.")]),t._v(" "),a("h4",{attrs:{id:"returns-55"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-55"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("An initial observation.")]),t._v(" "),a("h3",{attrs:{id:"sample-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-2"}},[t._v("#")]),t._v(" _sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation._sample()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Simulation._state_sample()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically\nsamples an observation corresponding to the sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation._sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._state_sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-40"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-40"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-56"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-56"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-2"}},[t._v("#")]),t._v(" _set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with\nsuccessive '),a("code",[t._v("Environment._step()")]),t._v(" calls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-41"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-41"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-2"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"state-reset"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-reset"}},[t._v("#")]),t._v(" _state_reset "),a("Badge",{attrs:{text:"Initializable",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_reset",sig:{params:[{name:"self"}],return:"D.T_state"}}}),t._v(" "),a("p",[t._v("Reset the state of the environment and return an initial state.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Initializable._reset()")]),t._v(". It focuses on the state level, as\nopposed to the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"returns-57"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-57"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("An initial state.")]),t._v(" "),a("h3",{attrs:{id:"state-sample"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-sample"}},[t._v("#")]),t._v(" _state_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one sample of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Simulation._sample()")]),t._v(". It focuses on the state level, as\nopposed to the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-42"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-42"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-58"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-58"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"state-step"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-step"}},[t._v("#")]),t._v(" _state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one step of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Environment._step()")]),t._v(". It focuses on the state level, as opposed\nto the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-43"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-43"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-59"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-59"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"step-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-2"}},[t._v("#")]),t._v(" _step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment._step()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Environment._state_step()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically stores\nnext state into the "),a("code",[t._v("_memory")]),t._v(" attribute and samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment._step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._state_step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment._step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable._reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-44"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-44"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-60"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-60"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h2",{attrs:{id:"fuel-optimisation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fuel-optimisation"}},[t._v("#")]),t._v(" fuel_optimisation")]),t._v(" "),a("skdecide-signature",{attrs:{name:"fuel_optimisation",sig:{params:[{name:"origin",annotation:"typing.Union[str, tuple]"},{name:"destination",annotation:"typing.Union[str, tuple]"},{name:"aircraft_state",annotation:"<class 'skdecide.hub.domain.flight_planning.aircraft_performance.bean.aircraft_state.AircraftState'>"},{name:"cruise_height_min",annotation:"<class 'float'>"},{name:"cruise_height_max",annotation:"<class 'float'>"},{name:"constraints",annotation:"<class 'dict'>"},{name:"weather_date",annotation:"<class 'skdecide.hub.domain.flight_planning.domain.WeatherDate'>"},{name:"solver_cls",annotation:"type[skdecide.solvers.Solver]"},{name:"solver_kwargs",annotation:"dict[str, typing.Any]"},{name:"max_steps",default:"100",annotation:"<class 'int'>"},{name:"fuel_tol",default:"0.001",annotation:"<class 'float'>"}],return:"<class 'float'>"}}}),t._v(" "),a("p",[t._v("Function to optimise the fuel loaded in the plane, doing multiple fuel loops to approach an optimal")]),t._v(" "),a("h4",{attrs:{id:"parameters-45"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-45"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("p",[t._v("origin (Union[str, tuple]):\nICAO code of the departure airport of th flight plan e.g LFPG for Paris-CDG, or a tuple (lat,lon)")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("destination (Union[str, tuple]):\n    ICAO code of the arrival airport of th flight plan e.g LFBO for Toulouse-Blagnac airport, or a tuple (lat,lon)\n\naircraft_state (AircraftState)\n    Initial aircraft state.\n\ncruise_height_min (float)\n    Minimum cruise height in ft\n\ncruise_height_max (float)\n    Maximum cruise height in ft\n\nconstraints (dict):\n    Constraints that will be defined for the flight plan\n\nsolver_cls (type[Solver]):\n    Solver class used in the fuel loop.\n\nsolver_kwargs (dict[str, Any]):\n    Kwargs to initialize the solver used in the fuel loop.\n\nmax_steps (int):\n    max steps to use in the internal fuel loop\n\nfuel_tol (float):\n    tolerance on fuel used to stop the optimization\n")])])]),a("h4",{attrs:{id:"returns-61"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-61"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("float:\n    Return the quantity of fuel to be loaded in the plane for the flight\n")])])])],1)}),[],!1,null,null,null);e.default=n.exports}}]);