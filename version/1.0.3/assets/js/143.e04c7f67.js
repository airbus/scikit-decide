(window.webpackJsonp=window.webpackJsonp||[]).push([[143],{657:function(a,e,t){"use strict";t.r(e);var s=t(38),n=Object(s.a)({},(function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"hub-solver-stable-baselines-autoregressive-common-buffers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hub-solver-stable-baselines-autoregressive-common-buffers"}},[a._v("#")]),a._v(" hub.solver.stable_baselines.autoregressive.common.buffers")]),a._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[a._v("Domain specification")]),a._v(" "),t("skdecide-summary")],1),a._v(" "),t("h2",{attrs:{id:"applicableactionsrolloutbuffer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#applicableactionsrolloutbuffer"}},[a._v("#")]),a._v(" ApplicableActionsRolloutBuffer")]),a._v(" "),t("p",[a._v("Rollout buffer storing also applicable actions.")]),a._v(" "),t("p",[a._v("For each step, applicable actions are stored as a numpy array N,M with")]),a._v(" "),t("ul",[t("li",[a._v("N: nb of applicable actions")]),a._v(" "),t("li",[a._v("M: flattened dim of action space")])]),a._v(" "),t("p",[a._v("As the number of applicable actions vary, we have to use a list of numpy arrays\ninstead of a single numpy array to store them in the buffer.")]),a._v(" "),t("p",[a._v("(And at first it comes as a list of list because of sb3 vectorized environment)")]),a._v(" "),t("h3",{attrs:{id:"constructor"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#constructor"}},[a._v("#")]),a._v(" Constructor "),t("Badge",{attrs:{text:"ApplicableActionsRolloutBuffer",type:"tip"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"ApplicableActionsRolloutBuffer",sig:{params:[{name:"buffer_size",annotation:"<class 'int'>"},{name:"observation_space",annotation:"<class 'gymnasium.spaces.space.Space'>"},{name:"action_space",annotation:"<class 'gymnasium.spaces.space.Space'>"},{name:"device",default:"auto",annotation:"typing.Union[torch.device, str]"},{name:"gae_lambda",default:"1",annotation:"<class 'float'>"},{name:"gamma",default:"0.99",annotation:"<class 'float'>"},{name:"n_envs",default:"1",annotation:"<class 'int'>"}]}}}),a._v(" "),t("p",[a._v("Initialize self.  See help(type(self)) for accurate signature.")]),a._v(" "),t("h3",{attrs:{id:"add"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#add"}},[a._v("#")]),a._v(" add "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"add",sig:{params:[{name:"self"},{name:"*args"},{name:"action_masks",default:"None",annotation:"typing.Optional[numpy.ndarray]"},{name:"**kwargs"}],return:null}}}),a._v(" "),t("p",[a._v(":param action_masks: Masks applied to constrain the choice of possible actions.")]),a._v(" "),t("h3",{attrs:{id:"compute-returns-and-advantage"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#compute-returns-and-advantage"}},[a._v("#")]),a._v(" compute_returns_and_advantage "),t("Badge",{attrs:{text:"RolloutBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"compute_returns_and_advantage",sig:{params:[{name:"self"},{name:"last_values",annotation:"<class 'torch.Tensor'>"},{name:"dones",annotation:"<class 'numpy.ndarray'>"}],return:null}}}),a._v(" "),t("p",[a._v("Post-processing step: compute the lambda-return (TD(lambda) estimate)\nand GAE(lambda) advantage.")]),a._v(" "),t("p",[a._v("Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\nto compute the advantage. To obtain Monte-Carlo advantage estimate (A(s) = R - V(S))\nwhere R is the sum of discounted reward with value bootstrap\n(because we don't always have full episode), set "),t("code",[a._v("gae_lambda=1.0")]),a._v(" during initialization.")]),a._v(" "),t("p",[a._v("The TD(lambda) estimator has also two special cases:")]),a._v(" "),t("ul",[t("li",[a._v("TD(1) is Monte-Carlo estimate (sum of discounted rewards)")]),a._v(" "),t("li",[a._v("TD(0) is one-step estimate with bootstrapping (r_t + gamma * v(s_{t+1}))")])]),a._v(" "),t("p",[a._v("For more information, see discussion in https://github.com/DLR-RM/stable-baselines3/pull/375.")]),a._v(" "),t("p",[a._v(":param last_values: state value estimation for the last step (one for each env)\n:param dones: if the last step was a terminal step (one bool for each env).")]),a._v(" "),t("h3",{attrs:{id:"extend"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#extend"}},[a._v("#")]),a._v(" extend "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"extend",sig:{params:[{name:"self"},{name:"*args"},{name:"**kwargs"}],return:null}}}),a._v(" "),t("p",[a._v("Add a new batch of transitions to the buffer")]),a._v(" "),t("h3",{attrs:{id:"reset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reset"}},[a._v("#")]),a._v(" reset "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"reset",sig:{params:[{name:"self"}],return:null}}}),a._v(" "),t("p",[a._v("Reset the buffer.")]),a._v(" "),t("h3",{attrs:{id:"sample"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sample"}},[a._v("#")]),a._v(" sample "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"batch_size",annotation:"<class 'int'>"},{name:"env",default:"None",annotation:"typing.Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]"}]}}}),a._v(" "),t("p",[a._v(":param batch_size: Number of element to sample\n:param env: associated gym VecEnv\nto normalize the observations/rewards when sampling\n:return:")]),a._v(" "),t("h3",{attrs:{id:"size"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#size"}},[a._v("#")]),a._v(" size "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"size",sig:{params:[{name:"self"}],return:"<class 'int'>"}}}),a._v(" "),t("p",[a._v(":return: The current size of the buffer")]),a._v(" "),t("h3",{attrs:{id:"swap-and-flatten"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#swap-and-flatten"}},[a._v("#")]),a._v(" swap_and_flatten "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"swap_and_flatten",sig:{params:[{name:"arr",annotation:"<class 'numpy.ndarray'>"}],return:"<class 'numpy.ndarray'>"}}}),a._v(" "),t("p",[a._v("Swap and then flatten axes 0 (buffer_size) and 1 (n_envs)\nto convert shape from [n_steps, n_envs, ...] (when ... is the shape of the features)\nto [n_steps * n_envs, ...] (which maintain the order)")]),a._v(" "),t("p",[a._v(":param arr:\n:return:")]),a._v(" "),t("h3",{attrs:{id:"to-torch"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#to-torch"}},[a._v("#")]),a._v(" to_torch "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"to_torch",sig:{params:[{name:"self"},{name:"array",annotation:"<class 'numpy.ndarray'>"},{name:"copy",default:"True",annotation:"<class 'bool'>"}],return:"<class 'torch.Tensor'>"}}}),a._v(" "),t("p",[a._v("Convert a numpy array to a PyTorch tensor.\nNote: it copies the data by default")]),a._v(" "),t("p",[a._v(":param array:\n:param copy: Whether to copy or not the data (may be useful to avoid changing things\nby reference). This argument is inoperative if the device is not the CPU.\n:return:")]),a._v(" "),t("h3",{attrs:{id:"swap-and-flatten-action-masks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#swap-and-flatten-action-masks"}},[a._v("#")]),a._v(" _swap_and_flatten_action_masks "),t("Badge",{attrs:{text:"ScikitDecideRolloutBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"_swap_and_flatten_action_masks",sig:{params:[{name:"self"}],return:null}}}),a._v(" "),t("p",[a._v("Method to override in buffers meant to be used with action masks.")]),a._v(" "),t("h2",{attrs:{id:"applicableactionsgraphrolloutbuffer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#applicableactionsgraphrolloutbuffer"}},[a._v("#")]),a._v(" ApplicableActionsGraphRolloutBuffer")]),a._v(" "),t("p",[a._v("Buffer to store graph obs + applicable actions.")]),a._v(" "),t("p",[a._v("Both have variable shape thus need a dedicated buffer that will not initialize the buffer with fixed shapes.")]),a._v(" "),t("h3",{attrs:{id:"constructor-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#constructor-2"}},[a._v("#")]),a._v(" Constructor "),t("Badge",{attrs:{text:"ApplicableActionsGraphRolloutBuffer",type:"tip"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"ApplicableActionsGraphRolloutBuffer",sig:{params:[{name:"buffer_size",annotation:"<class 'int'>"},{name:"observation_space",annotation:"<class 'gymnasium.spaces.space.Space'>"},{name:"action_space",annotation:"<class 'gymnasium.spaces.space.Space'>"},{name:"device",default:"auto",annotation:"typing.Union[torch.device, str]"},{name:"gae_lambda",default:"1",annotation:"<class 'float'>"},{name:"gamma",default:"0.99",annotation:"<class 'float'>"},{name:"n_envs",default:"1",annotation:"<class 'int'>"}]}}}),a._v(" "),t("p",[a._v("Initialize self.  See help(type(self)) for accurate signature.")]),a._v(" "),t("h3",{attrs:{id:"add-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#add-2"}},[a._v("#")]),a._v(" add "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"add",sig:{params:[{name:"self"},{name:"*args"},{name:"action_masks",default:"None",annotation:"typing.Optional[numpy.ndarray]"},{name:"**kwargs"}],return:null}}}),a._v(" "),t("p",[a._v(":param action_masks: Masks applied to constrain the choice of possible actions.")]),a._v(" "),t("h3",{attrs:{id:"compute-returns-and-advantage-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#compute-returns-and-advantage-2"}},[a._v("#")]),a._v(" compute_returns_and_advantage "),t("Badge",{attrs:{text:"RolloutBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"compute_returns_and_advantage",sig:{params:[{name:"self"},{name:"last_values",annotation:"<class 'torch.Tensor'>"},{name:"dones",annotation:"<class 'numpy.ndarray'>"}],return:null}}}),a._v(" "),t("p",[a._v("Post-processing step: compute the lambda-return (TD(lambda) estimate)\nand GAE(lambda) advantage.")]),a._v(" "),t("p",[a._v("Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\nto compute the advantage. To obtain Monte-Carlo advantage estimate (A(s) = R - V(S))\nwhere R is the sum of discounted reward with value bootstrap\n(because we don't always have full episode), set "),t("code",[a._v("gae_lambda=1.0")]),a._v(" during initialization.")]),a._v(" "),t("p",[a._v("The TD(lambda) estimator has also two special cases:")]),a._v(" "),t("ul",[t("li",[a._v("TD(1) is Monte-Carlo estimate (sum of discounted rewards)")]),a._v(" "),t("li",[a._v("TD(0) is one-step estimate with bootstrapping (r_t + gamma * v(s_{t+1}))")])]),a._v(" "),t("p",[a._v("For more information, see discussion in https://github.com/DLR-RM/stable-baselines3/pull/375.")]),a._v(" "),t("p",[a._v(":param last_values: state value estimation for the last step (one for each env)\n:param dones: if the last step was a terminal step (one bool for each env).")]),a._v(" "),t("h3",{attrs:{id:"extend-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#extend-2"}},[a._v("#")]),a._v(" extend "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"extend",sig:{params:[{name:"self"},{name:"*args"},{name:"**kwargs"}],return:null}}}),a._v(" "),t("p",[a._v("Add a new batch of transitions to the buffer")]),a._v(" "),t("h3",{attrs:{id:"reset-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reset-2"}},[a._v("#")]),a._v(" reset "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"reset",sig:{params:[{name:"self"}],return:null}}}),a._v(" "),t("p",[a._v("Reset the buffer.")]),a._v(" "),t("h3",{attrs:{id:"sample-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sample-2"}},[a._v("#")]),a._v(" sample "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"batch_size",annotation:"<class 'int'>"},{name:"env",default:"None",annotation:"typing.Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]"}]}}}),a._v(" "),t("p",[a._v(":param batch_size: Number of element to sample\n:param env: associated gym VecEnv\nto normalize the observations/rewards when sampling\n:return:")]),a._v(" "),t("h3",{attrs:{id:"size-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#size-2"}},[a._v("#")]),a._v(" size "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"size",sig:{params:[{name:"self"}],return:"<class 'int'>"}}}),a._v(" "),t("p",[a._v(":return: The current size of the buffer")]),a._v(" "),t("h3",{attrs:{id:"swap-and-flatten-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#swap-and-flatten-2"}},[a._v("#")]),a._v(" swap_and_flatten "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"swap_and_flatten",sig:{params:[{name:"arr",annotation:"<class 'numpy.ndarray'>"}],return:"<class 'numpy.ndarray'>"}}}),a._v(" "),t("p",[a._v("Swap and then flatten axes 0 (buffer_size) and 1 (n_envs)\nto convert shape from [n_steps, n_envs, ...] (when ... is the shape of the features)\nto [n_steps * n_envs, ...] (which maintain the order)")]),a._v(" "),t("p",[a._v(":param arr:\n:return:")]),a._v(" "),t("h3",{attrs:{id:"to-torch-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#to-torch-2"}},[a._v("#")]),a._v(" to_torch "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"to_torch",sig:{params:[{name:"self"},{name:"array",annotation:"<class 'numpy.ndarray'>"},{name:"copy",default:"True",annotation:"<class 'bool'>"}],return:"<class 'torch.Tensor'>"}}}),a._v(" "),t("p",[a._v("Convert a numpy array to a PyTorch tensor.\nNote: it copies the data by default")]),a._v(" "),t("p",[a._v(":param array:\n:param copy: Whether to copy or not the data (may be useful to avoid changing things\nby reference). This argument is inoperative if the device is not the CPU.\n:return:")]),a._v(" "),t("h3",{attrs:{id:"swap-and-flatten-action-masks-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#swap-and-flatten-action-masks-2"}},[a._v("#")]),a._v(" _swap_and_flatten_action_masks "),t("Badge",{attrs:{text:"ScikitDecideRolloutBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"_swap_and_flatten_action_masks",sig:{params:[{name:"self"}],return:null}}}),a._v(" "),t("p",[a._v("Method to override in buffers meant to be used with action masks.")])],1)}),[],!1,null,null,null);e.default=n.exports}}]);