(window.webpackJsonp=window.webpackJsonp||[]).push([[148],{661:function(a,e,t){"use strict";t.r(e);var s=t(38),n=Object(s.a)({},(function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"hub-solver-stable-baselines-common-buffers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hub-solver-stable-baselines-common-buffers"}},[a._v("#")]),a._v(" hub.solver.stable_baselines.common.buffers")]),a._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[a._v("Domain specification")]),a._v(" "),t("skdecide-summary")],1),a._v(" "),t("h2",{attrs:{id:"scikitdeciderolloutbuffer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scikitdeciderolloutbuffer"}},[a._v("#")]),a._v(" ScikitDecideRolloutBuffer")]),a._v(" "),t("p",[a._v("Base class for scikit-decide customized RolloutBuffer.")]),a._v(" "),t("h3",{attrs:{id:"constructor"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#constructor"}},[a._v("#")]),a._v(" Constructor "),t("Badge",{attrs:{text:"ScikitDecideRolloutBuffer",type:"tip"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"ScikitDecideRolloutBuffer",sig:{params:[{name:"buffer_size",annotation:"<class 'int'>"},{name:"observation_space",annotation:"<class 'gymnasium.spaces.space.Space'>"},{name:"action_space",annotation:"<class 'gymnasium.spaces.space.Space'>"},{name:"device",default:"auto",annotation:"typing.Union[torch.device, str]"},{name:"gae_lambda",default:"1",annotation:"<class 'float'>"},{name:"gamma",default:"0.99",annotation:"<class 'float'>"},{name:"n_envs",default:"1",annotation:"<class 'int'>"}]}}}),a._v(" "),t("p",[a._v("Initialize self.  See help(type(self)) for accurate signature.")]),a._v(" "),t("h3",{attrs:{id:"add"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#add"}},[a._v("#")]),a._v(" add "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"add",sig:{params:[{name:"self"},{name:"obs",annotation:"<class 'numpy.ndarray'>"},{name:"action",annotation:"<class 'numpy.ndarray'>"},{name:"reward",annotation:"<class 'numpy.ndarray'>"},{name:"episode_start",annotation:"<class 'numpy.ndarray'>"},{name:"value",annotation:"<class 'torch.Tensor'>"},{name:"log_prob",annotation:"<class 'torch.Tensor'>"}],return:null}}}),a._v(" "),t("p",[a._v(":param obs: Observation\n:param action: Action\n:param reward:\n:param episode_start: Start of episode signal.\n:param value: estimated value of the current state\nfollowing the current policy.\n:param log_prob: log probability of the action\nfollowing the current policy.")]),a._v(" "),t("h3",{attrs:{id:"compute-returns-and-advantage"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#compute-returns-and-advantage"}},[a._v("#")]),a._v(" compute_returns_and_advantage "),t("Badge",{attrs:{text:"RolloutBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"compute_returns_and_advantage",sig:{params:[{name:"self"},{name:"last_values",annotation:"<class 'torch.Tensor'>"},{name:"dones",annotation:"<class 'numpy.ndarray'>"}],return:null}}}),a._v(" "),t("p",[a._v("Post-processing step: compute the lambda-return (TD(lambda) estimate)\nand GAE(lambda) advantage.")]),a._v(" "),t("p",[a._v("Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\nto compute the advantage. To obtain Monte-Carlo advantage estimate (A(s) = R - V(S))\nwhere R is the sum of discounted reward with value bootstrap\n(because we don't always have full episode), set "),t("code",[a._v("gae_lambda=1.0")]),a._v(" during initialization.")]),a._v(" "),t("p",[a._v("The TD(lambda) estimator has also two special cases:")]),a._v(" "),t("ul",[t("li",[a._v("TD(1) is Monte-Carlo estimate (sum of discounted rewards)")]),a._v(" "),t("li",[a._v("TD(0) is one-step estimate with bootstrapping (r_t + gamma * v(s_{t+1}))")])]),a._v(" "),t("p",[a._v("For more information, see discussion in https://github.com/DLR-RM/stable-baselines3/pull/375.")]),a._v(" "),t("p",[a._v(":param last_values: state value estimation for the last step (one for each env)\n:param dones: if the last step was a terminal step (one bool for each env).")]),a._v(" "),t("h3",{attrs:{id:"extend"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#extend"}},[a._v("#")]),a._v(" extend "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"extend",sig:{params:[{name:"self"},{name:"*args"},{name:"**kwargs"}],return:null}}}),a._v(" "),t("p",[a._v("Add a new batch of transitions to the buffer")]),a._v(" "),t("h3",{attrs:{id:"reset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reset"}},[a._v("#")]),a._v(" reset "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"reset",sig:{params:[{name:"self"}],return:null}}}),a._v(" "),t("p",[a._v("Reset the buffer.")]),a._v(" "),t("h3",{attrs:{id:"sample"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sample"}},[a._v("#")]),a._v(" sample "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"batch_size",annotation:"<class 'int'>"},{name:"env",default:"None",annotation:"typing.Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]"}]}}}),a._v(" "),t("p",[a._v(":param batch_size: Number of element to sample\n:param env: associated gym VecEnv\nto normalize the observations/rewards when sampling\n:return:")]),a._v(" "),t("h3",{attrs:{id:"size"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#size"}},[a._v("#")]),a._v(" size "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"size",sig:{params:[{name:"self"}],return:"<class 'int'>"}}}),a._v(" "),t("p",[a._v(":return: The current size of the buffer")]),a._v(" "),t("h3",{attrs:{id:"swap-and-flatten"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#swap-and-flatten"}},[a._v("#")]),a._v(" swap_and_flatten "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"swap_and_flatten",sig:{params:[{name:"arr",annotation:"<class 'numpy.ndarray'>"}],return:"<class 'numpy.ndarray'>"}}}),a._v(" "),t("p",[a._v("Swap and then flatten axes 0 (buffer_size) and 1 (n_envs)\nto convert shape from [n_steps, n_envs, ...] (when ... is the shape of the features)\nto [n_steps * n_envs, ...] (which maintain the order)")]),a._v(" "),t("p",[a._v(":param arr:\n:return:")]),a._v(" "),t("h3",{attrs:{id:"to-torch"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#to-torch"}},[a._v("#")]),a._v(" to_torch "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"to_torch",sig:{params:[{name:"self"},{name:"array",annotation:"<class 'numpy.ndarray'>"},{name:"copy",default:"True",annotation:"<class 'bool'>"}],return:"<class 'torch.Tensor'>"}}}),a._v(" "),t("p",[a._v("Convert a numpy array to a PyTorch tensor.\nNote: it copies the data by default")]),a._v(" "),t("p",[a._v(":param array:\n:param copy: Whether to copy or not the data (may be useful to avoid changing things\nby reference). This argument is inoperative if the device is not the CPU.\n:return:")]),a._v(" "),t("h3",{attrs:{id:"get-samples"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#get-samples"}},[a._v("#")]),a._v(" _get_samples "),t("Badge",{attrs:{text:"BaseBuffer",type:"warn"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"_get_samples",sig:{params:[{name:"self"},{name:"batch_inds",annotation:"<class 'numpy.ndarray'>"},{name:"env",default:"None",annotation:"typing.Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]"}],return:"<class 'stable_baselines3.common.type_aliases.RolloutBufferSamples'>"}}}),a._v(" "),t("p",[a._v(":param batch_inds:\n:param env:\n:return:")]),a._v(" "),t("h3",{attrs:{id:"swap-and-flatten-action-masks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#swap-and-flatten-action-masks"}},[a._v("#")]),a._v(" _swap_and_flatten_action_masks "),t("Badge",{attrs:{text:"ScikitDecideRolloutBuffer",type:"tip"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"_swap_and_flatten_action_masks",sig:{params:[{name:"self"}],return:null}}}),a._v(" "),t("p",[a._v("Method to override in buffers meant to be used with action masks.")]),a._v(" "),t("h2",{attrs:{id:"maskablescikitdeciderolloutbuffermixin"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#maskablescikitdeciderolloutbuffermixin"}},[a._v("#")]),a._v(" MaskableScikitDecideRolloutBufferMixin")]),a._v(" "),t("p",[a._v("Mixin to add to ScikitDecideRolloutBuffer for maskable buffers.")]),a._v(" "),t("h3",{attrs:{id:"add-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#add-2"}},[a._v("#")]),a._v(" add "),t("Badge",{attrs:{text:"MaskableScikitDecideRolloutBufferMixin",type:"tip"}})],1),a._v(" "),t("skdecide-signature",{attrs:{name:"add",sig:{params:[{name:"self"},{name:"*args"},{name:"action_masks",default:"None",annotation:"typing.Optional[numpy.ndarray]"},{name:"**kwargs"}],return:null}}}),a._v(" "),t("p",[a._v(":param action_masks: Masks applied to constrain the choice of possible actions.")])],1)}),[],!1,null,null,null);e.default=n.exports}}]);