(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{537:function(t,e,a){"use strict";a.r(e);var n=a(38),s=Object(n.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"builders-domain-dynamics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#builders-domain-dynamics"}},[t._v("#")]),t._v(" builders.domain.dynamics")]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#environment"}},[t._v("Environment")]),a("ul",[a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-tip"}},[t._v("step "),a("Badge",{attrs:{text:"Environment",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#state-step-badge-text-environment-type-tip"}},[t._v("_state_step "),a("Badge",{attrs:{text:"Environment",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-tip"}},[t._v("_step "),a("Badge",{attrs:{text:"Environment",type:"tip"}})],1)])])]),a("li",[a("a",{attrs:{href:"#simulation"}},[t._v("Simulation")]),a("ul",[a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-tip"}},[t._v("sample "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-tip"}},[t._v("set_memory "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-tip"}},[t._v("_sample "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-tip"}},[t._v("_set_memory "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#state-sample-badge-text-simulation-type-tip"}},[t._v("_state_sample "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#state-step-badge-text-environment-type-warn"}},[t._v("_state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)])])]),a("li",[a("a",{attrs:{href:"#uncertaintransitions"}},[t._v("UncertainTransitions")]),a("ul",[a("li",[a("a",{attrs:{href:"#get-next-state-distribution-badge-text-uncertaintransitions-type-tip"}},[t._v("get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#get-transition-value-badge-text-uncertaintransitions-type-tip"}},[t._v("get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#is-terminal-badge-text-uncertaintransitions-type-tip"}},[t._v("is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-tip"}},[t._v("is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-warn"}},[t._v("sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-warn"}},[t._v("set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#get-next-state-distribution-badge-text-uncertaintransitions-type-tip"}},[t._v("_get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#get-transition-value-badge-text-uncertaintransitions-type-tip"}},[t._v("_get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#is-terminal-badge-text-uncertaintransitions-type-tip"}},[t._v("_is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-tip"}},[t._v("_is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-tip"}},[t._v("_is_transition_value_dependent_on_next_state_ "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-warn"}},[t._v("_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-warn"}},[t._v("_set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#state-sample-badge-text-simulation-type-warn"}},[t._v("_state_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#state-step-badge-text-environment-type-warn"}},[t._v("_state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)])])]),a("li",[a("a",{attrs:{href:"#enumerabletransitions"}},[t._v("EnumerableTransitions")]),a("ul",[a("li",[a("a",{attrs:{href:"#get-next-state-distribution-badge-text-uncertaintransitions-type-warn"}},[t._v("get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#get-transition-value-badge-text-uncertaintransitions-type-warn"}},[t._v("get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-terminal-badge-text-uncertaintransitions-type-warn"}},[t._v("is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-warn"}},[t._v("is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-warn"}},[t._v("sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-warn"}},[t._v("set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#get-next-state-distribution-badge-text-uncertaintransitions-type-warn"}},[t._v("_get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#get-transition-value-badge-text-uncertaintransitions-type-warn"}},[t._v("_get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-terminal-badge-text-uncertaintransitions-type-warn"}},[t._v("_is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-warn"}},[t._v("_is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-warn"}},[t._v("_is_transition_value_dependent_on_next_state_ "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-warn"}},[t._v("_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-warn"}},[t._v("_set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#state-sample-badge-text-simulation-type-warn"}},[t._v("_state_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#state-step-badge-text-environment-type-warn"}},[t._v("_state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)])])]),a("li",[a("a",{attrs:{href:"#deterministictransitions"}},[t._v("DeterministicTransitions")]),a("ul",[a("li",[a("a",{attrs:{href:"#get-next-state-badge-text-deterministictransitions-type-tip"}},[t._v("get_next_state "),a("Badge",{attrs:{text:"DeterministicTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#get-next-state-distribution-badge-text-uncertaintransitions-type-warn"}},[t._v("get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#get-transition-value-badge-text-uncertaintransitions-type-warn"}},[t._v("get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-terminal-badge-text-uncertaintransitions-type-warn"}},[t._v("is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-warn"}},[t._v("is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-warn"}},[t._v("sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-warn"}},[t._v("set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#get-next-state-badge-text-deterministictransitions-type-tip"}},[t._v("_get_next_state "),a("Badge",{attrs:{text:"DeterministicTransitions",type:"tip"}})],1)]),a("li",[a("a",{attrs:{href:"#get-next-state-distribution-badge-text-uncertaintransitions-type-warn"}},[t._v("_get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#get-transition-value-badge-text-uncertaintransitions-type-warn"}},[t._v("_get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-terminal-badge-text-uncertaintransitions-type-warn"}},[t._v("_is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-warn"}},[t._v("_is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#is-transition-value-dependent-on-next-state-badge-text-uncertaintransitions-type-warn"}},[t._v("_is_transition_value_dependent_on_next_state_ "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#sample-badge-text-simulation-type-warn"}},[t._v("_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#set-memory-badge-text-simulation-type-warn"}},[t._v("_set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#state-sample-badge-text-simulation-type-warn"}},[t._v("_state_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#state-step-badge-text-environment-type-warn"}},[t._v("_state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)]),a("li",[a("a",{attrs:{href:"#step-badge-text-environment-type-warn"}},[t._v("_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1)])])])])]),a("p"),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("skdecide-summary")],1),t._v(" "),a("h2",{attrs:{id:"environment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#environment"}},[t._v("#")]),t._v(" Environment")]),t._v(" "),a("p",[t._v("A domain must inherit this class if agents interact with it like a black-box environment.")]),t._v(" "),a("p",[t._v("Black-box environment examples include: the real world, compiled ATARI games, etc.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Environment domains are typically stateful: they must keep the current state or history in their memory to\ncompute next steps (automatically done by default in the "),a("code",[t._v("_memory")]),t._v(" attribute).")])]),t._v(" "),a("h3",{attrs:{id:"step"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step"}},[t._v("#")]),t._v(" step "),a("Badge",{attrs:{text:"Environment",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment.step()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Environment._step()")]),t._v(" (which\nreturns a transition outcome). The boilerplate code automatically stores next state into the "),a("code",[t._v("_memory")]),t._v(" attribute\nand samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment.step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment.step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable.reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"state-step"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-step"}},[t._v("#")]),t._v(" _state_step "),a("Badge",{attrs:{text:"Environment",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one step of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Environment._step()")]),t._v(". It focuses on the state level, as opposed\nto the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-2"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-2"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"step-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-2"}},[t._v("#")]),t._v(" _step "),a("Badge",{attrs:{text:"Environment",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment._step()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Environment._state_step()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically stores\nnext state into the "),a("code",[t._v("_memory")]),t._v(" attribute and samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment._step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._state_step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment._step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable._reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-3"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-3"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h2",{attrs:{id:"simulation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#simulation"}},[t._v("#")]),t._v(" Simulation")]),t._v(" "),a("p",[t._v("A domain must inherit this class if agents interact with it like a simulation.")]),t._v(" "),a("p",[t._v("Compared to pure environment domains, simulation ones have the additional ability to sample transitions from any\ngiven state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Simulation domains are typically stateless: they do not need to store the current state or history in memory\nsince it is usually passed as parameter of their functions. By default, they only become stateful whenever they\nare used as environments (e.g. via "),a("code",[t._v("Initializable.reset()")]),t._v(" and "),a("code",[t._v("Environment.step()")]),t._v(" functions).")])]),t._v(" "),a("h3",{attrs:{id:"sample"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample"}},[t._v("#")]),t._v(" sample "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation.sample()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Simulation._sample()")]),t._v("\n(which returns a transition outcome). The boilerplate code automatically samples an observation corresponding to\nthe sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation.sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-4"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-4"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory"}},[t._v("#")]),t._v(" set_memory "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with successive '),a("code",[t._v("Environment.step()")]),t._v("\ncalls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-5"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"step-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-3"}},[t._v("#")]),t._v(" step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment.step()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Environment._step()")]),t._v(" (which\nreturns a transition outcome). The boilerplate code automatically stores next state into the "),a("code",[t._v("_memory")]),t._v(" attribute\nand samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment.step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment.step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable.reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-6"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-5"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"sample-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-2"}},[t._v("#")]),t._v(" _sample "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation._sample()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Simulation._state_sample()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically\nsamples an observation corresponding to the sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation._sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._state_sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-7"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-6"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-2"}},[t._v("#")]),t._v(" _set_memory "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with\nsuccessive '),a("code",[t._v("Environment._step()")]),t._v(" calls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-8"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-2"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"state-sample"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-sample"}},[t._v("#")]),t._v(" _state_sample "),a("Badge",{attrs:{text:"Simulation",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one sample of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Simulation._sample()")]),t._v(". It focuses on the state level, as\nopposed to the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-9"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-7"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"state-step-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-step-2"}},[t._v("#")]),t._v(" _state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one step of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Environment._step()")]),t._v(". It focuses on the state level, as opposed\nto the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-10"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-10"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-8"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"step-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-4"}},[t._v("#")]),t._v(" _step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment._step()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Environment._state_step()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically stores\nnext state into the "),a("code",[t._v("_memory")]),t._v(" attribute and samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment._step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._state_step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment._step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable._reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-11"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-11"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-9"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h2",{attrs:{id:"uncertaintransitions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#uncertaintransitions"}},[t._v("#")]),t._v(" UncertainTransitions")]),t._v(" "),a("p",[t._v("A domain must inherit this class if its dynamics is uncertain and provided as a white-box model.")]),t._v(" "),a("p",[t._v("Compared to pure simulation domains, uncertain transition ones provide in addition the full probability distribution\nof next states given a memory and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Uncertain transition domains are typically stateless: they do not need to store the current state or history in\nmemory since it is usually passed as parameter of their functions. By default, they only become stateful\nwhenever they are used as environments (e.g. via "),a("code",[t._v("Initializable.reset()")]),t._v(" and "),a("code",[t._v("Environment.step()")]),t._v(" functions).")])]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution"}},[t._v("#")]),t._v(" get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"Distribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the probability distribution of next state given a memory and action.")]),t._v(" "),a("h4",{attrs:{id:"parameters-12"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-12"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-10"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-10"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value"}},[t._v("#")]),t._v(" get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"},{name:"next_state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_agent[Value[D.T_value]]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.")]),t._v(" "),a("p",[t._v("The transition to consider is defined by the function parameters.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("If this function never depends on the next_state parameter for its computation, it is recommended to\nindicate it by overriding "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" to return\nFalse. This information can then be exploited by solvers to avoid computing next state to evaluate a\ntransition value (more efficient).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-13"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-13"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")]),t._v(" "),a("li",[a("strong",[t._v("next_state")]),t._v(": The next state in which the transition ends (if needed for the computation).")])]),t._v(" "),a("h4",{attrs:{id:"returns-11"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-11"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition value (reward or cost).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal"}},[t._v("#")]),t._v(" is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("A terminal state is a state with no outgoing transition (except to itself with value 0).")]),t._v(" "),a("h4",{attrs:{id:"parameters-14"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-14"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-12"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-12"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the state is terminal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state"}},[t._v("#")]),t._v(" is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions.is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-13"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-13"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"sample-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-3"}},[t._v("#")]),t._v(" sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation.sample()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Simulation._sample()")]),t._v("\n(which returns a transition outcome). The boilerplate code automatically samples an observation corresponding to\nthe sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation.sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-15"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-15"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-14"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-14"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-3"}},[t._v("#")]),t._v(" set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with successive '),a("code",[t._v("Environment.step()")]),t._v("\ncalls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-16"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-16"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-3"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"step-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-5"}},[t._v("#")]),t._v(" step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment.step()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Environment._step()")]),t._v(" (which\nreturns a transition outcome). The boilerplate code automatically stores next state into the "),a("code",[t._v("_memory")]),t._v(" attribute\nand samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment.step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment.step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable.reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-17"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-17"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-15"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-15"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution-2"}},[t._v("#")]),t._v(" _get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"Distribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the probability distribution of next state given a memory and action.")]),t._v(" "),a("h4",{attrs:{id:"parameters-18"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-18"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-16"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-16"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value-2"}},[t._v("#")]),t._v(" _get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"},{name:"next_state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_agent[Value[D.T_value]]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.")]),t._v(" "),a("p",[t._v("The transition to consider is defined by the function parameters.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("If this function never depends on the next_state parameter for its computation, it is recommended to\nindicate it by overriding "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" to return\nFalse. This information can then be exploited by solvers to avoid computing next state to evaluate a\ntransition value (more efficient).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-19"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-19"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")]),t._v(" "),a("li",[a("strong",[t._v("next_state")]),t._v(": The next state in which the transition ends (if needed for the computation).")])]),t._v(" "),a("h4",{attrs:{id:"returns-17"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-17"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition value (reward or cost).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal-2"}},[t._v("#")]),t._v(" _is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("A terminal state is a state with no outgoing transition (except to itself with value 0).")]),t._v(" "),a("h4",{attrs:{id:"parameters-20"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-20"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-18"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-18"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the state is terminal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-2"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-19"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-19"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-3"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state_ "),a("Badge",{attrs:{text:"UncertainTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state_",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation.")]),t._v(" "),a("p",[t._v("This is a helper function called by default\nfrom "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(", the difference being that the result\nis not cached here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("The underscore at the end of this function's name is a convention to remind that its result should be\nconstant.")])]),t._v(" "),a("h4",{attrs:{id:"returns-20"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-20"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"sample-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-4"}},[t._v("#")]),t._v(" _sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation._sample()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Simulation._state_sample()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically\nsamples an observation corresponding to the sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation._sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._state_sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-21"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-21"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-21"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-21"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-4"}},[t._v("#")]),t._v(" _set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with\nsuccessive '),a("code",[t._v("Environment._step()")]),t._v(" calls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-22"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-22"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-4"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"state-sample-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-sample-2"}},[t._v("#")]),t._v(" _state_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one sample of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Simulation._sample()")]),t._v(". It focuses on the state level, as\nopposed to the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-23"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-23"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-22"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-22"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"state-step-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-step-3"}},[t._v("#")]),t._v(" _state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one step of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Environment._step()")]),t._v(". It focuses on the state level, as opposed\nto the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-24"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-24"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-23"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-23"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"step-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-6"}},[t._v("#")]),t._v(" _step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment._step()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Environment._state_step()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically stores\nnext state into the "),a("code",[t._v("_memory")]),t._v(" attribute and samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment._step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._state_step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment._step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable._reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-25"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-25"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-24"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-24"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h2",{attrs:{id:"enumerabletransitions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#enumerabletransitions"}},[t._v("#")]),t._v(" EnumerableTransitions")]),t._v(" "),a("p",[t._v("A domain must inherit this class if its dynamics is uncertain (with enumerable transitions) and provided as a\nwhite-box model.")]),t._v(" "),a("p",[t._v("Compared to pure uncertain transition domains, enumerable transition ones guarantee that all probability\ndistributions of next state are discrete.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Enumerable transition domains are typically stateless: they do not need to store the current state or history in\nmemory since it is usually passed as parameter of their functions. By default, they only become stateful\nwhenever they are used as environments (e.g. via "),a("code",[t._v("Initializable.reset()")]),t._v(" and "),a("code",[t._v("Environment.step()")]),t._v(" functions).")])]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution-3"}},[t._v("#")]),t._v(" get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"DiscreteDistribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the discrete probability distribution of next state given a memory and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("In the Markovian case (memory only holds last state "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.061ex",height:"1.023ex",viewBox:"0 -442 469 452"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})])])])])]),t._v("), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function can\nbe mathematically represented by "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.292ex",height:"2.283ex",viewBox:"0 -759 4107.1 1009"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"msup",transform:"translate(1140, 0)"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1997.5, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2275.5, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2744.5, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3189.1, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3718.1, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(", where "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.94ex",height:"1.767ex",viewBox:"0 -759 857.5 781"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"msup"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])])])])])]),t._v(" is the next state random variable.")],1)]),t._v(" "),a("h4",{attrs:{id:"parameters-26"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-26"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-25"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-25"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The discrete probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value-3"}},[t._v("#")]),t._v(" get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"},{name:"next_state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_agent[Value[D.T_value]]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.")]),t._v(" "),a("p",[t._v("The transition to consider is defined by the function parameters.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("If this function never depends on the next_state parameter for its computation, it is recommended to\nindicate it by overriding "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" to return\nFalse. This information can then be exploited by solvers to avoid computing next state to evaluate a\ntransition value (more efficient).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-27"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-27"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")]),t._v(" "),a("li",[a("strong",[t._v("next_state")]),t._v(": The next state in which the transition ends (if needed for the computation).")])]),t._v(" "),a("h4",{attrs:{id:"returns-26"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-26"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition value (reward or cost).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal-3"}},[t._v("#")]),t._v(" is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("A terminal state is a state with no outgoing transition (except to itself with value 0).")]),t._v(" "),a("h4",{attrs:{id:"parameters-28"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-28"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-27"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-27"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the state is terminal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-4"}},[t._v("#")]),t._v(" is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions.is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-28"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-28"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"sample-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-5"}},[t._v("#")]),t._v(" sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation.sample()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Simulation._sample()")]),t._v("\n(which returns a transition outcome). The boilerplate code automatically samples an observation corresponding to\nthe sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation.sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-29"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-29"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-29"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-29"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-5"}},[t._v("#")]),t._v(" set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with successive '),a("code",[t._v("Environment.step()")]),t._v("\ncalls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-30"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-30"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-5"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"step-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-7"}},[t._v("#")]),t._v(" step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment.step()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Environment._step()")]),t._v(" (which\nreturns a transition outcome). The boilerplate code automatically stores next state into the "),a("code",[t._v("_memory")]),t._v(" attribute\nand samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment.step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment.step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable.reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-31"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-31"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-30"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-30"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution-4"}},[t._v("#")]),t._v(" _get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"DiscreteDistribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the discrete probability distribution of next state given a memory and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("In the Markovian case (memory only holds last state "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.061ex",height:"1.023ex",viewBox:"0 -442 469 452"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})])])])])]),t._v("), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function can\nbe mathematically represented by "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.292ex",height:"2.283ex",viewBox:"0 -759 4107.1 1009"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"msup",transform:"translate(1140, 0)"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1997.5, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2275.5, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2744.5, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3189.1, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3718.1, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(", where "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.94ex",height:"1.767ex",viewBox:"0 -759 857.5 781"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"msup"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])])])])])]),t._v(" is the next state random variable.")],1)]),t._v(" "),a("h4",{attrs:{id:"parameters-32"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-32"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-31"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-31"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The discrete probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value-4"}},[t._v("#")]),t._v(" _get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"},{name:"next_state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_agent[Value[D.T_value]]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.")]),t._v(" "),a("p",[t._v("The transition to consider is defined by the function parameters.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("If this function never depends on the next_state parameter for its computation, it is recommended to\nindicate it by overriding "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" to return\nFalse. This information can then be exploited by solvers to avoid computing next state to evaluate a\ntransition value (more efficient).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-33"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-33"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")]),t._v(" "),a("li",[a("strong",[t._v("next_state")]),t._v(": The next state in which the transition ends (if needed for the computation).")])]),t._v(" "),a("h4",{attrs:{id:"returns-32"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-32"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition value (reward or cost).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal-4"}},[t._v("#")]),t._v(" _is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("A terminal state is a state with no outgoing transition (except to itself with value 0).")]),t._v(" "),a("h4",{attrs:{id:"parameters-34"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-34"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-33"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-33"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the state is terminal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-5"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-34"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-34"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-6"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state_ "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state_",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation.")]),t._v(" "),a("p",[t._v("This is a helper function called by default\nfrom "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(", the difference being that the result\nis not cached here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("The underscore at the end of this function's name is a convention to remind that its result should be\nconstant.")])]),t._v(" "),a("h4",{attrs:{id:"returns-35"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-35"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"sample-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-6"}},[t._v("#")]),t._v(" _sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation._sample()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Simulation._state_sample()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically\nsamples an observation corresponding to the sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation._sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._state_sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-35"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-35"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-36"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-36"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-6"}},[t._v("#")]),t._v(" _set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with\nsuccessive '),a("code",[t._v("Environment._step()")]),t._v(" calls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-36"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-36"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-6"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"state-sample-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-sample-3"}},[t._v("#")]),t._v(" _state_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one sample of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Simulation._sample()")]),t._v(". It focuses on the state level, as\nopposed to the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-37"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-37"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-37"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-37"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"state-step-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-step-4"}},[t._v("#")]),t._v(" _state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one step of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Environment._step()")]),t._v(". It focuses on the state level, as opposed\nto the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-38"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-38"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-38"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-38"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"step-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-8"}},[t._v("#")]),t._v(" _step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment._step()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Environment._state_step()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically stores\nnext state into the "),a("code",[t._v("_memory")]),t._v(" attribute and samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment._step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._state_step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment._step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable._reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-39"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-39"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-39"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-39"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h2",{attrs:{id:"deterministictransitions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deterministictransitions"}},[t._v("#")]),t._v(" DeterministicTransitions")]),t._v(" "),a("p",[t._v("A domain must inherit this class if its dynamics is deterministic and provided as a white-box model.")]),t._v(" "),a("p",[t._v("Compared to pure enumerable transition domains, deterministic transition ones guarantee that there is only one next\nstate for a given source memory (state or history) and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Deterministic transition domains are typically stateless: they do not need to store the current state or history\nin memory since it is usually passed as parameter of their functions. By default, they only become stateful\nwhenever they are used as environments (e.g. via "),a("code",[t._v("Initializable.reset()")]),t._v(" and "),a("code",[t._v("Environment.step()")]),t._v(" functions).")])]),t._v(" "),a("h3",{attrs:{id:"get-next-state"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state"}},[t._v("#")]),t._v(" get_next_state "),a("Badge",{attrs:{text:"DeterministicTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_next_state",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"D.T_state"}}}),t._v(" "),a("p",[t._v("Get the next state given a memory and action.")]),t._v(" "),a("h4",{attrs:{id:"parameters-40"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-40"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-40"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-40"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The deterministic next state.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution-5"}},[t._v("#")]),t._v(" get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"DiscreteDistribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the discrete probability distribution of next state given a memory and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("In the Markovian case (memory only holds last state "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.061ex",height:"1.023ex",viewBox:"0 -442 469 452"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})])])])])]),t._v("), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function can\nbe mathematically represented by "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.292ex",height:"2.283ex",viewBox:"0 -759 4107.1 1009"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"msup",transform:"translate(1140, 0)"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1997.5, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2275.5, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2744.5, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3189.1, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3718.1, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(", where "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.94ex",height:"1.767ex",viewBox:"0 -759 857.5 781"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"msup"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])])])])])]),t._v(" is the next state random variable.")],1)]),t._v(" "),a("h4",{attrs:{id:"parameters-41"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-41"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-41"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-41"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The discrete probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value-5"}},[t._v("#")]),t._v(" get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"},{name:"next_state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_agent[Value[D.T_value]]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.")]),t._v(" "),a("p",[t._v("The transition to consider is defined by the function parameters.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("If this function never depends on the next_state parameter for its computation, it is recommended to\nindicate it by overriding "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" to return\nFalse. This information can then be exploited by solvers to avoid computing next state to evaluate a\ntransition value (more efficient).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-42"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-42"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")]),t._v(" "),a("li",[a("strong",[t._v("next_state")]),t._v(": The next state in which the transition ends (if needed for the computation).")])]),t._v(" "),a("h4",{attrs:{id:"returns-42"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-42"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition value (reward or cost).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal-5"}},[t._v("#")]),t._v(" is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("A terminal state is a state with no outgoing transition (except to itself with value 0).")]),t._v(" "),a("h4",{attrs:{id:"parameters-43"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-43"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-43"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-43"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the state is terminal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-7"}},[t._v("#")]),t._v(" is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions.is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-44"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-44"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"sample-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-7"}},[t._v("#")]),t._v(" sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation.sample()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Simulation._sample()")]),t._v("\n(which returns a transition outcome). The boilerplate code automatically samples an observation corresponding to\nthe sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation.sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-44"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-44"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-45"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-45"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-7"}},[t._v("#")]),t._v(" set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with successive '),a("code",[t._v("Environment.step()")]),t._v("\ncalls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-45"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-45"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-7"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"step-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-9"}},[t._v("#")]),t._v(" step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment.step()")]),t._v(" provides some boilerplate code and internally calls "),a("code",[t._v("Environment._step()")]),t._v(" (which\nreturns a transition outcome). The boilerplate code automatically stores next state into the "),a("code",[t._v("_memory")]),t._v(" attribute\nand samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment.step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment.step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable.reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-46"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-46"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-46"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-46"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-2"}},[t._v("#")]),t._v(" _get_next_state "),a("Badge",{attrs:{text:"DeterministicTransitions",type:"tip"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_next_state",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"D.T_state"}}}),t._v(" "),a("p",[t._v("Get the next state given a memory and action.")]),t._v(" "),a("h4",{attrs:{id:"parameters-47"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-47"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-47"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-47"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The deterministic next state.")]),t._v(" "),a("h3",{attrs:{id:"get-next-state-distribution-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-next-state-distribution-6"}},[t._v("#")]),t._v(" _get_next_state_distribution "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_next_state_distribution",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"SingleValueDistribution[D.T_state]"}}}),t._v(" "),a("p",[t._v("Get the discrete probability distribution of next state given a memory and action.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("In the Markovian case (memory only holds last state "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.061ex",height:"1.023ex",viewBox:"0 -442 469 452"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})])])])])]),t._v("), given an action "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.023ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.197ex",height:"1.02ex",viewBox:"0 -441 529 451"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})])])])])]),t._v(", this function can\nbe mathematically represented by "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.566ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"9.292ex",height:"2.283ex",viewBox:"0 -759 4107.1 1009"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"50",d:"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(751, 0)"}},[a("path",{attrs:{"data-c":"28",d:"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"}})]),a("g",{attrs:{"data-mml-node":"msup",transform:"translate(1140, 0)"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(1997.5, 0)"}},[a("path",{attrs:{"data-c":"7C",d:"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(2275.5, 0)"}},[a("path",{attrs:{"data-c":"73",d:"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(2744.5, 0)"}},[a("path",{attrs:{"data-c":"2C",d:"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"}})]),a("g",{attrs:{"data-mml-node":"mi",transform:"translate(3189.1, 0)"}},[a("path",{attrs:{"data-c":"61",d:"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(3718.1, 0)"}},[a("path",{attrs:{"data-c":"29",d:"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"}})])])])])]),t._v(", where "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[a("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"1.94ex",height:"1.767ex",viewBox:"0 -759 857.5 781"}},[a("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[a("g",{attrs:{"data-mml-node":"math"}},[a("g",{attrs:{"data-mml-node":"msup"}},[a("g",{attrs:{"data-mml-node":"mi"}},[a("path",{attrs:{"data-c":"53",d:"M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"}})]),a("g",{attrs:{"data-mml-node":"mo",transform:"translate(613, 363) scale(0.707)"}},[a("path",{attrs:{"data-c":"2032",d:"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"}})])])])])])]),t._v(" is the next state random variable.")],1)]),t._v(" "),a("h4",{attrs:{id:"parameters-48"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-48"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-48"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-48"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The discrete probability distribution of next state.")]),t._v(" "),a("h3",{attrs:{id:"get-transition-value-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#get-transition-value-6"}},[t._v("#")]),t._v(" _get_transition_value "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_get_transition_value",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"},{name:"next_state",default:"None",annotation:"Optional[D.T_state]"}],return:"D.T_agent[Value[D.T_value]]"}}}),t._v(" "),a("p",[t._v("Get the value (reward or cost) of a transition.")]),t._v(" "),a("p",[t._v("The transition to consider is defined by the function parameters.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("If this function never depends on the next_state parameter for its computation, it is recommended to\nindicate it by overriding "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" to return\nFalse. This information can then be exploited by solvers to avoid computing next state to evaluate a\ntransition value (more efficient).")])]),t._v(" "),a("h4",{attrs:{id:"parameters-49"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-49"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")]),t._v(" "),a("li",[a("strong",[t._v("next_state")]),t._v(": The next state in which the transition ends (if needed for the computation).")])]),t._v(" "),a("h4",{attrs:{id:"returns-49"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-49"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition value (reward or cost).")]),t._v(" "),a("h3",{attrs:{id:"is-terminal-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-terminal-6"}},[t._v("#")]),t._v(" _is_terminal "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_terminal",sig:{params:[{name:"self"},{name:"state",annotation:"D.T_state"}],return:"D.T_agent[D.T_predicate]"}}}),t._v(" "),a("p",[t._v("Indicate whether a state is terminal.")]),t._v(" "),a("p",[t._v("A terminal state is a state with no outgoing transition (except to itself with value 0).")]),t._v(" "),a("h4",{attrs:{id:"parameters-50"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-50"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("state")]),t._v(": The state to consider.")])]),t._v(" "),a("h4",{attrs:{id:"returns-50"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-50"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the state is terminal (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-8"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation (cached).")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(" internally\ncalls "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state_()")]),t._v(" the first time and automatically\ncaches its value to make future calls more efficient (since the returned value is assumed to be constant).")]),t._v(" "),a("h4",{attrs:{id:"returns-51"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-51"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"is-transition-value-dependent-on-next-state-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#is-transition-value-dependent-on-next-state-9"}},[t._v("#")]),t._v(" _is_transition_value_dependent_on_next_state_ "),a("Badge",{attrs:{text:"UncertainTransitions",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_is_transition_value_dependent_on_next_state_",sig:{params:[{name:"self"}],return:"bool"}}}),t._v(" "),a("p",[t._v("Indicate whether _get_transition_value() requires the next_state parameter for its computation.")]),t._v(" "),a("p",[t._v("This is a helper function called by default\nfrom "),a("code",[t._v("UncertainTransitions._is_transition_value_dependent_on_next_state()")]),t._v(", the difference being that the result\nis not cached here.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("The underscore at the end of this function's name is a convention to remind that its result should be\nconstant.")])]),t._v(" "),a("h4",{attrs:{id:"returns-52"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-52"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("True if the transition value computation depends on next_state (False otherwise).")]),t._v(" "),a("h3",{attrs:{id:"sample-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sample-8"}},[t._v("#")]),t._v(" _sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Sample one transition of the simulator's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Simulation._sample()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Simulation._state_sample()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically\nsamples an observation corresponding to the sampled next state.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing simulator needs to be wrapped instead of implemented fully in scikit-decide (e.g. a\nsimulator), it is recommended to overwrite "),a("code",[t._v("Simulation._sample()")]),t._v(" to call the external simulator and not use\nthe "),a("code",[t._v("Simulation._state_sample()")]),t._v(" helper function.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-51"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-51"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-53"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-53"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"set-memory-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#set-memory-8"}},[t._v("#")]),t._v(" _set_memory "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_set_memory",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"}],return:"None"}}}),t._v(" "),a("p",[t._v("Set internal memory attribute "),a("code",[t._v("_memory")]),t._v(" to given one.")]),t._v(" "),a("p",[t._v('This can be useful to set a specific "starting point" before doing a rollout with\nsuccessive '),a("code",[t._v("Environment._step()")]),t._v(" calls.")]),t._v(" "),a("h4",{attrs:{id:"parameters-52"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-52"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The memory to set internally.")])]),t._v(" "),a("h4",{attrs:{id:"example-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example-8"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set simulation_domain memory to my_state (assuming Markovian domain)")]),t._v("\nsimulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_set_memory"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start a 100-steps rollout from here (applying my_action at every step)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    simulation_domain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_action"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"state-sample-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-sample-4"}},[t._v("#")]),t._v(" _state_sample "),a("Badge",{attrs:{text:"Simulation",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_sample",sig:{params:[{name:"self"},{name:"memory",annotation:"D.T_memory[D.T_state]"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one sample of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Simulation._sample()")]),t._v(". It focuses on the state level, as\nopposed to the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-53"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-53"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("memory")]),t._v(": The source memory (state or history) of the transition.")]),t._v(" "),a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the given memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-54"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-54"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of the sampled transition.")]),t._v(" "),a("h3",{attrs:{id:"state-step-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#state-step-5"}},[t._v("#")]),t._v(" _state_step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_state_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"TransitionOutcome[D.T_state, D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Compute one step of the transition's dynamics.")]),t._v(" "),a("p",[t._v("This is a helper function called by default from "),a("code",[t._v("Environment._step()")]),t._v(". It focuses on the state level, as opposed\nto the observation one for the latter.")]),t._v(" "),a("h4",{attrs:{id:"parameters-54"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-54"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-55"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-55"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The transition outcome of this step.")]),t._v(" "),a("h3",{attrs:{id:"step-10"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#step-10"}},[t._v("#")]),t._v(" _step "),a("Badge",{attrs:{text:"Environment",type:"warn"}})],1),t._v(" "),a("skdecide-signature",{attrs:{name:"_step",sig:{params:[{name:"self"},{name:"action",annotation:"D.T_agent[D.T_concurrency[D.T_event]]"}],return:"EnvironmentOutcome[D.T_agent[D.T_observation], D.T_agent[Value[D.T_value]], D.T_agent[D.T_predicate], D.T_agent[D.T_info]]"}}}),t._v(" "),a("p",[t._v("Run one step of the environment's dynamics.")]),t._v(" "),a("p",[t._v("By default, "),a("code",[t._v("Environment._step()")]),t._v(" provides some boilerplate code and internally\ncalls "),a("code",[t._v("Environment._state_step()")]),t._v(" (which returns a transition outcome). The boilerplate code automatically stores\nnext state into the "),a("code",[t._v("_memory")]),t._v(" attribute and samples a corresponding observation.")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("Whenever an existing environment needs to be wrapped instead of implemented fully in scikit-decide (e.g. compiled\nATARI games), it is recommended to overwrite "),a("code",[t._v("Environment._step()")]),t._v(" to call the external environment and not\nuse the "),a("code",[t._v("Environment._state_step()")]),t._v(" helper function.")])]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("Before calling "),a("code",[t._v("Environment._step()")]),t._v(" the first time or when the end of an episode is\nreached, "),a("code",[t._v("Initializable._reset()")]),t._v(" must be called to reset the environment's state.")])]),t._v(" "),a("h4",{attrs:{id:"parameters-55"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameters-55"}},[t._v("#")]),t._v(" Parameters")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("action")]),t._v(": The action taken in the current memory (state or history) triggering the transition.")])]),t._v(" "),a("h4",{attrs:{id:"returns-56"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-56"}},[t._v("#")]),t._v(" Returns")]),t._v(" "),a("p",[t._v("The environment outcome of this step.")])],1)}),[],!1,null,null,null);e.default=s.exports}}]);