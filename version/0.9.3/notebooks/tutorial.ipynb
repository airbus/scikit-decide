{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Create a maze domain and solve it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from enum import Enum\n",
        "from typing import *\n",
        "\n",
        "from skdecide import *\n",
        "from skdecide.builders.domain import *\n",
        "from skdecide.hub.solver.lazy_astar import LazyAstar\n",
        "from skdecide.hub.space.gym import EnumSpace, ListSpace\n",
        "from skdecide.utils import rollout"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define your state space (agent positions) & action space (agent movements)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class State(NamedTuple):\n",
        "    x: int\n",
        "    y: int\n",
        "\n",
        "\n",
        "class Action(Enum):\n",
        "    up = 0\n",
        "    down = 1\n",
        "    left = 2\n",
        "    right = 3"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define your domain type from a base template (DeterministicPlanningDomain here) with optional refinements (UnrestrictedActions & Renderable here)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class D(DeterministicPlanningDomain, UnrestrictedActions, Renderable):\n",
        "    T_state = State  # Type of states\n",
        "    T_observation = T_state  # Type of observations\n",
        "    T_event = Action  # Type of events\n",
        "    T_value = float  # Type of transition values (rewards or costs)\n",
        "    T_predicate = bool  # Type of logical checks\n",
        "    T_info = None  # Type of additional information in environment outcome"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement the maze domain by filling all non-implemented methods and adding a constructor to define the maze & start/end positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class MyDomain(D):\n",
        "    def __init__(self, start, end, maze_str):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.maze_str = maze_str.strip()\n",
        "        self.maze = self.maze_str.splitlines()\n",
        "\n",
        "    def _get_next_state(self, memory: D.T_state, action: D.T_event) -> D.T_state:\n",
        "        # Move agent according to action (except if bumping into a wall)\n",
        "        next_x, next_y = memory.x, memory.y\n",
        "        if action == Action.up:\n",
        "            next_x -= 1\n",
        "        if action == Action.down:\n",
        "            next_x += 1\n",
        "        if action == Action.left:\n",
        "            next_y -= 1\n",
        "        if action == Action.right:\n",
        "            next_y += 1\n",
        "        return State(next_x, next_y) if self.maze[next_x][next_y] != \".\" else memory\n",
        "\n",
        "    def _get_transition_value(\n",
        "        self,\n",
        "        memory: D.T_state,\n",
        "        action: D.T_event,\n",
        "        next_state: Optional[D.T_state] = None,\n",
        "    ) -> Value[D.T_value]:\n",
        "        # Set cost to 1 when moving (energy cost) and to 2 when bumping into a wall (damage cost)\n",
        "        return Value(cost=1 if next_state != memory else 2)\n",
        "\n",
        "    def _get_initial_state_(self) -> D.T_state:\n",
        "        # Set the start position as initial state\n",
        "        return self.start\n",
        "\n",
        "    def _get_goals_(self) -> Space[D.T_observation]:\n",
        "        # Set the end position as goal\n",
        "        return ListSpace([self.end])\n",
        "\n",
        "    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:\n",
        "        # Stop an episode only when goal reached\n",
        "        return self._is_goal(state)\n",
        "\n",
        "    def _get_action_space_(self) -> Space[D.T_event]:\n",
        "        # Define action space\n",
        "        return EnumSpace(Action)\n",
        "\n",
        "    def _get_observation_space_(self) -> Space[D.T_observation]:\n",
        "        # Define observation space (not mandatory here)\n",
        "        pass\n",
        "\n",
        "    def _render_from(self, memory: D.T_state, **kwargs: Any) -> Any:\n",
        "        # Print the maze in console with agent represented by 'o'\n",
        "        cols = len(self.maze[0]) + 1\n",
        "        pos = memory.x * cols + memory.y\n",
        "        render = self.maze_str[:pos] + \"o\" + self.maze_str[pos + 1 :]\n",
        "        print(render)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a maze and test a random walk inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Maze example ('.' represent walls, ' ' represent free space)\n",
        "maze_str = \"\"\"\n",
        ".....................\n",
        ".   .             . .\n",
        ". . . ....... ... . .\n",
        ". . .   .   . . .   .\n",
        ". ..... ... . . . ...\n",
        ". .   .   . .   .   .\n",
        ". . . . . . . ... ...\n",
        ".   .   .   . .     .\n",
        "............... ... .\n",
        ".             .   . .\n",
        ". ......... . ..... .\n",
        ".   .       .       .\n",
        ". . . ... ... .......\n",
        ". . .   .     .     .\n",
        ". ..... . ... . ... .\n",
        ". .     . . . .   . .\n",
        "... ... . . . ... . .\n",
        ".   .   .   .   . . .\n",
        ". ... ......... . . .\n",
        ".   .       .     . .\n",
        ".....................\n",
        "\"\"\"\n",
        "\n",
        "# Start top-left, try to reach bottom-right of this maze\n",
        "domain = MyDomain(State(1, 1), State(19, 19), maze_str)\n",
        "\n",
        "# Random walk in the maze (may sometimes reach the goal by chance)\n",
        "rollout(domain, max_steps=100, render=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pick a solver (lazy A*) and solve the maze optimally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check solver compatibility with the domain\n",
        "assert LazyAstar.check_domain(domain)\n",
        "\n",
        "# Compute solution and visualize it\n",
        "with LazyAstar() as solver:\n",
        "    MyDomain.solve_with(solver, lambda: MyDomain(State(1, 1), State(19, 19), maze_str))\n",
        "    rollout(domain, solver, max_steps=100, max_framerate=10, verbose=False)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}