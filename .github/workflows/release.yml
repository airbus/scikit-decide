name: ðŸ”¨ Release scikit-decide

on:
  push:
    tags:
      - 'v[0-9]+.[0-9]+.[0-9]+'

env:
  BOOST_DIR: 3rdparty/boost
  BOOST_VERSION: "1.76.0"
  SKDECIDE_SKIP_DEPS: 1

jobs:

  setup:
    runs-on: ubuntu-latest
    outputs:
      python_version: ${{ steps.generate-matrix.outputs.python_version }}
      python_version_per_os: ${{ steps.generate-matrix.outputs.python_version_per_os }}
      build: ${{ steps.generate-matrix.outputs.build}}
      test: ${{ steps.generate-matrix.outputs.test}}
      deploy_test_pypi: ${{ steps.generate-matrix.outputs.deploy_test_pypi}}
    steps:
      - uses: actions/setup-python@v4
      - name: Generate Matrix
        id: generate-matrix
        shell: python3 {0}
        run: |
          from os import environ

          python_version = ["3.8", "3.9", "3.10", "3.11"]
          build_dict = { "macos":["macos-11"], "ubuntu":["ubuntu-latest"], "windows":["windows-latest"] }
          test_dict = { "macos":["macos-12", "macos-11"], "ubuntu":["ubuntu-22.04", "ubuntu-20.04"], "windows":["windows-2019", "windows-2022" ]}
          deploy_test_pypi = "true"
          python_version_per_os = {os: python_version for os in build_dict}
          #Â remove python 3.11 for windows: dependency conflict from pyarrow prevent testing the wheel windows python 3.11          python_version_per_os["windows"] = [v for v in python_version if v != "3.11"]
          if "${{ contains(github.event.head_commit.message, '[ci: skip-deploy-test-pypi]') }}" == "true":
              deploy_test_pypi = "false"

          with open(environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"build={build_dict}\n")
              f.write(f"test={test_dict}\n")
              f.write(f"python_version={python_version}\n")
              f.write(f"python_version_per_os={python_version_per_os}\n")
              f.write(f"deploy_test_pypi={deploy_test_pypi}\n")

  lint-sources:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.8"
      - name: install pre-commit
        run: python -m pip install pre-commit
      - name: get cached pre-commit hooks
        uses: actions/cache@v3
        with:
          path: ~/.cache/pre-commit
          key: pre-commit|${{ env.pythonLocation }}|${{ hashFiles('.pre-commit-config.yaml') }}
      - name: pre-commit checks
        run: pre-commit run --show-diff-on-failure --color=always --all-files

  build-windows:
    needs: [setup]
    strategy:
      matrix:
        os: ${{ fromJSON(needs.setup.outputs.build).windows }}
        python-version: ${{ fromJSON(needs.setup.outputs.python_version_per_os).windows }}
      fail-fast: false
    defaults:
      run:
        shell: bash
    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout scikit-decide source code
        uses: actions/checkout@v3
        with:
          submodules: true
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Load cached venv
        id: cached-pip-wheels
        uses: actions/cache@v3
        with:
          path: ~/.cache
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - name: Restore Boost cache
        uses: actions/cache@v3
        id: cache-boost
        with:
          path: ${{env.BOOST_DIR}}
          key: BOOST_${{env.BOOST_VERSION}}

      - name: Install Boost
        if: steps.cache-boost.outputs.cache-hit != 'true'
        run: |
          mkdir -p $BOOST_DIR
          curl --silent --location --output - \
            https://boostorg.jfrog.io/artifactory/main/release/$BOOST_VERSION/source/boost_${BOOST_VERSION//./_}.tar.bz2 |\
            tar jxf - -C $BOOST_DIR --strip-components=1 boost_${BOOST_VERSION//./_}/boost
        shell: bash

      - name: Restore build dependencies
        id: cache-build-dependencies
        uses: actions/cache@v3
        with:
          path: |
            skdecide/hub/bin
            skdecide/hub/share
            skdecide/hub/*.msc
          key: ${{ runner.os }}-cache-deps

      - name: Update SKDECIDE_SKIP_DEPS
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: echo "SKDECIDE_SKIP_DEPS=0" >> $GITHUB_ENV

      - name: Build wheel
        run: |
          export "BOOST_ROOT=$PWD/$BOOST_DIR"
          python -m pip install --upgrade pip
          pip install build poetry-dynamic-versioning
          python -m build --sdist --wheel

      - name: Update build cache from wheels
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: 7z x dist/*.whl -y

      - name: Upload as build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: wheels
          path: dist/*.whl

  build-macos:
    needs: [setup]
    strategy:
      matrix:
        os: ${{ fromJSON(needs.setup.outputs.build).macos }}
        python-version: ${{ fromJSON(needs.setup.outputs.python_version_per_os).macos }}
      fail-fast: false
    defaults:
      run:
        shell: bash
    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout scikit-decide source code
        uses: actions/checkout@v3
        with:
          submodules: true
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Load cached venv
        id: cached-pip-wheels
        uses: actions/cache@v3
        with:
          path: ~/.cache
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - name: Restore Boost cache
        uses: actions/cache@v3
        id: cache-boost
        with:
          path: ${{env.BOOST_DIR}}
          key: BOOST_${{env.BOOST_VERSION}}

      - name: Install Boost
        if: steps.cache-boost.outputs.cache-hit != 'true'
        run: |
          mkdir -p $BOOST_DIR
          curl --silent --location --output - \
            https://boostorg.jfrog.io/artifactory/main/release/$BOOST_VERSION/source/boost_${BOOST_VERSION//./_}.tar.bz2 |\
            tar jxf - -C $BOOST_DIR --strip-components=1 boost_${BOOST_VERSION//./_}/boost
        shell: bash

      - name: Restore build dependencies
        id: cache-build-dependencies
        uses: actions/cache@v3
        with:
          path: |
            skdecide/hub/bin
            skdecide/hub/share
            skdecide/hub/*.msc
          key: ${{ runner.os }}-cache-deps

      - name: Update SKDECIDE_SKIP_DEPS
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: echo "SKDECIDE_SKIP_DEPS=0" >> $GITHUB_ENV

      - name: Install omp
        run: brew install libomp

      - name: Build wheel
        run: |
          export "BOOST_ROOT=$PWD/$BOOST_DIR"
          python -m pip install --upgrade pip
          pip install build poetry-dynamic-versioning
          python -m build --sdist --wheel

      - name: Update build cache from wheels
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: 7z x dist/*.whl -y

      - name: Upload as build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: wheels
          path: dist/*.whl

  build-ubuntu:
    needs: [setup]
    strategy:
      matrix:
        os: ${{ fromJSON(needs.setup.outputs.build).ubuntu }}
        python-version: ${{ fromJSON(needs.setup.outputs.python_version_per_os).ubuntu }}
      fail-fast: false
    defaults:
      run:
        shell: bash
    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout scikit-decide source code
        uses: actions/checkout@v3
        with:
          submodules: true
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Load cached venv
        id: cached-pip-wheels
        uses: actions/cache@v3
        with:
          path: ~/.cache
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - name: Restore Boost cache
        uses: actions/cache@v3
        id: cache-boost
        with:
          path: ${{env.BOOST_DIR}}
          key: BOOST_${{env.BOOST_VERSION}}

      - name: Install Boost
        if: steps.cache-boost.outputs.cache-hit != 'true'
        run: |
          mkdir -p $BOOST_DIR
          curl --silent --location --output - \
            https://boostorg.jfrog.io/artifactory/main/release/$BOOST_VERSION/source/boost_${BOOST_VERSION//./_}.tar.bz2 |\
            tar jxf - -C $BOOST_DIR --strip-components=1 boost_${BOOST_VERSION//./_}/boost
        shell: bash

      - name: Restore build dependencies
        id: cache-build-dependencies
        uses: actions/cache@v3
        with:
          path: |
            skdecide/hub/bin
            skdecide/hub/share
            skdecide/hub/*.msc
          key: ${{ runner.os }}-cache-deps

      - name: Update SKDECIDE_SKIP_DEPS
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: echo "SKDECIDE_SKIP_DEPS=0" >> $GITHUB_ENV

      - name: Restore docker dev image
        id: cache-dev-deps
        uses: actions/cache@v3
        with:
          path: /tmp/docker
          key: dev-deps-${{ runner.os }}-${{ hashFiles('scripts/build-skdecide_dev.sh', 'scripts/Dockerfile_x86_64_dev') }}

      - name: Build wheels
        run: |
          # Load skdecide_dev image from cache, or build it if not found
          if test -f /tmp/docker/skdecide_dev.tar; then
            docker image load -i /tmp/docker/skdecide_dev.tar
          else
            docker build -f scripts/Dockerfile_x86_64_dev -t skdecide_dev .
            mkdir -p /tmp/docker
            docker image save -o /tmp/docker/skdecide_dev.tar skdecide_dev
          fi
          docker build -f scripts/Dockerfile_x86_64 -t skdecide_x86_64 --build-arg PYTHON_VERSION=${{matrix.python-version}} --build-arg SKDECIDE_SKIP_DEPS=${SKDECIDE_SKIP_DEPS} --build-arg BOOST_DIR=${BOOST_DIR} .
          # Fetch wheels from Docker
          docker run --rm -v $PWD:/mytmp skdecide_x86_64 cp -r /io/dist /mytmp

      - name: Update build cache from wheels
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: 7z x dist/*.whl -y

      - name: Upload as build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: wheels
          path: dist/*.whl

  test-windows:
    needs: [build-macos, build-ubuntu, build-windows, setup]
    strategy:
      matrix:
        os: ${{ fromJSON(needs.setup.outputs.test).windows }}
        python-version: ${{ fromJSON(needs.setup.outputs.python_version_per_os).windows }}
        compiler: [gnu]
      fail-fast: true
    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash
    env:
      minizinc_config_cmdline: export PATH=$PATH:~/AppData/Local/Programs/MiniZinc
      minizinc_cache_path: ~/AppData/Local/Programs/MiniZinc
      minizinc_url: https://github.com/MiniZinc/MiniZincIDE/releases/download/2.6.3/MiniZincIDE-2.6.3-bundled-setup-win64.exe
      minizinc_downloaded_filepath: minizinc_setup.exe
      minizinc_install_cmdline: cmd //c "minizinc_setup.exe /verysilent /currentuser /norestart /suppressmsgboxes /sp"

    steps:
      - uses: actions/checkout@v3
        with:
          submodules: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: wheels
          path: wheels

      - name: get MininZinc path to cache
        id: get-mzn-cache-path
        run: |
          echo "path=${{ env.minizinc_cache_path }}" >> $GITHUB_OUTPUT  # expands variables

      - name: Restore MiniZinc cache
        id: cache-minizinc
        uses: actions/cache@v3
        with:
          path: ${{ steps.get-mzn-cache-path.outputs.path }}
          key: ${{ env.minizinc_url }}

      - name: Download MiniZinc
        if: steps.cache-minizinc.outputs.cache-hit != 'true'
        run: |
          curl -o "${{ env.minizinc_downloaded_filepath }}" -L ${{ env.minizinc_url }}

      - name: Install MiniZinc
        if: steps.cache-minizinc.outputs.cache-hit != 'true'
        run: |
          ${{ env.minizinc_install_cmdline }}

      - name: Test minizinc install
        run: |
          ${{ env.minizinc_config_cmdline }}
          minizinc --version

      - name: Install scikit-decide and test dependencies
        run: |
          python_version=${{ matrix.python-version }}
          wheelfile=$(ls ./wheels/scikit_decide*-cp${python_version/\./}-*win*.whl)
          pip install ${wheelfile}[all] pytest gymnasium[classic-control]

      - name: Test with pytest
        run: |
          # configure minizinc
          ${{ env.minizinc_config_cmdline }}
          # test minizinc
          python -c "import minizinc; print(minizinc.default_driver.minizinc_version); minizinc.Solver.lookup('gecode')"
          # run pytest, split tests using cpp scikit-decide library from others to avoid openmp versions conflicts
          pytest -v -s tests/*/cpp
          pytest -v -s --ignore-glob tests/*/cpp

  test-macos:
    needs: [build-macos, build-ubuntu, build-windows, setup]
    strategy:
      matrix:
        os: ${{ fromJSON(needs.setup.outputs.test).macos }}
        python-version: ${{ fromJSON(needs.setup.outputs.python_version_per_os).macos }}
      fail-fast: true
    runs-on: ${{ matrix.os }}
    env:
      minizinc_config_cmdline: export PATH=$PATH:$(pwd)/bin/MiniZincIDE.app/Contents/Resources
      minizinc_cache_path: $(pwd)/bin/MiniZincIDE.app
      minizinc_url: https://github.com/MiniZinc/MiniZincIDE/releases/download/2.6.3/MiniZincIDE-2.6.3-bundled.dmg
      minizinc_downloaded_filepath: bin/minizinc.dmg
      minizinc_install_cmdline: sudo hdiutil attach bin/minizinc.dmg; sudo cp -R /Volumes/MiniZinc*/MiniZincIDE.app bin/.

    steps:
      - uses: actions/checkout@v3

      - name: Install libomp package
        run: brew install libomp

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: wheels
          path: wheels

      - name: Create bin/
        run: mkdir -p bin
      - name: get MininZinc path to cache
        id: get-mzn-cache-path
        run: |
          echo "path=${{ env.minizinc_cache_path }}" >> $GITHUB_OUTPUT  # expands variables

      - name: Restore MiniZinc cache
        id: cache-minizinc
        uses: actions/cache@v3
        with:
          path: ${{ steps.get-mzn-cache-path.outputs.path }}
          key: ${{ env.minizinc_url }}

      - name: Download MiniZinc
        if: steps.cache-minizinc.outputs.cache-hit != 'true'
        run: |
          curl -o "${{ env.minizinc_downloaded_filepath }}" -L ${{ env.minizinc_url }}

      - name: Install MiniZinc
        if: steps.cache-minizinc.outputs.cache-hit != 'true'
        run: |
          ${{ env.minizinc_install_cmdline }}

      - name: Test minizinc install
        run: |
          ${{ env.minizinc_config_cmdline }}
          minizinc --version

      - name: Install scikit-decide and test dependencies
        run: |
          python_version=${{ matrix.python-version }}
          wheelfile=$(ls ./wheels/scikit_decide*-cp${python_version/\./}-*macos*.whl)
          pip install ${wheelfile}[all] pytest gymnasium[classic-control]

      - name: Test with pytest
        run: |
          # configure minizinc
          ${{ env.minizinc_config_cmdline }}
          # test minizinc
          python -c "import minizinc; print(minizinc.default_driver.minizinc_version); minizinc.Solver.lookup('gecode')"
          # run pytest, split tests using cpp scikit-decide library from others to avoid openmp versions conflicts
          pytest -v -s tests/*/cpp
          pytest -v -s --ignore-glob tests/*/cpp

  test-ubuntu:
    needs: [build-macos, build-ubuntu, build-windows, setup]
    strategy:
      matrix:
        os: ${{ fromJSON(needs.setup.outputs.test).ubuntu }}
        python-version: ${{ fromJSON(needs.setup.outputs.python_version_per_os).ubuntu }}
      fail-fast: true
    runs-on: ${{ matrix.os }}
    env:
      minizinc_config_cmdline: export PATH=$PATH:$(pwd)/bin/squashfs-root/usr/bin; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(pwd)/bin/squashfs-root/usr/lib
      minizinc_cache_path: $(pwd)/bin/squashfs-root
      minizinc_url: https://github.com/MiniZinc/MiniZincIDE/releases/download/2.6.3/MiniZincIDE-2.6.3-x86_64.AppImage
      minizinc_downloaded_filepath: bin/minizinc.AppImage
      minizinc_install_cmdline: cd bin; sudo chmod +x minizinc.AppImage; sudo ./minizinc.AppImage --appimage-extract; cd ..

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: wheels
          path: wheels

      - name: Create bin/
        run: mkdir -p bin

      - name: get MininZinc path to cache
        id: get-mzn-cache-path
        run: |
          echo "path=${{ env.minizinc_cache_path }}" >> $GITHUB_OUTPUT  # expands variables

      - name: Restore MiniZinc cache
        id: cache-minizinc
        uses: actions/cache@v3
        with:
          path: ${{ steps.get-mzn-cache-path.outputs.path }}
          key: ${{ env.minizinc_url }}

      - name: Download MiniZinc
        if: steps.cache-minizinc.outputs.cache-hit != 'true'
        run: |
          curl -o "${{ env.minizinc_downloaded_filepath }}" -L ${{ env.minizinc_url }}

      - name: Install MiniZinc
        if: steps.cache-minizinc.outputs.cache-hit != 'true'
        run: |
          ${{ env.minizinc_install_cmdline }}

      - name: Test minizinc install
        run: |
          ${{ env.minizinc_config_cmdline }}
          minizinc --version

      - name: Install scikit-decide and test dependencies
        run: |
          python_version=${{ matrix.python-version }}
          wheelfile=$(ls ./wheels/scikit_decide*-cp${python_version/\./}-*manylinux*.whl)
          pip install ${wheelfile}[all] pytest gymnasium[classic-control]

      - name: Test with pytest
        run: |
          # configure minizinc
          ${{ env.minizinc_config_cmdline }}
          # test minizinc
          python -c "import minizinc; print(minizinc.default_driver.minizinc_version); minizinc.Solver.lookup('gecode')"
          # run pytest, split tests using cpp scikit-decide library from others to avoid openmp versions conflicts
          pytest -v -s tests/*/cpp
          pytest -v -s --ignore-glob tests/*/cpp

  upload:
    needs: [test-ubuntu, test-macos, test-windows]
    runs-on: ubuntu-latest

    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: wheels
          path: wheels

      - name: Get the version
        id: get_version
        run: |
          echo "VERSION=${GITHUB_REF/refs\/tags\//}" >> $GITHUB_OUTPUT

      - name: Upload artifacts ðŸ“¦ to release
        uses: ncipollo/release-action@v1
        with:
          artifacts: wheels/*.whl
          tag: ${{ steps.get_version.outputs.VERSION }}
          allowUpdates: true
          generateReleaseNotes: true

  deploy:
    needs: [upload, setup]
    runs-on: ubuntu-latest

    steps:
      - name: Download artifact
        uses: actions/download-artifact@v3
        with:
          name: wheels
          path: wheels

      - name: Publish distribution ðŸ“¦ to PyPI
        env:
          PYPI_TOKEN: ${{ secrets.PYPI_PASSWORD }}
        if: github.repository == 'airbus/scikit-decide' && env.PYPI_TOKEN != ''
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_PASSWORD }}
          packages_dir: wheels/

      - name: Publish distribution ðŸ“¦ to Test PyPI
        env:
          TEST_PYPI_TOKEN: ${{ secrets.TEST_PYPI_PASSWORD }}
        if: env.TEST_PYPI_TOKEN != '' && needs.setup.outputs.deploy_test_pypi == 'true'
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.TEST_PYPI_PASSWORD }}
          packages_dir: wheels/
          repository_url: https://test.pypi.org/legacy/

  build-doc:
    needs: [deploy]
    runs-on: ubuntu-latest
    env:
      DOCS_VERSION_PATH: /
      python_version: "3.8"

    steps:
      - name: Get scikit-decide release version and update online docs path
        run: |
          TAG_NAME=${GITHUB_REF/refs\/tags\//}  # stripping "refs/tags/"
          SKDECIDE_VERSION=${TAG_NAME/v/}  #Â stripping "v"
          echo "TAG_NAME=${TAG_NAME}" >> $GITHUB_ENV
          echo "SKDECIDE_VERSION=${SKDECIDE_VERSION}" >> $GITHUB_ENV
          echo "DOCS_VERSION_PATH=/version/$SKDECIDE_VERSION/" >> $GITHUB_ENV

      - name: Checkout all branches
        uses: actions/checkout@v3
        with:
          submodules: true
          fetch-depth: 0  # fetch all branches

      - name: Create binder environment for the release
        run: |
          git checkout binder
          # Specify scikit-decide dependency for the release binder env
          sed -i -e "s/\(scikit-decide[^=]*==\).*/\1${SKDECIDE_VERSION}/" environment.yml
          # Unset nightly_build_url to avoid reinstalling master version over release
          sed -i -e 's/nightly_build_url="[^"]*"/nightly_build_url=""/' postBuild
          git config user.name "Actions"
          git config user.email "actions@github.com"
          git commit environment.yml postBuild -m "Specify scikit-decide used by binder for release ${SKDECIDE_VERSION}"
          # get sha1 to be used by binder for the environment
          BINDER_RELEASE_ENV_SHA1=$(git rev-parse --verify HEAD)
          echo "BINDER_RELEASE_ENV_SHA1=${BINDER_RELEASE_ENV_SHA1}" >> $GITHUB_ENV
          # push binder branch so that reference to release binder env exists on remote
          git push origin binder
          # switch back to original branch
          git checkout $TAG_NAME

      - name: Trigger a build on each BinderHub deployments in the mybinder.org federation
        run: |
          bash scripts/trigger_binder.sh https://ovh.mybinder.org/build/gh/${GITHUB_REPOSITORY}/${BINDER_RELEASE_ENV_SHA1}
          bash scripts/trigger_binder.sh https://ovh2.mybinder.org/build/gh/${GITHUB_REPOSITORY}/binder
          bash scripts/trigger_binder.sh https://notebooks.gesis.org/binder/build/gh/${GITHUB_REPOSITORY}/${BINDER_RELEASE_ENV_SHA1}

      - name: Set env variables for github+binder links in doc
        run: |
          echo "AUTODOC_BINDER_ENV_GH_REPO_NAME=${GITHUB_REPOSITORY}" >> $GITHUB_ENV
          echo "AUTODOC_BINDER_ENV_GH_BRANCH=${BINDER_RELEASE_ENV_SHA1}" >> $GITHUB_ENV
          echo "AUTODOC_NOTEBOOKS_REPO_URL=${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}" >> $GITHUB_ENV
          echo "AUTODOC_NOTEBOOKS_BRANCH=${TAG_NAME}" >> $GITHUB_ENV

      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.python_version }}

      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: wheels
          path: wheels

      - name: Install scikit-decide
        run: |
          # find proper wheel and install it
          python_version=${{ env.python_version }}
          wheelfile=$(ls ./wheels/scikit_decide*-cp${python_version/\./}-*manylinux*.whl)
          pip install ${wheelfile}[all]

      - name: generate documentation
        run: |
          yarn global add vuepress && yarn install
          export NODE_OPTIONS=--openssl-legacy-provider  # avoid issue with node 18 and current dependencies (ok because no interaction with external network during the build)
          export DO_SKIP_MZN_CHECK=1  # avoid having to install minizinc for discrete-optimization
          yarn docs:build
          touch docs/.vuepress/dist/.nojekyll

      - name: Deploy ðŸš€
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          branch: gh-pages # The branch the action should deploy to.
          folder: docs/.vuepress/dist # The folder the action should deploy.
          target-folder: ${{ env.DOCS_VERSION_PATH }} # The folder the action should deploy to.
          commit-message: publish documentation
          clean: false # Releasing a new version is about creating a new directory, so we don't want to clean up the root.

  delete-nightly-release:
    runs-on: ubuntu-latest
    needs: [deploy]

    steps:
      - name: Delete nightly release
        uses: actions/github-script@v6
        with:
          script: |
            const releases = await github.rest.repos.listReleases({
              owner: context.repo.owner,
              repo: context.repo.repo,
            })

            const nightlyRelease = releases.data.find(r => r.tag_name === 'nightly')

            if (nightlyRelease) {
              await github.rest.repos.deleteRelease({
                owner: context.repo.owner,
                repo: context.repo.repo,
                release_id: nightlyRelease.id,
              })
              console.log(`${nightlyRelease.tag_name} release has been deleted`)

            } else {
              console.log('No nightly release found')
            }
