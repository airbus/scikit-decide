name: ðŸ”¨ Build scikit-decide

on:
  push:
    branches:
      - "**"
  pull_request:
  workflow_dispatch:
  schedule:
    - cron:  '45 1 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:

  lint-sources:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: "3.8"
      - uses: pre-commit/action@v2.0.0

  build:
    strategy:
      fail-fast: false
      matrix:
        os: [windows-2016, macos-10.15, ubuntu-latest]
        python-version: ["3.7", "3.8"]
    defaults:
      run:
        shell: bash
    runs-on: ${{ matrix.os }}

    env:
      BOOST_DIR: 3rdparty/boost
      BOOST_VERSION: "1.76.0"
      SKDECIDE_SKIP_DEPS: 1

    steps:
      - name: Checkout scikit-decide source code
        uses: actions/checkout@v2
        with:
          submodules: true
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Load cached venv
        id: cached-pip-wheels
        uses: actions/cache@v2
        with:
          path: ~/.cache
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - name: Restore Boost cache
        uses: actions/cache@v2.1.4
        id: cache-boost
        with:
          path: ${{env.BOOST_DIR}}
          key: BOOST_${{env.BOOST_VERSION}}

      - name: Install Boost
        if: steps.cache-boost.outputs.cache-hit != 'true'
        run: |
          mkdir -p $BOOST_DIR
          curl --silent --location --output - \
            https://boostorg.jfrog.io/artifactory/main/release/$BOOST_VERSION/source/boost_${BOOST_VERSION//./_}.tar.bz2 |\
            tar jxf - -C $BOOST_DIR --strip-components=1 boost_${BOOST_VERSION//./_}/boost
        shell: bash

      - name: Restore build dependencies
        id: cache-build-dependencies
        uses: actions/cache@v2
        with:
          path: |
            skdecide/hub/bin
            skdecide/hub/share
            skdecide/hub/*.msc
          key: ${{ runner.os }}-cache-deps-${{ hashFiles('cpp/deps/chuffed', 'cpp/deps/gecode', 'cpp/deps/libminizinc') }}

      - name: Update SKDECIDE_SKIP_DEPS
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: echo "SKDECIDE_SKIP_DEPS=0" >> $GITHUB_ENV

      - name: Install omp on MacOS
        if: matrix.os == 'macos-10.15'
        run: brew install libomp

      - name: Install and restore ccache for macOs
        if: matrix.os == 'macos-10.15'
        uses: hendrikmuhs/ccache-action@v1.0.5
        with:
          key: ${{ runner.os }}-py${{ matrix.python-version }}
          max-size: 80M

      - name: Let cmake use ccache for macOs
        if: matrix.os == 'macos-10.15'
        run: |
          echo "CMAKE_CXX_COMPILER_LAUNCHER=ccache" >> ${GITHUB_ENV}
          echo "CMAKE_C_COMPILER_LAUNCHER=ccache" >> ${GITHUB_ENV}

      - name: Build macOS/Windows wheel
        if: matrix.os != 'ubuntu-latest'
        run: |
          export "BOOST_ROOT=$PWD/$BOOST_DIR"
          python -m pip install --upgrade pip
          pip install build poetry-dynamic-versioning
          python -m build --sdist --wheel

      - name: Restore docker dev image for Linux
        id: cache-dev-deps
        if: matrix.os == 'ubuntu-latest'
        uses: actions/cache@v2.1.4
        with:
          path: /tmp/docker
          key: dev-deps-${{ runner.os }}-${{ hashFiles('scripts/build-skdecide_dev.sh', 'scripts/build-pip-install.sh', 'scripts/Dockerfile_x86_64_dev') }}

      - name: Restore ccache cache for Linux
        id: ccache-restore
        if: matrix.os == 'ubuntu-latest'
        uses: actions/cache@v2.1.4
        with:
          path: .ccache
          key: ccache-${{ runner.os }}-py${{ matrix.python-version }}-${{ github.run_id }}-${{github.run_number}}
          restore-keys: ccache-${{ runner.os }}-py${{ matrix.python-version }}

      - name: Build x86 Linux wheels
        if: matrix.os == 'ubuntu-latest'
        run: |
          # Load skdecide_dev image from cache, or build it if not found
          if test -f /tmp/docker/skdecide_dev.tar; then
            docker image load -i /tmp/docker/skdecide_dev.tar
          else
            docker build -f scripts/Dockerfile_x86_64_dev -t skdecide_dev .
            mkdir -p /tmp/docker
            docker image save -o /tmp/docker/skdecide_dev.tar skdecide_dev
          fi
          # The existence of .ccache directory triggers ccache use in builds-manylinux-wheels.sh
          test -d .ccache || mkdir .ccache
          docker build -f scripts/Dockerfile_x86_64 -t skdecide_x86_64 --build-arg PYTHON_VERSION=${{matrix.python-version}} --build-arg SKDECIDE_SKIP_DEPS=${SKDECIDE_SKIP_DEPS} --build-arg BOOST_DIR=${BOOST_DIR} .
          # Fetch wheels from Docker
          docker run --rm -v $PWD:/mytmp skdecide_x86_64 cp -r /io/dist /mytmp
          # Fetch ccache from Docker
          docker run --rm -v $PWD:/mytmp skdecide_x86_64 cp -r /io/.ccache /mytmp

      - name: Update build cache from wheels
        if: steps.cache-build-dependencies.outputs.cache-hit != 'true'
        run: 7z x dist/*.whl -y

      - name: Upload as build artifacts
        uses: actions/upload-artifact@v2
        with:
          name: wheels
          path: dist/*.whl

  test-unix:
    needs: build
    strategy:
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.7", "3.8"]
        compiler: [gnu]
      fail-fast: true
    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pytest tqdm

      - name: Download artifacts
        uses: actions/download-artifact@v1.0.0
        with:
          name: wheels

      - name: Test with pytest
        run: |
          pip install --pre --find-links ./wheels/ "scikit-decide[all]"
          pytest -v -s tests/autocast
          pytest -v -s tests/solvers/cpp
          pytest -v -s tests/solvers/python
          pytest -v -s tests/scheduling

  test-macos:
    needs: build
    strategy:
      matrix:
        os: [macos-latest]
        python-version: ["3.7", "3.8"]
        compiler: [gnu]
      fail-fast: true
    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v2

      - name: Install libomp package
        run: brew install libomp

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pytest tqdm

      - name: Download artifacts
        uses: actions/download-artifact@v1.0.0
        with:
          name: wheels

      - name: Test with pytest
        run: |
          env
          pip install --pre --find-links ./wheels/ "scikit-decide[all]"
          pytest -v -s tests/autocast
          pytest -v -s tests/solvers/cpp
          pytest -v -s tests/solvers/python
          pytest -v -s tests/scheduling

  test-windows:
    needs: build
    strategy:
      matrix:
        os: [windows-latest]
        python-version: ["3.7", "3.8"]
        compiler: [gnu]
      fail-fast: true
    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pytest tqdm

      - name: Download artifacts
        uses: actions/download-artifact@v1.0.0
        with:
          name: wheels

      - name: Test with pytest
        run: |
          pip install --pre --find-links ./wheels/ "scikit-decide[all]"
          pytest -v -s tests/autocast
          pytest -v -s tests/solvers/cpp
          pytest -v -s tests/solvers/python
          pytest -v -s tests/scheduling

  build-docs:
    needs: [test-unix, test-macos, test-windows]
    strategy:
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.7"]
      fail-fast: false
    runs-on: ${{ matrix.os }}

    steps:
      - name: Set env variables for github+binder links in doc
        run: |
          # binder environment repo and branch
          AUTODOC_BINDER_ENV_GH_REPO_NAME="airbus/scikit-decide"
          AUTODOC_BINDER_ENV_GH_BRANCH="binder"
          # notebooks source repo and branch depending if it is a commit push or a PR
          if [[ $GITHUB_REF == refs/pull* ]];
          then
              AUTODOC_NOTEBOOKS_REPO_URL="${GITHUB_SERVER_URL}/${{ github.event.pull_request.head.repo.full_name }}"
              AUTODOC_NOTEBOOKS_BRANCH=${GITHUB_HEAD_REF}
          elif [[ $GITHUB_REF == refs/heads* ]];
          then
              AUTODOC_NOTEBOOKS_REPO_URL=${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}
              AUTODOC_NOTEBOOKS_BRANCH=${GITHUB_REF/refs\/heads\//}
          fi
          # export in GITHUB_ENV for next steps
          echo "AUTODOC_BINDER_ENV_GH_REPO_NAME=${AUTODOC_BINDER_ENV_GH_REPO_NAME}" >> $GITHUB_ENV
          echo "AUTODOC_BINDER_ENV_GH_BRANCH=${AUTODOC_BINDER_ENV_GH_BRANCH}" >> $GITHUB_ENV
          echo "AUTODOC_NOTEBOOKS_REPO_URL=${AUTODOC_NOTEBOOKS_REPO_URL}" >> $GITHUB_ENV
          echo "AUTODOC_NOTEBOOKS_BRANCH=${AUTODOC_NOTEBOOKS_BRANCH}" >> $GITHUB_ENV
          #Â check computed variables
          echo "Binder env: ${AUTODOC_BINDER_ENV_GH_REPO_NAME}/${AUTODOC_BINDER_ENV_GH_BRANCH}"
          echo "Notebooks source: ${AUTODOC_NOTEBOOKS_REPO_URL}/tree/${AUTODOC_NOTEBOOKS_BRANCH}"

      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - uses: actions/setup-node@v2
        with:
          node-version: '14'

      - name: Download artifacts
        uses: actions/download-artifact@v1.0.0
        with:
          name: wheels

      - name: Install scikit-decide
        run: |
          pip install --pre --find-links ./wheels/ "scikit-decide[all]"

      - name: generate documentation
        run: yarn global add vuepress && yarn install && yarn docs:build && touch docs/.vuepress/dist/.nojekyll

      - name: upload as artifact
        uses: actions/upload-artifact@v2
        with:
          name: doc
          path: docs/.vuepress/dist

      - name: Deploy documentation in root folder on GH pages ðŸš€
        if: github.ref == 'refs/heads/master'
        uses: JamesIves/github-pages-deploy-action@4.1.5
        with:
          branch: gh-pages # The branch the action should deploy to.
          folder: docs/.vuepress/dist # The folder the action should deploy.
          target-folder: / # The folder the action should deploy to.
          commit-message: publish documentation
          clean-exclude: |
            "version/*"

  upload-nightly:
    if: (github.ref == 'refs/heads/master') && (github.event_name == 'schedule')
    needs: [test-unix, test-macos, test-windows]
    runs-on: ubuntu-latest

    steps:
    - uses: actions/download-artifact@v2
      with:
        name: wheels
        path: dist/

    - run: |
        zip -r dist.zip dist/

    - uses: actions/github-script@v5
      id: asset
      with:
        github-token: ${{ secrets.gh_access_token }}
        script: |
          const fs = require('fs');

          // Get the ref for master
          const master_sha = '${{ github.sha }}';
          console.log(`master reference ${master_sha}`);

          // Retrieve ref for tag `nightly`
          let ref_nightly = null;
          try {
            ref_nightly = await github.rest.git.getRef({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: 'tags/nightly',
            });

            if (ref_nightly.data.object.sha === master_sha) {
              return "No new nightly release";
            }
          } catch (err) {
            // The tag does not exist so let's create it
            ref_nightly = await github.rest.git.createRef({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: 'refs/tags/nightly',
              sha: master_sha,
            });
          }

          // Call the GitHub API to get a release by tag
          let release = null;
          try {
            release = await github.rest.repos.getReleaseByTag({
              owner: context.repo.owner,
              repo: context.repo.repo,
              tag: 'nightly',
            });
            console.log(`Found release ${release.data.tag_name} ${release.data.draft} ${release.data.prerelease}`);
          } catch (err) {
            console.log(`Release 'nightly' not found`);

            // If the release doesn't exist, create it
            release = await github.rest.repos.createRelease({
              owner: context.repo.owner,
              repo: context.repo.repo,
              tag_name: 'nightly',
              name: 'nightly',
              body: 'Nightly release crafted with â™¥ï¸ somewhere on ðŸŒŽ',
              draft: false,
              prerelease: true,
            });

            console.log(`Created release ${release.data.tag_name} ${release.data.draft} ${release.data.prerelease} ${doIProceed}`);
          }
          console.log(`Release does exist with tag ${release.data.tag_name} [${release.data.draft} ${release.data.prerelease}]`);

          // At this stage both tag & release exist

          // Update nightly tag
          await github.rest.git.updateRef({
            owner: context.repo.owner,
            repo: context.repo.repo,
            ref: 'tags/nightly',
            sha: master_sha,
            force: true,
          });
          console.log(`Updated tag with sha ${ref_nightly.data.object.sha}`);

          // Update the release
          await github.rest.repos.updateRelease({
            owner: context.repo.owner,
            repo: context.repo.repo,
            release_id: release.data.id,
            tag_name: 'nightly',
            name: 'nightly',
            body: 'Nightly release crafted with â™¥ï¸ somewhere on ðŸŒŽ',
            draft: false,
            prerelease: true,
          });
          console.log(`Updated ${release.data.tag_name} nightly release  ${release.data.draft} ${release.data.prerelease}`);

          // Get all tags and keep the newest one starting by v
          let newest_tag = { name: 'v0.0.0' };

          const tags = await github.rest.repos.listTags({
            owner: context.repo.owner,
            repo: context.repo.repo,
          });

          // Keep latest tag
          for (const tag of tags.data) {
            if (tag.name.startsWith('v')) {
              if (tag.name.localeCompare(newest_tag.name, undefined, { numeric: true}) > 0) {
                newest_tag = tag;
              }
            }
          }
          console.log(`Previous release has tag ${newest_tag.name} â†’ ${newest_tag.commit.sha}`);

          // Count all commits between HEAD and newest tag
          // Limited to 250 commits
          const distance = await github.rest.repos.compareCommitsWithBasehead({
            owner: context.repo.owner,
            repo: context.repo.repo,
            basehead: `${newest_tag.commit.sha}...${master_sha}`,
          }).then(d => d.data.total_commits);

          // Zip a zip file from dist directory
          let release_name = `nightly_${distance}_${master_sha.substring(0,8)}` + '.zip';
          console.log(`Release file name: ${release_name}`);
          fs.renameSync('dist.zip', release_name);

          // Upload the zip file to GitHub
          const uploadedAsset = await github.rest.repos.uploadReleaseAsset({
            owner: context.repo.owner,
            repo: context.repo.repo,
            release_id: release.data.id,
            name: release_name,
            data: fs.readFileSync(release_name),
            headers: {
              'content-type': 'application/zip',
            },
          });

          return uploadedAsset.data.browser_download_url;
        result-encoding: string
