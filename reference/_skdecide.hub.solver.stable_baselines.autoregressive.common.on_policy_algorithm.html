<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>hub.solver.stablebaselines.autoregressive.common.onpolicy_algorithm | Scikit-decide</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="This is scikit-decide documentation">
    
    <link rel="preload" href="/scikit-decide/assets/css/0.styles.d13ef3ac.css" as="style"><link rel="preload" href="/scikit-decide/assets/js/app.19d3e3ed.js" as="script"><link rel="preload" href="/scikit-decide/assets/js/3.0d3eec02.js" as="script"><link rel="preload" href="/scikit-decide/assets/js/6.b1520538.js" as="script"><link rel="preload" href="/scikit-decide/assets/js/145.8b00b533.js" as="script"><link rel="preload" href="/scikit-decide/assets/js/8.047bff44.js" as="script"><link rel="preload" href="/scikit-decide/assets/js/9.151f8781.js" as="script"><link rel="preload" href="/scikit-decide/assets/js/5.fe62d74f.js" as="script"><link rel="prefetch" href="/scikit-decide/assets/js/1.903016a6.js"><link rel="prefetch" href="/scikit-decide/assets/js/10.e3e9aece.js"><link rel="prefetch" href="/scikit-decide/assets/js/100.68fd2ee4.js"><link rel="prefetch" href="/scikit-decide/assets/js/101.efbdd279.js"><link rel="prefetch" href="/scikit-decide/assets/js/102.c466bc90.js"><link rel="prefetch" href="/scikit-decide/assets/js/103.13c86b4d.js"><link rel="prefetch" href="/scikit-decide/assets/js/104.cee07a67.js"><link rel="prefetch" href="/scikit-decide/assets/js/105.71c23639.js"><link rel="prefetch" href="/scikit-decide/assets/js/106.90555e21.js"><link rel="prefetch" href="/scikit-decide/assets/js/107.2cd90177.js"><link rel="prefetch" href="/scikit-decide/assets/js/108.f1f441c7.js"><link rel="prefetch" href="/scikit-decide/assets/js/109.b145aa08.js"><link rel="prefetch" href="/scikit-decide/assets/js/11.d3883cc6.js"><link rel="prefetch" href="/scikit-decide/assets/js/110.4d94c568.js"><link rel="prefetch" href="/scikit-decide/assets/js/111.7ba875c1.js"><link rel="prefetch" href="/scikit-decide/assets/js/112.241cd43c.js"><link rel="prefetch" href="/scikit-decide/assets/js/113.9c869ea3.js"><link rel="prefetch" href="/scikit-decide/assets/js/114.8090f622.js"><link rel="prefetch" href="/scikit-decide/assets/js/115.d1d9cda7.js"><link rel="prefetch" href="/scikit-decide/assets/js/116.a0ff8711.js"><link rel="prefetch" href="/scikit-decide/assets/js/117.59d0214d.js"><link rel="prefetch" href="/scikit-decide/assets/js/118.535a4441.js"><link rel="prefetch" href="/scikit-decide/assets/js/119.c2e6609f.js"><link rel="prefetch" href="/scikit-decide/assets/js/12.ffbbeb9a.js"><link rel="prefetch" href="/scikit-decide/assets/js/120.d04245f8.js"><link rel="prefetch" href="/scikit-decide/assets/js/121.586ec58f.js"><link rel="prefetch" href="/scikit-decide/assets/js/122.4b86ccd5.js"><link rel="prefetch" href="/scikit-decide/assets/js/123.dad0a714.js"><link rel="prefetch" href="/scikit-decide/assets/js/124.7d28fafe.js"><link rel="prefetch" href="/scikit-decide/assets/js/125.9cd13e0b.js"><link rel="prefetch" href="/scikit-decide/assets/js/126.aef23910.js"><link rel="prefetch" href="/scikit-decide/assets/js/127.4105bf1a.js"><link rel="prefetch" href="/scikit-decide/assets/js/128.77fbafc2.js"><link rel="prefetch" href="/scikit-decide/assets/js/129.4d3bde70.js"><link rel="prefetch" href="/scikit-decide/assets/js/13.07af27b0.js"><link rel="prefetch" href="/scikit-decide/assets/js/130.9019689a.js"><link rel="prefetch" href="/scikit-decide/assets/js/131.a82b980c.js"><link rel="prefetch" href="/scikit-decide/assets/js/132.78b5eeef.js"><link rel="prefetch" href="/scikit-decide/assets/js/133.ddc21157.js"><link rel="prefetch" href="/scikit-decide/assets/js/134.61d74de8.js"><link rel="prefetch" href="/scikit-decide/assets/js/135.afe1fcd1.js"><link rel="prefetch" href="/scikit-decide/assets/js/136.83baebf8.js"><link rel="prefetch" href="/scikit-decide/assets/js/137.b082659e.js"><link rel="prefetch" href="/scikit-decide/assets/js/138.7726b07e.js"><link rel="prefetch" href="/scikit-decide/assets/js/139.085582e5.js"><link rel="prefetch" href="/scikit-decide/assets/js/14.026b1a69.js"><link rel="prefetch" href="/scikit-decide/assets/js/140.f03b0abb.js"><link rel="prefetch" href="/scikit-decide/assets/js/141.fe31a518.js"><link rel="prefetch" href="/scikit-decide/assets/js/142.da916c91.js"><link rel="prefetch" href="/scikit-decide/assets/js/143.e04c7f67.js"><link rel="prefetch" href="/scikit-decide/assets/js/144.02f31751.js"><link rel="prefetch" href="/scikit-decide/assets/js/146.a1cb5d36.js"><link rel="prefetch" href="/scikit-decide/assets/js/147.79952dc1.js"><link rel="prefetch" href="/scikit-decide/assets/js/148.1da30468.js"><link rel="prefetch" href="/scikit-decide/assets/js/149.5227fae6.js"><link rel="prefetch" href="/scikit-decide/assets/js/15.bd3d0100.js"><link rel="prefetch" href="/scikit-decide/assets/js/150.8f40017d.js"><link rel="prefetch" href="/scikit-decide/assets/js/151.71347332.js"><link rel="prefetch" href="/scikit-decide/assets/js/152.2984beee.js"><link rel="prefetch" href="/scikit-decide/assets/js/153.a8fc066b.js"><link rel="prefetch" href="/scikit-decide/assets/js/154.11817884.js"><link rel="prefetch" href="/scikit-decide/assets/js/155.3fa337a8.js"><link rel="prefetch" href="/scikit-decide/assets/js/156.71b3f72d.js"><link rel="prefetch" href="/scikit-decide/assets/js/157.36363b5b.js"><link rel="prefetch" href="/scikit-decide/assets/js/158.c20580fd.js"><link rel="prefetch" href="/scikit-decide/assets/js/159.ff115d4e.js"><link rel="prefetch" href="/scikit-decide/assets/js/16.d9bde08a.js"><link rel="prefetch" href="/scikit-decide/assets/js/160.4a857157.js"><link rel="prefetch" href="/scikit-decide/assets/js/161.95a82d1f.js"><link rel="prefetch" href="/scikit-decide/assets/js/162.64fd0c86.js"><link rel="prefetch" href="/scikit-decide/assets/js/163.c8940a83.js"><link rel="prefetch" href="/scikit-decide/assets/js/164.ebf48712.js"><link rel="prefetch" href="/scikit-decide/assets/js/165.a6021ced.js"><link rel="prefetch" href="/scikit-decide/assets/js/166.99e85596.js"><link rel="prefetch" href="/scikit-decide/assets/js/167.3b978734.js"><link rel="prefetch" href="/scikit-decide/assets/js/168.20982819.js"><link rel="prefetch" href="/scikit-decide/assets/js/169.13df8c1f.js"><link rel="prefetch" href="/scikit-decide/assets/js/17.af139114.js"><link rel="prefetch" href="/scikit-decide/assets/js/170.d476ad8e.js"><link rel="prefetch" href="/scikit-decide/assets/js/171.8e5aca43.js"><link rel="prefetch" href="/scikit-decide/assets/js/172.e782251a.js"><link rel="prefetch" href="/scikit-decide/assets/js/173.6e6dafc8.js"><link rel="prefetch" href="/scikit-decide/assets/js/174.20da1c0d.js"><link rel="prefetch" href="/scikit-decide/assets/js/18.babbb0d2.js"><link rel="prefetch" href="/scikit-decide/assets/js/19.23bb9961.js"><link rel="prefetch" href="/scikit-decide/assets/js/20.acc4d117.js"><link rel="prefetch" href="/scikit-decide/assets/js/21.0374b298.js"><link rel="prefetch" href="/scikit-decide/assets/js/22.11543dc8.js"><link rel="prefetch" href="/scikit-decide/assets/js/23.b5d7f644.js"><link rel="prefetch" href="/scikit-decide/assets/js/24.838bb10b.js"><link rel="prefetch" href="/scikit-decide/assets/js/25.b021abe9.js"><link rel="prefetch" href="/scikit-decide/assets/js/26.cbd7a07b.js"><link rel="prefetch" href="/scikit-decide/assets/js/27.03766ae0.js"><link rel="prefetch" href="/scikit-decide/assets/js/28.4f0e54fe.js"><link rel="prefetch" href="/scikit-decide/assets/js/29.5b3da0c8.js"><link rel="prefetch" href="/scikit-decide/assets/js/30.f4e14a73.js"><link rel="prefetch" href="/scikit-decide/assets/js/31.f5cba84c.js"><link rel="prefetch" href="/scikit-decide/assets/js/32.e680f6f7.js"><link rel="prefetch" href="/scikit-decide/assets/js/33.a3c3d918.js"><link rel="prefetch" href="/scikit-decide/assets/js/34.ba5dde21.js"><link rel="prefetch" href="/scikit-decide/assets/js/35.d5544cee.js"><link rel="prefetch" href="/scikit-decide/assets/js/36.b030ae7f.js"><link rel="prefetch" href="/scikit-decide/assets/js/37.6d04239c.js"><link rel="prefetch" href="/scikit-decide/assets/js/38.166d132f.js"><link rel="prefetch" href="/scikit-decide/assets/js/39.28362d33.js"><link rel="prefetch" href="/scikit-decide/assets/js/4.1033bc0a.js"><link rel="prefetch" href="/scikit-decide/assets/js/40.363edc5f.js"><link rel="prefetch" href="/scikit-decide/assets/js/41.79a5872f.js"><link rel="prefetch" href="/scikit-decide/assets/js/42.b992c489.js"><link rel="prefetch" href="/scikit-decide/assets/js/43.f5674a4e.js"><link rel="prefetch" href="/scikit-decide/assets/js/44.3f2761eb.js"><link rel="prefetch" href="/scikit-decide/assets/js/45.7dcc3efe.js"><link rel="prefetch" href="/scikit-decide/assets/js/46.82253439.js"><link rel="prefetch" href="/scikit-decide/assets/js/47.438a5db6.js"><link rel="prefetch" href="/scikit-decide/assets/js/48.58c9acf3.js"><link rel="prefetch" href="/scikit-decide/assets/js/49.df7fbaa3.js"><link rel="prefetch" href="/scikit-decide/assets/js/50.0e6ca24e.js"><link rel="prefetch" href="/scikit-decide/assets/js/51.38024db0.js"><link rel="prefetch" href="/scikit-decide/assets/js/52.9b76d288.js"><link rel="prefetch" href="/scikit-decide/assets/js/53.1a522ef1.js"><link rel="prefetch" href="/scikit-decide/assets/js/54.9ba35601.js"><link rel="prefetch" href="/scikit-decide/assets/js/55.a601294f.js"><link rel="prefetch" href="/scikit-decide/assets/js/56.9b666cd9.js"><link rel="prefetch" href="/scikit-decide/assets/js/57.9231162e.js"><link rel="prefetch" href="/scikit-decide/assets/js/58.a1591d27.js"><link rel="prefetch" href="/scikit-decide/assets/js/59.be8c6632.js"><link rel="prefetch" href="/scikit-decide/assets/js/60.4ac277ad.js"><link rel="prefetch" href="/scikit-decide/assets/js/61.abaa3522.js"><link rel="prefetch" href="/scikit-decide/assets/js/62.279d91a5.js"><link rel="prefetch" href="/scikit-decide/assets/js/63.076734ca.js"><link rel="prefetch" href="/scikit-decide/assets/js/64.9ebd01c9.js"><link rel="prefetch" href="/scikit-decide/assets/js/65.0d7d7e77.js"><link rel="prefetch" href="/scikit-decide/assets/js/66.0e931191.js"><link rel="prefetch" href="/scikit-decide/assets/js/67.19691949.js"><link rel="prefetch" href="/scikit-decide/assets/js/68.b4346de2.js"><link rel="prefetch" href="/scikit-decide/assets/js/69.a81f73de.js"><link rel="prefetch" href="/scikit-decide/assets/js/7.645e7686.js"><link rel="prefetch" href="/scikit-decide/assets/js/70.04f58e8d.js"><link rel="prefetch" href="/scikit-decide/assets/js/71.48091a4d.js"><link rel="prefetch" href="/scikit-decide/assets/js/72.417a39d1.js"><link rel="prefetch" href="/scikit-decide/assets/js/73.7d7549b9.js"><link rel="prefetch" href="/scikit-decide/assets/js/74.bcca3680.js"><link rel="prefetch" href="/scikit-decide/assets/js/75.21849825.js"><link rel="prefetch" href="/scikit-decide/assets/js/76.a50269a0.js"><link rel="prefetch" href="/scikit-decide/assets/js/77.30142592.js"><link rel="prefetch" href="/scikit-decide/assets/js/78.d174a12e.js"><link rel="prefetch" href="/scikit-decide/assets/js/79.945bae30.js"><link rel="prefetch" href="/scikit-decide/assets/js/80.39a447c6.js"><link rel="prefetch" href="/scikit-decide/assets/js/81.bdd463bc.js"><link rel="prefetch" href="/scikit-decide/assets/js/82.f83ecf17.js"><link rel="prefetch" href="/scikit-decide/assets/js/83.453d1ccf.js"><link rel="prefetch" href="/scikit-decide/assets/js/84.2b1fe63a.js"><link rel="prefetch" href="/scikit-decide/assets/js/85.f78f7764.js"><link rel="prefetch" href="/scikit-decide/assets/js/86.a15617e9.js"><link rel="prefetch" href="/scikit-decide/assets/js/87.17f83aec.js"><link rel="prefetch" href="/scikit-decide/assets/js/88.56683713.js"><link rel="prefetch" href="/scikit-decide/assets/js/89.affff5ec.js"><link rel="prefetch" href="/scikit-decide/assets/js/90.e47fcc52.js"><link rel="prefetch" href="/scikit-decide/assets/js/91.b3ce4387.js"><link rel="prefetch" href="/scikit-decide/assets/js/92.2e25a9c9.js"><link rel="prefetch" href="/scikit-decide/assets/js/93.85d795fa.js"><link rel="prefetch" href="/scikit-decide/assets/js/94.10ff6a63.js"><link rel="prefetch" href="/scikit-decide/assets/js/95.2d2797bb.js"><link rel="prefetch" href="/scikit-decide/assets/js/96.def58203.js"><link rel="prefetch" href="/scikit-decide/assets/js/97.a8f5437e.js"><link rel="prefetch" href="/scikit-decide/assets/js/98.13f3afc5.js"><link rel="prefetch" href="/scikit-decide/assets/js/99.7c9eadc8.js">
    <link rel="stylesheet" href="/scikit-decide/assets/css/0.styles.d13ef3ac.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/scikit-decide/" class="home-link router-link-active"><img src="/scikit-decide/logo.svg" alt="Scikit-decide" class="logo"> <span class="site-name can-hide">Scikit-decide</span></a> <!----> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/scikit-decide/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/scikit-decide/install.html" class="nav-link">
  Install
</a></div><div class="nav-item"><a href="/scikit-decide/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/scikit-decide/notebooks/" class="nav-link">
  Notebooks
</a></div><div class="nav-item"><a href="/scikit-decide/codegen/" class="nav-link">
  Code generators
</a></div><div class="nav-item"><a href="/scikit-decide/reference/" class="nav-link router-link-active">
  Reference
</a></div><div class="nav-item"><a href="/scikit-decide/contribute.html" class="nav-link">
  Contribute
</a></div> <a href="https://github.com/airbus/scikit-decide" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/scikit-decide/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/scikit-decide/install.html" class="nav-link">
  Install
</a></div><div class="nav-item"><a href="/scikit-decide/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/scikit-decide/notebooks/" class="nav-link">
  Notebooks
</a></div><div class="nav-item"><a href="/scikit-decide/codegen/" class="nav-link">
  Code generators
</a></div><div class="nav-item"><a href="/scikit-decide/reference/" class="nav-link router-link-active">
  Reference
</a></div><div class="nav-item"><a href="/scikit-decide/contribute.html" class="nav-link">
  Contribute
</a></div> <a href="https://github.com/airbus/scikit-decide" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>hub.solver.stablebaselines.autoregressive.common.onpolicy_algorithm</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#applicableactionsonpolicyalgorithm" class="sidebar-link">ApplicableActionsOnPolicyAlgorithm</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#constructor" class="sidebar-link">Constructor</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#collect-rollouts" class="sidebar-link">collect_rollouts</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-env" class="sidebar-link">get_env</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-parameters" class="sidebar-link">get_parameters</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-vec-normalize-env" class="sidebar-link">get_vec_normalize_env</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#learn" class="sidebar-link">learn</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#load" class="sidebar-link">load</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#predict" class="sidebar-link">predict</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#save" class="sidebar-link">save</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-env" class="sidebar-link">set_env</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-logger" class="sidebar-link">set_logger</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-parameters" class="sidebar-link">set_parameters</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-random-seed" class="sidebar-link">set_random_seed</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#train" class="sidebar-link">train</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#dump-logs" class="sidebar-link">_dump_logs</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#excluded-save-params" class="sidebar-link">_excluded_save_params</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-policy-from-name" class="sidebar-link">_get_policy_from_name</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-torch-save-params" class="sidebar-link">_get_torch_save_params</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#init-callback" class="sidebar-link">_init_callback</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#setup-learn" class="sidebar-link">_setup_learn</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#setup-lr-schedule" class="sidebar-link">_setup_lr_schedule</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#setup-model" class="sidebar-link">_setup_model</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#update-current-progress-remaining" class="sidebar-link">_update_current_progress_remaining</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#update-info-buffer" class="sidebar-link">_update_info_buffer</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#update-learning-rate" class="sidebar-link">_update_learning_rate</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#wrap-env" class="sidebar-link">_wrap_env</a></li></ul></li><li><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#applicableactionsgraphonpolicyalgorithm" class="sidebar-link">ApplicableActionsGraphOnPolicyAlgorithm</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#constructor-2" class="sidebar-link">Constructor</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#collect-rollouts-2" class="sidebar-link">collect_rollouts</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-env-2" class="sidebar-link">get_env</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-parameters-2" class="sidebar-link">get_parameters</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-vec-normalize-env-2" class="sidebar-link">get_vec_normalize_env</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#learn-2" class="sidebar-link">learn</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#load-2" class="sidebar-link">load</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#predict-2" class="sidebar-link">predict</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#save-2" class="sidebar-link">save</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-env-2" class="sidebar-link">set_env</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-logger-2" class="sidebar-link">set_logger</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-parameters-2" class="sidebar-link">set_parameters</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#set-random-seed-2" class="sidebar-link">set_random_seed</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#train-2" class="sidebar-link">train</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#dump-logs-2" class="sidebar-link">_dump_logs</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#excluded-save-params-2" class="sidebar-link">_excluded_save_params</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-policy-from-name-2" class="sidebar-link">_get_policy_from_name</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#get-torch-save-params-2" class="sidebar-link">_get_torch_save_params</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#init-callback-2" class="sidebar-link">_init_callback</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#setup-learn-2" class="sidebar-link">_setup_learn</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#setup-lr-schedule-2" class="sidebar-link">_setup_lr_schedule</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#setup-model-2" class="sidebar-link">_setup_model</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#update-current-progress-remaining-2" class="sidebar-link">_update_current_progress_remaining</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#update-info-buffer-2" class="sidebar-link">_update_info_buffer</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#update-learning-rate-2" class="sidebar-link">_update_learning_rate</a></li><li class="sidebar-sub-header"><a href="/scikit-decide/reference/_skdecide.hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm.html#wrap-env-2" class="sidebar-link">_wrap_env</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="hub-solver-stable-baselines-autoregressive-common-on-policy-algorithm"><a href="#hub-solver-stable-baselines-autoregressive-common-on-policy-algorithm" class="header-anchor">#</a> hub.solver.stable_baselines.autoregressive.common.on_policy_algorithm</h1> <div class="custom-block tip"><p class="custom-block-title">Domain specification</p> <div style="margin:10px 0px;" data-v-0ec7540b><div style="margin-top: 5px; margin-bottom: 10px" data-v-0ec7540b><span class="el-tag el-tag--danger el-tag--dark" style="margin-bottom:5px;" data-v-0ec7540b><strong data-v-0ec7540b>Domain</strong></span> </div> <button type="button" class="el-button el-button--info el-button--small is-round" style="margin-right:15px;margin-bottom:5px;" data-v-0ec7540b><!----><i class="el-icon-edit"></i><span><strong data-v-0ec7540b>Edit</strong></span></button> <label class="el-checkbox is-checked" data-v-0ec7540b><span class="el-checkbox__input is-checked"><span class="el-checkbox__inner"></span><input type="checkbox" aria-hidden="false" checked="checked" class="el-checkbox__original"></span><span class="el-checkbox__label">Only show finetuned characteristics<!----></span></label> <label class="el-checkbox is-checked" data-v-0ec7540b><span class="el-checkbox__input is-checked"><span class="el-checkbox__inner"></span><input type="checkbox" aria-hidden="false" checked="checked" class="el-checkbox__original"></span><span class="el-checkbox__label">Simplify signatures<!----></span></label> <div class="el-dialog__wrapper" style="display:none;" data-v-0ec7540b><div role="dialog" aria-modal="true" aria-label="Edit domain specification" class="el-dialog" style="margin-top:15vh;"><div class="el-dialog__header"><span class="el-dialog__title">Edit domain specification</span><button type="button" aria-label="Close" class="el-dialog__headerbtn"><i class="el-dialog__close el-icon el-icon-close"></i></button></div><!----><!----></div></div></div></div> <h2 id="applicableactionsonpolicyalgorithm"><a href="#applicableactionsonpolicyalgorithm" class="header-anchor">#</a> ApplicableActionsOnPolicyAlgorithm</h2> <p>Base class for On-Policy algorithms (ex: A2C/PPO) using list of applicable actions.</p> <h3 id="constructor"><a href="#constructor" class="header-anchor">#</a> Constructor <span class="badge tip" style="vertical-align:top;" data-v-15b7b770>ApplicableActionsOnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">ApplicableActionsOnPolicyAlgorithm</span>(
  policy: <span>typing.Union[str, type[stable_baselines3.common.policies.ActorCriticPolicy]]</span><!---->,<br>  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv')]</span><!---->,<br>  rollout_buffer_class: <span>typing.Optional[type[stable_baselines3.common.buffers.RolloutBuffer]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  **kwargs<!----><!----><!----><br>)<!----></code>
</pre> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <h3 id="collect-rollouts"><a href="#collect-rollouts" class="header-anchor">#</a> collect_rollouts <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>OnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">collect_rollouts</span>(
  self<!----><!---->,<br>  env: <span><class 'stable_baselines3.common.vec_env.base_vec_env.VecEnv'></span><!---->,<br>  callback: <span><class 'stable_baselines3.common.callbacks.BaseCallback'></span><!---->,<br>  rollout_buffer: <span><class 'stable_baselines3.common.buffers.RolloutBuffer'></span><!---->,<br>  n_rollout_steps: <span><class 'int'></span><!---->,<br>  use_masking: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span><class 'bool'></span></code>
</pre> <p>Collect experiences using the current policy and fill a <code>RolloutBuffer</code>.
The term rollout here refers to the model-free notion and should not
be used with the concept of rollout used in model-based RL or planning.</p> <p>This method is largely identical to the implementation found in the parent class and MaskablePPO.</p> <p>:param env: The training environment
:param callback: Callback that will be called at each step
(and at the beginning and end of the rollout)
:param rollout_buffer: Buffer to fill with rollouts
:param n_rollout_steps: Number of experiences to collect per environment
:param use_masking: Whether to use invalid action masks during training
:return: True if function returned with at least <code>n_rollout_steps</code>
collected, False if callback terminated rollout prematurely.</p> <h3 id="get-env"><a href="#get-env" class="header-anchor">#</a> get_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">get_env</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Optional[stable_baselines3.common.vec_env.base_vec_env.VecEnv]</span></code>
</pre> <p>Returns the current environment (can be None if not defined).</p> <p>:return: The current environment</p> <h3 id="get-parameters"><a href="#get-parameters" class="header-anchor">#</a> get_parameters <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">get_parameters</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Dict[str, typing.Dict]</span></code>
</pre> <p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p> <p>:return: Mapping of from names of the objects to PyTorch state-dicts.</p> <h3 id="get-vec-normalize-env"><a href="#get-vec-normalize-env" class="header-anchor">#</a> get_vec_normalize_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">get_vec_normalize_env</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]</span></code>
</pre> <p>Return the <code>VecNormalize</code> wrapper of the training env
if it exists.</p> <p>:return: The <code>VecNormalize</code> env.</p> <h3 id="learn"><a href="#learn" class="header-anchor">#</a> learn <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">learn</span>(
  self: <span>~SelfOnPolicyAlgorithm</span><!---->,<br>  total_timesteps: <span><class 'int'></span><!---->,<br>  callback: <span>typing.Union[NoneType, typing.Callable, typing.List[ForwardRef('BaseCallback')], ForwardRef('BaseCallback')]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  log_interval: <span><class 'int'></span> <span class="token operator">=</span> <span class="token boolean">1</span>,<br>  tb_log_name: <span><class 'str'></span> <span class="token operator">=</span> <span class="token boolean">OnPolicyAlgorithm</span>,<br>  reset_num_timesteps: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  progress_bar: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span>~SelfOnPolicyAlgorithm</span></code>
</pre> <p>Return a trained model.</p> <p>:param total_timesteps: The total number of samples (env steps) to train on
:param callback: callback(s) called at every step with state of the algorithm.
:param log_interval: for on-policy algos (e.g., PPO, A2C, ...) this is the number of
training iterations (i.e., log_interval * n_steps * n_envs timesteps) before logging;
for off-policy algos (e.g., TD3, SAC, ...) this is the number of episodes before
logging.
:param tb_log_name: the name of the run for TensorBoard logging
:param reset_num_timesteps: whether or not to reset the current timestep number (used in logging)
:param progress_bar: Display a progress bar using tqdm and rich.
:return: the trained model</p> <h3 id="load"><a href="#load" class="header-anchor">#</a> load <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">load</span>(
  path: <span>typing.Union[str, pathlib.Path, io.BufferedIOBase]</span><!---->,<br>  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv'), NoneType]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  device: <span>typing.Union[torch.device, str]</span> <span class="token operator">=</span> <span class="token boolean">auto</span>,<br>  custom_objects: <span>typing.Optional[typing.Dict[str, typing.Any]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  print_system_info: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span>,<br>  force_reset: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  **kwargs<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>~SelfBaseAlgorithm</span></code>
</pre> <p>Load the model from a zip-file.
Warning: <code>load</code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code>set_parameters</code> instead.</p> <p>:param path: path to the file (or a file-like) where to
load the agent from
:param env: the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment
:param device: Device on which the code should run.
:param custom_objects: Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code>keras.models.load_model</code>. Useful when you have an object in
file that can not be deserialized.
:param print_system_info: Whether to print system info from the saved model
and the current system info (useful to debug loading issues)
:param force_reset: Force call to <code>reset()</code> before training
to avoid unexpected behavior.
See https://github.com/DLR-RM/stable-baselines3/issues/597
:param kwargs: extra arguments to change the model when loading
:return: new model instance with loaded parameters</p> <h3 id="predict"><a href="#predict" class="header-anchor">#</a> predict <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">predict</span>(
  self<!----><!---->,<br>  observation: <span>typing.Union[numpy.ndarray, typing.Dict[str, numpy.ndarray]]</span><!---->,<br>  state: <span>typing.Optional[typing.Tuple[numpy.ndarray, ...]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  episode_start: <span>typing.Optional[numpy.ndarray]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  deterministic: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Tuple[numpy.ndarray, typing.Optional[typing.Tuple[numpy.ndarray, ...]]]</span></code>
</pre> <p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p> <p>:param observation: the input observation
:param state: The last hidden states (can be None, used in recurrent policies)
:param episode_start: The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.
:param deterministic: Whether or not to return deterministic actions.
:return: the model's action and the next hidden state
(used in recurrent policies)</p> <h3 id="save"><a href="#save" class="header-anchor">#</a> save <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">save</span>(
  self<!----><!---->,<br>  path: <span>typing.Union[str, pathlib.Path, io.BufferedIOBase]</span><!---->,<br>  exclude: <span>typing.Optional[typing.Iterable[str]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  include: <span>typing.Optional[typing.Iterable[str]]</span> <span class="token operator">=</span> <span class="token boolean">None</span><!----><br>)<!----></code>
</pre> <p>Save all the attributes of the object and the model parameters in a zip-file.</p> <p>:param path: path to the file where the rl agent should be saved
:param exclude: name of parameters that should be excluded in addition to the default ones
:param include: name of parameters that might be excluded but should be included anyway</p> <h3 id="set-env"><a href="#set-env" class="header-anchor">#</a> set_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_env</span>(
  self<!----><!---->,<br>  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv')]</span><!---->,<br>  force_reset: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span><!----><br>)<!----></code>
</pre> <p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:</p> <ul><li>observation_space</li> <li>action_space</li></ul> <p>:param env: The environment for learning a policy
:param force_reset: Force call to <code>reset()</code> before training
to avoid unexpected behavior.
See issue https://github.com/DLR-RM/stable-baselines3/issues/597</p> <h3 id="set-logger"><a href="#set-logger" class="header-anchor">#</a> set_logger <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_logger</span>(
  self<!----><!---->,<br>  logger: <span><class 'stable_baselines3.common.logger.Logger'></span><!----><!----><br>)<!----></code>
</pre> <p>Setter for for logger object.</p> <p>.. warning::</p> <p>When passing a custom logger object,
this will overwrite <code>tensorboard_log</code> and <code>verbose</code> settings
passed to the constructor.</p> <h3 id="set-parameters"><a href="#set-parameters" class="header-anchor">#</a> set_parameters <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_parameters</span>(
  self<!----><!---->,<br>  load_path_or_dict: <span>typing.Union[str, typing.Dict[str, torch.Tensor]]</span><!---->,<br>  exact_match: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  device: <span>typing.Union[torch.device, str]</span> <span class="token operator">=</span> <span class="token boolean">auto</span><!----><br>)<!----></code>
</pre> <p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code>get_parameters</code>).</p> <p>:param load_path_or_iter: Location of the saved data (path or file-like, see <code>save</code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code>torch.nn.Module.state_dict()</code>.
:param exact_match: If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.
:param device: Device on which the code should run.</p> <h3 id="set-random-seed"><a href="#set-random-seed" class="header-anchor">#</a> set_random_seed <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_random_seed</span>(
  self<!----><!---->,<br>  seed: <span>typing.Optional[int]</span> <span class="token operator">=</span> <span class="token boolean">None</span><!----><br>)<!----></code>
</pre> <p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p> <p>:param seed:</p> <h3 id="train"><a href="#train" class="header-anchor">#</a> train <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>OnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">train</span>(
  self<!----><!----><!----><br>)<!----></code>
</pre> <p>Consume current rollout data and update policy parameters.
Implemented by individual algorithms.</p> <h3 id="dump-logs"><a href="#dump-logs" class="header-anchor">#</a> _dump_logs <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>OnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_dump_logs</span>(
  self<!----><!---->,<br>  iteration: <span><class 'int'></span><!----><!----><br>)<!----></code>
</pre> <p>Write log.</p> <p>:param iteration: Current logging iteration</p> <h3 id="excluded-save-params"><a href="#excluded-save-params" class="header-anchor">#</a> _excluded_save_params <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_excluded_save_params</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.List[str]</span></code>
</pre> <p>Returns the names of the parameters that should be excluded from being
saved by pickling. E.g. replay buffers are skipped by default
as they take up a lot of space. PyTorch variables should be excluded
with this so they can be stored with <code>th.save</code>.</p> <p>:return: List of parameters that should be excluded from being saved with pickle.</p> <h3 id="get-policy-from-name"><a href="#get-policy-from-name" class="header-anchor">#</a> _get_policy_from_name <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_get_policy_from_name</span>(
  self<!----><!---->,<br>  policy_name: <span><class 'str'></span><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Type[stable_baselines3.common.policies.BasePolicy]</span></code>
</pre> <p>Get a policy class from its name representation.</p> <p>The goal here is to standardize policy naming, e.g.
all algorithms can call upon &quot;MlpPolicy&quot; or &quot;CnnPolicy&quot;,
and they receive respective policies that work for them.</p> <p>:param policy_name: Alias of the policy
:return: A policy class (type)</p> <h3 id="get-torch-save-params"><a href="#get-torch-save-params" class="header-anchor">#</a> _get_torch_save_params <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_get_torch_save_params</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Tuple[typing.List[str], typing.List[str]]</span></code>
</pre> <p>Get the name of the torch variables that will be saved with
PyTorch <code>th.save</code>, <code>th.load</code> and <code>state_dicts</code> instead of the default
pickling strategy. This is to handle device placement correctly.</p> <p>Names can point to specific variables under classes, e.g.
&quot;policy.optimizer&quot; would point to <code>optimizer</code> object of <code>self.policy</code>
if this object.</p> <p>:return:
List of Torch variables whose state dicts to save (e.g. th.nn.Modules),
and list of other Torch variables to store with <code>th.save</code>.</p> <h3 id="init-callback"><a href="#init-callback" class="header-anchor">#</a> _init_callback <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_init_callback</span>(
  self<!----><!---->,<br>  callback: <span>typing.Union[NoneType, typing.Callable, typing.List[ForwardRef('BaseCallback')], ForwardRef('BaseCallback')]</span><!---->,<br>  progress_bar: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span><class 'stable_baselines3.common.callbacks.BaseCallback'></span></code>
</pre> <p>:param callback: Callback(s) called at every step with state of the algorithm.
:param progress_bar: Display a progress bar using tqdm and rich.
:return: A hybrid callback calling <code>callback</code> and performing evaluation.</p> <h3 id="setup-learn"><a href="#setup-learn" class="header-anchor">#</a> _setup_learn <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_setup_learn</span>(
  self<!----><!---->,<br>  total_timesteps: <span><class 'int'></span><!---->,<br>  callback: <span>typing.Union[NoneType, typing.Callable, typing.List[ForwardRef('BaseCallback')], ForwardRef('BaseCallback')]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  reset_num_timesteps: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  tb_log_name: <span><class 'str'></span> <span class="token operator">=</span> <span class="token boolean">run</span>,<br>  progress_bar: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Tuple[int, stable_baselines3.common.callbacks.BaseCallback]</span></code>
</pre> <p>Initialize different variables needed for training.</p> <p>:param total_timesteps: The total number of samples (env steps) to train on
:param callback: Callback(s) called at every step with state of the algorithm.
:param reset_num_timesteps: Whether to reset or not the <code>num_timesteps</code> attribute
:param tb_log_name: the name of the run for tensorboard log
:param progress_bar: Display a progress bar using tqdm and rich.
:return: Total timesteps and callback(s)</p> <h3 id="setup-lr-schedule"><a href="#setup-lr-schedule" class="header-anchor">#</a> _setup_lr_schedule <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_setup_lr_schedule</span>(
  self<!----><!----><!----><br>)<!----></code>
</pre> <p>Transform to callable if needed.</p> <h3 id="setup-model"><a href="#setup-model" class="header-anchor">#</a> _setup_model <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_setup_model</span>(
  self<!----><!----><!----><br>)<!----></code>
</pre> <p>Create networks, buffer and optimizers.</p> <h3 id="update-current-progress-remaining"><a href="#update-current-progress-remaining" class="header-anchor">#</a> _update_current_progress_remaining <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_update_current_progress_remaining</span>(
  self<!----><!---->,<br>  num_timesteps: <span><class 'int'></span><!---->,<br>  total_timesteps: <span><class 'int'></span><!----><!----><br>)<!----></code>
</pre> <p>Compute current progress remaining (starts from 1 and ends to 0)</p> <p>:param num_timesteps: current number of timesteps
:param total_timesteps:</p> <h3 id="update-info-buffer"><a href="#update-info-buffer" class="header-anchor">#</a> _update_info_buffer <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_update_info_buffer</span>(
  self<!----><!---->,<br>  infos: <span>typing.List[typing.Dict[str, typing.Any]]</span><!---->,<br>  dones: <span>typing.Optional[numpy.ndarray]</span> <span class="token operator">=</span> <span class="token boolean">None</span><!----><br>)<!----></code>
</pre> <p>Retrieve reward, episode length, episode success and update the buffer
if using Monitor wrapper or a GoalEnv.</p> <p>:param infos: List of additional information about the transition.
:param dones: Termination signals</p> <h3 id="update-learning-rate"><a href="#update-learning-rate" class="header-anchor">#</a> _update_learning_rate <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_update_learning_rate</span>(
  self<!----><!---->,<br>  optimizers: <span>typing.Union[typing.List[torch.optim.optimizer.Optimizer], torch.optim.optimizer.Optimizer]</span><!----><!----><br>)<!----></code>
</pre> <p>Update the optimizers learning rate using the current learning rate schedule
and the current progress remaining (from 1 to 0).</p> <p>:param optimizers:
An optimizer or a list of optimizers.</p> <h3 id="wrap-env"><a href="#wrap-env" class="header-anchor">#</a> _wrap_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_wrap_env</span>(
  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv')]</span><!---->,<br>  verbose: <span><class 'int'></span> <span class="token operator">=</span> <span class="token boolean">0</span>,<br>  monitor_wrapper: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span><!----><br>) <span class="token operator">-&gt;</span> <span><class 'stable_baselines3.common.vec_env.base_vec_env.VecEnv'></span></code>
</pre> <p>&quot;
Wrap environment with the appropriate wrappers if needed.
For instance, to have a vectorized environment
or to re-order the image channels.</p> <p>:param env:
:param verbose: Verbosity level: 0 for no output, 1 for indicating wrappers used
:param monitor_wrapper: Whether to wrap the env in a <code>Monitor</code> when possible.
:return: The wrapped environment.</p> <h2 id="applicableactionsgraphonpolicyalgorithm"><a href="#applicableactionsgraphonpolicyalgorithm" class="header-anchor">#</a> ApplicableActionsGraphOnPolicyAlgorithm</h2> <p>Base class for On-Policy algorithms (ex: A2C/PPO) using list of applicable actions and graph obs.</p> <h3 id="constructor-2"><a href="#constructor-2" class="header-anchor">#</a> Constructor <span class="badge tip" style="vertical-align:top;" data-v-15b7b770>ApplicableActionsGraphOnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">ApplicableActionsGraphOnPolicyAlgorithm</span>(
  policy: <span>typing.Union[str, type[stable_baselines3.common.policies.ActorCriticPolicy]]</span><!---->,<br>  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv')]</span><!---->,<br>  rollout_buffer_class: <span>typing.Optional[type[stable_baselines3.common.buffers.RolloutBuffer]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  **kwargs<!----><!----><!----><br>)<!----></code>
</pre> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <h3 id="collect-rollouts-2"><a href="#collect-rollouts-2" class="header-anchor">#</a> collect_rollouts <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>OnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">collect_rollouts</span>(
  self<!----><!---->,<br>  env: <span><class 'stable_baselines3.common.vec_env.base_vec_env.VecEnv'></span><!---->,<br>  callback: <span><class 'stable_baselines3.common.callbacks.BaseCallback'></span><!---->,<br>  rollout_buffer: <span><class 'stable_baselines3.common.buffers.RolloutBuffer'></span><!---->,<br>  n_rollout_steps: <span><class 'int'></span><!---->,<br>  use_masking: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span><class 'bool'></span></code>
</pre> <p>Collect experiences using the current policy and fill a <code>RolloutBuffer</code>.
The term rollout here refers to the model-free notion and should not
be used with the concept of rollout used in model-based RL or planning.</p> <p>This method is largely identical to the implementation found in the parent class and MaskablePPO.</p> <p>:param env: The training environment
:param callback: Callback that will be called at each step
(and at the beginning and end of the rollout)
:param rollout_buffer: Buffer to fill with rollouts
:param n_rollout_steps: Number of experiences to collect per environment
:param use_masking: Whether to use invalid action masks during training
:return: True if function returned with at least <code>n_rollout_steps</code>
collected, False if callback terminated rollout prematurely.</p> <h3 id="get-env-2"><a href="#get-env-2" class="header-anchor">#</a> get_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">get_env</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Optional[stable_baselines3.common.vec_env.base_vec_env.VecEnv]</span></code>
</pre> <p>Returns the current environment (can be None if not defined).</p> <p>:return: The current environment</p> <h3 id="get-parameters-2"><a href="#get-parameters-2" class="header-anchor">#</a> get_parameters <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">get_parameters</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Dict[str, typing.Dict]</span></code>
</pre> <p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p> <p>:return: Mapping of from names of the objects to PyTorch state-dicts.</p> <h3 id="get-vec-normalize-env-2"><a href="#get-vec-normalize-env-2" class="header-anchor">#</a> get_vec_normalize_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">get_vec_normalize_env</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Optional[stable_baselines3.common.vec_env.vec_normalize.VecNormalize]</span></code>
</pre> <p>Return the <code>VecNormalize</code> wrapper of the training env
if it exists.</p> <p>:return: The <code>VecNormalize</code> env.</p> <h3 id="learn-2"><a href="#learn-2" class="header-anchor">#</a> learn <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">learn</span>(
  self: <span>~SelfOnPolicyAlgorithm</span><!---->,<br>  total_timesteps: <span><class 'int'></span><!---->,<br>  callback: <span>typing.Union[NoneType, typing.Callable, typing.List[ForwardRef('BaseCallback')], ForwardRef('BaseCallback')]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  log_interval: <span><class 'int'></span> <span class="token operator">=</span> <span class="token boolean">1</span>,<br>  tb_log_name: <span><class 'str'></span> <span class="token operator">=</span> <span class="token boolean">OnPolicyAlgorithm</span>,<br>  reset_num_timesteps: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  progress_bar: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span>~SelfOnPolicyAlgorithm</span></code>
</pre> <p>Return a trained model.</p> <p>:param total_timesteps: The total number of samples (env steps) to train on
:param callback: callback(s) called at every step with state of the algorithm.
:param log_interval: for on-policy algos (e.g., PPO, A2C, ...) this is the number of
training iterations (i.e., log_interval * n_steps * n_envs timesteps) before logging;
for off-policy algos (e.g., TD3, SAC, ...) this is the number of episodes before
logging.
:param tb_log_name: the name of the run for TensorBoard logging
:param reset_num_timesteps: whether or not to reset the current timestep number (used in logging)
:param progress_bar: Display a progress bar using tqdm and rich.
:return: the trained model</p> <h3 id="load-2"><a href="#load-2" class="header-anchor">#</a> load <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">load</span>(
  path: <span>typing.Union[str, pathlib.Path, io.BufferedIOBase]</span><!---->,<br>  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv'), NoneType]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  device: <span>typing.Union[torch.device, str]</span> <span class="token operator">=</span> <span class="token boolean">auto</span>,<br>  custom_objects: <span>typing.Optional[typing.Dict[str, typing.Any]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  print_system_info: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span>,<br>  force_reset: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  **kwargs<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>~SelfBaseAlgorithm</span></code>
</pre> <p>Load the model from a zip-file.
Warning: <code>load</code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code>set_parameters</code> instead.</p> <p>:param path: path to the file (or a file-like) where to
load the agent from
:param env: the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment
:param device: Device on which the code should run.
:param custom_objects: Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code>keras.models.load_model</code>. Useful when you have an object in
file that can not be deserialized.
:param print_system_info: Whether to print system info from the saved model
and the current system info (useful to debug loading issues)
:param force_reset: Force call to <code>reset()</code> before training
to avoid unexpected behavior.
See https://github.com/DLR-RM/stable-baselines3/issues/597
:param kwargs: extra arguments to change the model when loading
:return: new model instance with loaded parameters</p> <h3 id="predict-2"><a href="#predict-2" class="header-anchor">#</a> predict <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">predict</span>(
  self<!----><!---->,<br>  observation: <span>typing.Union[numpy.ndarray, typing.Dict[str, numpy.ndarray]]</span><!---->,<br>  state: <span>typing.Optional[typing.Tuple[numpy.ndarray, ...]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  episode_start: <span>typing.Optional[numpy.ndarray]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  deterministic: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Tuple[numpy.ndarray, typing.Optional[typing.Tuple[numpy.ndarray, ...]]]</span></code>
</pre> <p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p> <p>:param observation: the input observation
:param state: The last hidden states (can be None, used in recurrent policies)
:param episode_start: The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.
:param deterministic: Whether or not to return deterministic actions.
:return: the model's action and the next hidden state
(used in recurrent policies)</p> <h3 id="save-2"><a href="#save-2" class="header-anchor">#</a> save <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">save</span>(
  self<!----><!---->,<br>  path: <span>typing.Union[str, pathlib.Path, io.BufferedIOBase]</span><!---->,<br>  exclude: <span>typing.Optional[typing.Iterable[str]]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  include: <span>typing.Optional[typing.Iterable[str]]</span> <span class="token operator">=</span> <span class="token boolean">None</span><!----><br>)<!----></code>
</pre> <p>Save all the attributes of the object and the model parameters in a zip-file.</p> <p>:param path: path to the file where the rl agent should be saved
:param exclude: name of parameters that should be excluded in addition to the default ones
:param include: name of parameters that might be excluded but should be included anyway</p> <h3 id="set-env-2"><a href="#set-env-2" class="header-anchor">#</a> set_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_env</span>(
  self<!----><!---->,<br>  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv')]</span><!---->,<br>  force_reset: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span><!----><br>)<!----></code>
</pre> <p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:</p> <ul><li>observation_space</li> <li>action_space</li></ul> <p>:param env: The environment for learning a policy
:param force_reset: Force call to <code>reset()</code> before training
to avoid unexpected behavior.
See issue https://github.com/DLR-RM/stable-baselines3/issues/597</p> <h3 id="set-logger-2"><a href="#set-logger-2" class="header-anchor">#</a> set_logger <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_logger</span>(
  self<!----><!---->,<br>  logger: <span><class 'stable_baselines3.common.logger.Logger'></span><!----><!----><br>)<!----></code>
</pre> <p>Setter for for logger object.</p> <p>.. warning::</p> <p>When passing a custom logger object,
this will overwrite <code>tensorboard_log</code> and <code>verbose</code> settings
passed to the constructor.</p> <h3 id="set-parameters-2"><a href="#set-parameters-2" class="header-anchor">#</a> set_parameters <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_parameters</span>(
  self<!----><!---->,<br>  load_path_or_dict: <span>typing.Union[str, typing.Dict[str, torch.Tensor]]</span><!---->,<br>  exact_match: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  device: <span>typing.Union[torch.device, str]</span> <span class="token operator">=</span> <span class="token boolean">auto</span><!----><br>)<!----></code>
</pre> <p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code>get_parameters</code>).</p> <p>:param load_path_or_iter: Location of the saved data (path or file-like, see <code>save</code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code>torch.nn.Module.state_dict()</code>.
:param exact_match: If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.
:param device: Device on which the code should run.</p> <h3 id="set-random-seed-2"><a href="#set-random-seed-2" class="header-anchor">#</a> set_random_seed <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">set_random_seed</span>(
  self<!----><!---->,<br>  seed: <span>typing.Optional[int]</span> <span class="token operator">=</span> <span class="token boolean">None</span><!----><br>)<!----></code>
</pre> <p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p> <p>:param seed:</p> <h3 id="train-2"><a href="#train-2" class="header-anchor">#</a> train <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>OnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">train</span>(
  self<!----><!----><!----><br>)<!----></code>
</pre> <p>Consume current rollout data and update policy parameters.
Implemented by individual algorithms.</p> <h3 id="dump-logs-2"><a href="#dump-logs-2" class="header-anchor">#</a> _dump_logs <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>OnPolicyAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_dump_logs</span>(
  self<!----><!---->,<br>  iteration: <span><class 'int'></span><!----><!----><br>)<!----></code>
</pre> <p>Write log.</p> <p>:param iteration: Current logging iteration</p> <h3 id="excluded-save-params-2"><a href="#excluded-save-params-2" class="header-anchor">#</a> _excluded_save_params <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_excluded_save_params</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.List[str]</span></code>
</pre> <p>Returns the names of the parameters that should be excluded from being
saved by pickling. E.g. replay buffers are skipped by default
as they take up a lot of space. PyTorch variables should be excluded
with this so they can be stored with <code>th.save</code>.</p> <p>:return: List of parameters that should be excluded from being saved with pickle.</p> <h3 id="get-policy-from-name-2"><a href="#get-policy-from-name-2" class="header-anchor">#</a> _get_policy_from_name <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_get_policy_from_name</span>(
  self<!----><!---->,<br>  policy_name: <span><class 'str'></span><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Type[stable_baselines3.common.policies.BasePolicy]</span></code>
</pre> <p>Get a policy class from its name representation.</p> <p>The goal here is to standardize policy naming, e.g.
all algorithms can call upon &quot;MlpPolicy&quot; or &quot;CnnPolicy&quot;,
and they receive respective policies that work for them.</p> <p>:param policy_name: Alias of the policy
:return: A policy class (type)</p> <h3 id="get-torch-save-params-2"><a href="#get-torch-save-params-2" class="header-anchor">#</a> _get_torch_save_params <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_get_torch_save_params</span>(
  self<!----><!----><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Tuple[typing.List[str], typing.List[str]]</span></code>
</pre> <p>Get the name of the torch variables that will be saved with
PyTorch <code>th.save</code>, <code>th.load</code> and <code>state_dicts</code> instead of the default
pickling strategy. This is to handle device placement correctly.</p> <p>Names can point to specific variables under classes, e.g.
&quot;policy.optimizer&quot; would point to <code>optimizer</code> object of <code>self.policy</code>
if this object.</p> <p>:return:
List of Torch variables whose state dicts to save (e.g. th.nn.Modules),
and list of other Torch variables to store with <code>th.save</code>.</p> <h3 id="init-callback-2"><a href="#init-callback-2" class="header-anchor">#</a> _init_callback <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_init_callback</span>(
  self<!----><!---->,<br>  callback: <span>typing.Union[NoneType, typing.Callable, typing.List[ForwardRef('BaseCallback')], ForwardRef('BaseCallback')]</span><!---->,<br>  progress_bar: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span><class 'stable_baselines3.common.callbacks.BaseCallback'></span></code>
</pre> <p>:param callback: Callback(s) called at every step with state of the algorithm.
:param progress_bar: Display a progress bar using tqdm and rich.
:return: A hybrid callback calling <code>callback</code> and performing evaluation.</p> <h3 id="setup-learn-2"><a href="#setup-learn-2" class="header-anchor">#</a> _setup_learn <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_setup_learn</span>(
  self<!----><!---->,<br>  total_timesteps: <span><class 'int'></span><!---->,<br>  callback: <span>typing.Union[NoneType, typing.Callable, typing.List[ForwardRef('BaseCallback')], ForwardRef('BaseCallback')]</span> <span class="token operator">=</span> <span class="token boolean">None</span>,<br>  reset_num_timesteps: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span>,<br>  tb_log_name: <span><class 'str'></span> <span class="token operator">=</span> <span class="token boolean">run</span>,<br>  progress_bar: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">False</span><!----><br>) <span class="token operator">-&gt;</span> <span>typing.Tuple[int, stable_baselines3.common.callbacks.BaseCallback]</span></code>
</pre> <p>Initialize different variables needed for training.</p> <p>:param total_timesteps: The total number of samples (env steps) to train on
:param callback: Callback(s) called at every step with state of the algorithm.
:param reset_num_timesteps: Whether to reset or not the <code>num_timesteps</code> attribute
:param tb_log_name: the name of the run for tensorboard log
:param progress_bar: Display a progress bar using tqdm and rich.
:return: Total timesteps and callback(s)</p> <h3 id="setup-lr-schedule-2"><a href="#setup-lr-schedule-2" class="header-anchor">#</a> _setup_lr_schedule <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_setup_lr_schedule</span>(
  self<!----><!----><!----><br>)<!----></code>
</pre> <p>Transform to callable if needed.</p> <h3 id="setup-model-2"><a href="#setup-model-2" class="header-anchor">#</a> _setup_model <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_setup_model</span>(
  self<!----><!----><!----><br>)<!----></code>
</pre> <p>Create networks, buffer and optimizers.</p> <h3 id="update-current-progress-remaining-2"><a href="#update-current-progress-remaining-2" class="header-anchor">#</a> _update_current_progress_remaining <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_update_current_progress_remaining</span>(
  self<!----><!---->,<br>  num_timesteps: <span><class 'int'></span><!---->,<br>  total_timesteps: <span><class 'int'></span><!----><!----><br>)<!----></code>
</pre> <p>Compute current progress remaining (starts from 1 and ends to 0)</p> <p>:param num_timesteps: current number of timesteps
:param total_timesteps:</p> <h3 id="update-info-buffer-2"><a href="#update-info-buffer-2" class="header-anchor">#</a> _update_info_buffer <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_update_info_buffer</span>(
  self<!----><!---->,<br>  infos: <span>typing.List[typing.Dict[str, typing.Any]]</span><!---->,<br>  dones: <span>typing.Optional[numpy.ndarray]</span> <span class="token operator">=</span> <span class="token boolean">None</span><!----><br>)<!----></code>
</pre> <p>Retrieve reward, episode length, episode success and update the buffer
if using Monitor wrapper or a GoalEnv.</p> <p>:param infos: List of additional information about the transition.
:param dones: Termination signals</p> <h3 id="update-learning-rate-2"><a href="#update-learning-rate-2" class="header-anchor">#</a> _update_learning_rate <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_update_learning_rate</span>(
  self<!----><!---->,<br>  optimizers: <span>typing.Union[typing.List[torch.optim.optimizer.Optimizer], torch.optim.optimizer.Optimizer]</span><!----><!----><br>)<!----></code>
</pre> <p>Update the optimizers learning rate using the current learning rate schedule
and the current progress remaining (from 1 to 0).</p> <p>:param optimizers:
An optimizer or a list of optimizers.</p> <h3 id="wrap-env-2"><a href="#wrap-env-2" class="header-anchor">#</a> _wrap_env <span class="badge warn" style="vertical-align:top;" data-v-15b7b770>BaseAlgorithm</span></h3> <pre><code class="language-python"><span class="token function">_wrap_env</span>(
  env: <span>typing.Union[gymnasium.core.Env, ForwardRef('VecEnv')]</span><!---->,<br>  verbose: <span><class 'int'></span> <span class="token operator">=</span> <span class="token boolean">0</span>,<br>  monitor_wrapper: <span><class 'bool'></span> <span class="token operator">=</span> <span class="token boolean">True</span><!----><br>) <span class="token operator">-&gt;</span> <span><class 'stable_baselines3.common.vec_env.base_vec_env.VecEnv'></span></code>
</pre> <p>&quot;
Wrap environment with the appropriate wrappers if needed.
For instance, to have a vectorized environment
or to re-order the image channels.</p> <p>:param env:
:param verbose: Verbosity level: 0 for no output, 1 for indicating wrappers used
:param monitor_wrapper: Whether to wrap the env in a <code>Monitor</code> when possible.
:return: The wrapped environment.</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"><!----></div></div>
    <script src="/scikit-decide/assets/js/app.19d3e3ed.js" defer></script><script src="/scikit-decide/assets/js/3.0d3eec02.js" defer></script><script src="/scikit-decide/assets/js/6.b1520538.js" defer></script><script src="/scikit-decide/assets/js/145.8b00b533.js" defer></script><script src="/scikit-decide/assets/js/8.047bff44.js" defer></script><script src="/scikit-decide/assets/js/9.151f8781.js" defer></script><script src="/scikit-decide/assets/js/5.fe62d74f.js" defer></script>
  </body>
</html>
